import {} from '../NodeBase.js';
import { nanoid } from 'nanoid/non-secure';
import { NodeImpl } from '../NodeImpl.js';
import { nodeDefinition } from '../NodeDefinition.js';
import {} from '../../index.js';
import { mapValues } from 'lodash-es';
import { dedent } from 'ts-dedent';
import { coerceType, coerceTypeOptional } from '../../utils/coerceType.js';
import { getInputOrData } from '../../utils/index.js';
import { interpolate, extractInterpolationVariables } from '../../utils/interpolation.js';
import { match } from 'ts-pattern';
export class PromptNodeImpl extends NodeImpl {
    static create() {
        const chartNode = {
            type: 'prompt',
            title: 'Prompt',
            id: nanoid(),
            visualData: {
                x: 0,
                y: 0,
                width: 250,
            },
            data: {
                type: 'user',
                useTypeInput: false,
                promptText: '{{input}}',
                enableFunctionCall: false,
            },
        };
        return chartNode;
    }
    getInputDefinitions() {
        let inputs = [];
        if (this.data.enableFunctionCall) {
            inputs.push({
                id: 'function-call',
                title: 'Function Call',
                dataType: 'object',
            });
        }
        if (this.data.useTypeInput) {
            inputs.push({
                id: 'type',
                title: 'Type',
                dataType: 'string',
            });
        }
        if (this.data.useNameInput) {
            inputs.push({
                id: 'name',
                title: 'Name/ID',
                dataType: 'string',
            });
        }
        if (this.data.useIsCacheBreakpointInput) {
            inputs.push({
                id: 'isCacheBreakpoint',
                title: 'Is Cache Breakpoint',
                dataType: 'boolean',
            });
        }
        // Extract inputs from promptText, everything like {{input}}
        const inputNames = extractInterpolationVariables(this.data.promptText);
        inputs = [
            ...inputs,
            ...(inputNames?.map((inputName) => {
                return {
                    id: inputName,
                    title: inputName,
                    dataType: 'string',
                    required: false,
                };
            }) ?? []),
        ];
        return inputs;
    }
    getOutputDefinitions() {
        const outputs = [
            {
                id: 'output',
                title: 'Output',
                dataType: 'chat-message',
            },
        ];
        if (this.chartNode.data.computeTokenCount) {
            outputs.push({
                id: 'tokenCount',
                title: 'Token Count',
                dataType: 'number',
            });
        }
        return outputs;
    }
    getEditors() {
        return [
            {
                type: 'custom',
                customEditorId: 'PromptNodeAiAssist',
                label: 'Generate Using AI',
            },
            {
                type: 'dropdown',
                label: 'Type',
                options: [
                    { value: 'system', label: 'System' },
                    { value: 'user', label: 'User' },
                    { value: 'assistant', label: 'Assistant' },
                    { value: 'function', label: 'Function' },
                ],
                dataKey: 'type',
                useInputToggleDataKey: 'useTypeInput',
            },
            {
                type: 'string',
                label: 'Name',
                dataKey: 'name',
                useInputToggleDataKey: 'useNameInput',
                hideIf: (data) => data.type !== 'function',
                helperMessage: 'For OpenAI, this is the tool call ID. Otherwise, it is the name of the function that is outputting the message.',
            },
            {
                type: 'toggle',
                label: 'Enable Function Call',
                dataKey: 'enableFunctionCall',
                hideIf: (data) => data.type !== 'assistant',
            },
            {
                type: 'toggle',
                label: 'Compute Token Count',
                dataKey: 'computeTokenCount',
            },
            {
                type: 'toggle',
                label: 'Is Cache Breakpoint',
                dataKey: 'isCacheBreakpoint',
                helperMessage: 'For Anthropic, marks this message as a cache breakpoint - this message and every message before it will be cached using Prompt Caching.',
                useInputToggleDataKey: 'useIsCacheBreakpointInput',
            },
            {
                type: 'code',
                label: 'Prompt Text',
                dataKey: 'promptText',
                language: 'prompt-interpolation-markdown',
                theme: 'prompt-interpolation',
            },
        ];
    }
    getBody() {
        return [
            {
                type: 'markdown',
                text: dedent `
          _${typeDisplay[this.data.type]}${this.data.name ? ` (${this.data.name})` : ''}_ ${this.data.isCacheBreakpoint ? ' (Cache Breakpoint)' : ''}
      `,
            },
            {
                type: 'colorized',
                text: this.data.promptText.split('\n').slice(0, 15).join('\n').trim(),
                language: 'prompt-interpolation-markdown',
                theme: 'prompt-interpolation',
            },
        ];
    }
    static getUIData() {
        return {
            infoBoxBody: dedent `
        Outputs a chat message, which is a string of text with an attached "type" saying who sent the message (User, Assistant, System) and optionally an attached "name".

        Also provides the same <span style="color: var(--primary)">{{interpolation}}</span> capabilities as a Text node.

        Can change one chat message type into another chat message type. For example, changing a User message into a System message.
      `,
            infoBoxTitle: 'Prompt Node',
            contextMenuTitle: 'Prompt',
            group: ['Text'],
        };
    }
    async process(inputs, context) {
        const inputMap = mapValues(inputs, (input) => coerceType(input, 'string'));
        const outputValue = interpolate(this.chartNode.data.promptText, inputMap);
        const type = getInputOrData(this.data, inputs, 'type', 'string');
        const isCacheBreakpoint = getInputOrData(this.data, inputs, 'isCacheBreakpoint', 'boolean');
        if (['assistant', 'system', 'user', 'function'].includes(type) === false) {
            throw new Error(`Invalid type: ${type}`);
        }
        const message = match(type)
            .with('system', (type) => ({
            type,
            message: outputValue,
            isCacheBreakpoint,
        }))
            .with('user', (type) => ({
            type,
            message: outputValue,
            isCacheBreakpoint,
        }))
            .with('assistant', (type) => {
            let functionCall = this.data.enableFunctionCall
                ? coerceTypeOptional(inputs['function-call'], 'object')
                : undefined;
            // If no name is specified, ignore the function call
            if (!functionCall?.name || !functionCall?.arguments) {
                functionCall = undefined;
            }
            // GPT is weird - the arguments should be a stringified JSON object https://platform.openai.com/docs/api-reference/chat/create
            if (functionCall?.arguments && typeof functionCall.arguments !== 'string') {
                functionCall.arguments = JSON.stringify(functionCall.arguments);
            }
            return {
                type,
                message: outputValue,
                function_call: functionCall,
                function_calls: functionCall ? [functionCall] : undefined,
                isCacheBreakpoint,
            };
        })
            .with('function', (type) => ({
            type,
            message: outputValue,
            name: getInputOrData(this.data, inputs, 'name', 'string'),
            isCacheBreakpoint,
        }))
            .otherwise(() => {
            throw new Error(`Invalid chat-message type: ${type}`);
        });
        const outputs = {
            ['output']: {
                type: 'chat-message',
                value: message,
            },
        };
        if (this.chartNode.data.computeTokenCount) {
            const tokenCount = await context.tokenizer.getTokenCountForMessages([message], undefined, {
                node: this.chartNode,
            });
            outputs['tokenCount'] = {
                type: 'number',
                value: tokenCount,
            };
        }
        return outputs;
    }
}
export const promptNode = nodeDefinition(PromptNodeImpl, 'Prompt');
const typeDisplay = {
    assistant: 'Assistant',
    system: 'System',
    user: 'User',
    function: 'Function',
};
