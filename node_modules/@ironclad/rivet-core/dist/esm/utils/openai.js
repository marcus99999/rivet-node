import { orderBy } from 'lodash-es';
import { DEFAULT_CHAT_NODE_TIMEOUT } from './defaults.js';
import fetchEventSource from './fetchEventSource.js';
export const openaiModels = {
    'gpt-4': {
        maxTokens: 8192,
        cost: {
            prompt: 0.03,
            completion: 0.06,
        },
        displayName: 'GPT-4',
    },
    'gpt-4-32k': {
        maxTokens: 32768,
        cost: {
            prompt: 0.06,
            completion: 0.12,
        },
        displayName: 'GPT-4 32k',
    },
    'gpt-4-0613': {
        maxTokens: 8192,
        cost: {
            prompt: 0.03,
            completion: 0.06,
        },
        displayName: 'GPT-4 (v0613)',
    },
    'gpt-4-32k-0613': {
        maxTokens: 32768,
        cost: {
            prompt: 0.06,
            completion: 0.12,
        },
        displayName: 'GPT-4 32k (v0613)',
    },
    'gpt-4-0314': {
        maxTokens: 8192,
        cost: {
            prompt: 0.03,
            completion: 0.06,
        },
        displayName: 'GPT-4 (v0314)',
    },
    'gpt-4-32k-0314': {
        maxTokens: 32768,
        cost: {
            prompt: 0.06,
            completion: 0.12,
        },
        displayName: 'GPT-4 32k (v0314)',
    },
    'gpt-4-1106-preview': {
        maxTokens: 128000,
        cost: {
            prompt: 0.01,
            completion: 0.03,
        },
        displayName: 'GPT-4 Turbo 128K (1106 Preview)',
    },
    'gpt-4-turbo': {
        maxTokens: 128000,
        cost: {
            prompt: 0.01,
            completion: 0.03,
        },
        displayName: 'GPT-4 Turbo 128K with Vision',
    },
    'gpt-4-vision-preview': {
        maxTokens: 128000,
        cost: {
            prompt: 0.01,
            completion: 0.03,
        },
        displayName: 'GPT-4 Vision (Preview)',
    },
    'gpt-4o': {
        maxTokens: 128000,
        cost: {
            prompt: 0.005,
            completion: 0.015,
        },
        displayName: 'GPT-4o',
    },
    'gpt-4o-mini': {
        maxTokens: 128000,
        cost: {
            prompt: 0.00015,
            completion: 0.00075,
        },
        displayName: 'GPT-4o mini',
    },
    'gpt-4o-mini-2024-07-18': {
        maxTokens: 128000,
        cost: {
            prompt: 0.00015,
            completion: 0.00075,
        },
        displayName: 'GPT-4o mini (2024-07-18)',
    },
    o1: {
        maxTokens: 128000,
        cost: {
            prompt: 0.015,
            completion: 0.6,
        },
        displayName: 'o1',
    },
    'o1-preview': {
        maxTokens: 128000,
        cost: {
            prompt: 0.015,
            completion: 0.06,
        },
        displayName: 'o1-preview',
    },
    'o1-preview-2024-09-12': {
        maxTokens: 128000,
        cost: {
            prompt: 0.015,
            completion: 0.06,
        },
        displayName: 'o1-preview (2024-09-12)',
    },
    'o1-mini': {
        maxTokens: 128000,
        cost: {
            prompt: 0.0011,
            completion: 0.0044,
        },
        displayName: 'o1-mini',
    },
    'o1-mini-2024-09-12': {
        maxTokens: 128000,
        cost: {
            prompt: 0.0011,
            completion: 0.0044,
        },
        displayName: 'o1-mini (2024-09-12)',
    },
    'o3-mini': {
        maxTokens: 200000,
        cost: {
            prompt: 0.0011,
            completion: 0.0044,
        },
        displayName: 'o3-mini',
    },
    'o3-mini-2025-01-31': {
        maxTokens: 200000,
        cost: {
            prompt: 0.0011,
            completion: 0.0044,
        },
        displayName: 'o3-mini (2025-01-31)',
    },
    'gpt-4o-audio-preview': {
        maxTokens: 128000,
        cost: {
            prompt: 0.0025,
            completion: 0.01,
            audioPrompt: 0.04,
            audioCompletion: 0.08,
        },
        displayName: 'GPT-4o Audio (Preview)',
    },
    'local-model': {
        maxTokens: Number.MAX_SAFE_INTEGER,
        cost: {
            prompt: 0,
            completion: 0,
        },
        displayName: 'Local Model',
    },
};
export const openAiModelOptions = orderBy(Object.entries(openaiModels).map(([id, { displayName }]) => ({
    value: id,
    label: displayName,
})), 'label');
export class OpenAIError extends Error {
    status;
    responseJson;
    constructor(status, responseJson) {
        super(`OpenAIError: ${status} ${JSON.stringify(responseJson)}`);
        this.status = status;
        this.responseJson = responseJson;
        this.name = 'OpenAIError';
    }
}
export async function chatCompletions({ endpoint, auth, signal, headers, timeout, ...rest }) {
    const abortSignal = signal ?? new AbortController().signal;
    const response = await fetch(endpoint, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${auth.apiKey}`,
            ...(auth.organization ? { 'OpenAI-Organization': auth.organization } : {}),
            ...headers,
        },
        body: JSON.stringify(rest),
        signal: abortSignal,
    });
    return response.json();
}
export async function* streamChatCompletions({ endpoint, auth, signal, headers, timeout, ...rest }) {
    const abortSignal = signal ?? new AbortController().signal;
    const response = await fetchEventSource(endpoint, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${auth.apiKey}`,
            ...(auth.organization ? { 'OpenAI-Organization': auth.organization } : {}),
            ...headers,
        },
        body: JSON.stringify({
            ...rest,
            stream: true,
            stream_options: {
                include_usage: true,
            },
        }),
        signal: abortSignal,
    }, timeout ?? DEFAULT_CHAT_NODE_TIMEOUT);
    let hadChunks = false;
    for await (const chunk of response.events()) {
        hadChunks = true;
        if (chunk === '[DONE]' || abortSignal?.aborted) {
            return;
        }
        let data;
        try {
            data = JSON.parse(chunk);
        }
        catch (err) {
            console.error('JSON parse failed on chunk: ', chunk);
            throw err;
        }
        yield data;
    }
    if (!hadChunks) {
        const responseJson = await response.json();
        throw new OpenAIError(response.status, responseJson);
    }
}
export const openAIFilePurposeOptions = [
    { value: 'fine-tune', label: 'Fine-tuning' },
    { value: 'fine-tune-results', label: 'Fine-tuning Results' },
    { value: 'assistants', label: 'Assistants' },
    { value: 'assistants_output', label: 'Assistants Output' },
];
export const openAIFileUploadPurposeOptions = [
    { value: 'fine-tune', label: 'Fine-tuning' },
    { value: 'assistants', label: 'Assistants' },
    { value: 'assistants_output', label: 'Assistants Output' },
];
