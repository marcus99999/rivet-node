import { type ChatMessage, type GptFunction } from '../index.js';
import type { Tokenizer, TokenizerCallInfo } from './Tokenizer.js';
import Emittery from 'emittery';
export declare class GptTokenizerTokenizer implements Tokenizer {
    emitter: Emittery<{
        error: Error;
    }, {
        error: Error;
    } & import("emittery").OmnipresentEventData, never>;
    on(event: 'error', listener: (err: Error) => void): void;
    getTokenCountForString(input: string, _info: TokenizerCallInfo): Promise<number>;
    getTokenCountForMessages(messages: ChatMessage[], functions: GptFunction[] | undefined, _info: TokenizerCallInfo): Promise<number>;
    /**
     * Converts GPT Functions to approximate TypeScript-style string.
     * Per thread: https://community.openai.com/t/how-to-calculate-the-tokens-when-using-function-call/266573/24
     * We should consider using a different library, eg. https://github.com/hmarr/openai-chat-tokens
     * @param functions
     */
    private convertGptFunctionsToPromptString;
}
