import { type ChatMessage } from '../DataValue.js';
import type { EditorDefinition } from '../EditorDefinition.js';
import type { ChartNode, NodeInputDefinition } from '../NodeBase.js';
import type { ChatNode } from './ChatNode.js';
import type { Inputs, Outputs } from '../GraphProcessor.js';
import type { InternalProcessContext } from '../ProcessContext.js';
export type ChatNodeConfigData = {
    model: string;
    temperature: number;
    useTopP: boolean;
    top_p?: number;
    maxTokens: number;
    stop?: string;
    presencePenalty?: number;
    frequencyPenalty?: number;
    enableFunctionUse?: boolean;
    user?: string;
    numberOfChoices?: number;
    endpoint?: string;
    overrideModel?: string;
    overrideMaxTokens?: number;
    headers?: {
        key: string;
        value: string;
    }[];
    seed?: number;
    toolChoice?: 'none' | 'auto' | 'function';
    toolChoiceFunction?: string;
    responseFormat?: '' | 'text' | 'json' | 'json_schema';
    parallelFunctionCalling?: boolean;
    additionalParameters?: {
        key: string;
        value: string;
    }[];
    responseSchemaName?: string;
    useServerTokenCalculation?: boolean;
    outputUsage?: boolean;
    usePredictedOutput?: boolean;
    reasoningEffort?: 'low' | 'medium' | 'high';
    modalitiesIncludeText?: boolean;
    modalitiesIncludeAudio?: boolean;
    audioVoice?: string;
    audioFormat?: 'wav' | 'mp3' | 'flac' | 'opus' | 'pcm16';
};
export type ChatNodeData = ChatNodeConfigData & {
    useModelInput: boolean;
    useTemperatureInput: boolean;
    useTopPInput: boolean;
    useTopP: boolean;
    useUseTopPInput: boolean;
    useMaxTokensInput: boolean;
    useStop: boolean;
    useStopInput: boolean;
    usePresencePenaltyInput: boolean;
    useFrequencyPenaltyInput: boolean;
    useUserInput?: boolean;
    useNumberOfChoicesInput?: boolean;
    useEndpointInput?: boolean;
    useHeadersInput?: boolean;
    useSeedInput?: boolean;
    useToolChoiceInput?: boolean;
    useToolChoiceFunctionInput?: boolean;
    useResponseFormatInput?: boolean;
    useAdditionalParametersInput?: boolean;
    useResponseSchemaNameInput?: boolean;
    useAudioVoiceInput?: boolean;
    useAudioFormatInput?: boolean;
    useReasoningEffortInput?: boolean;
    /** Given the same set of inputs, return the same output without hitting GPT */
    cache: boolean;
    useAsGraphPartialOutput?: boolean;
};
export declare const ChatNodeBase: {
    defaultData: () => ChatNodeData;
    getInputDefinitions: (data: ChatNodeData) => NodeInputDefinition[];
    getOutputDefinitions: (data: ChatNodeData) => NodeInputDefinition[];
    getEditors: () => EditorDefinition<ChatNode>[];
    getBody: (data: ChatNodeData) => string | undefined;
    process: (data: ChatNodeData, node: ChartNode, inputs: Inputs, context: InternalProcessContext) => Promise<Outputs>;
};
export declare function getChatNodeMessages(inputs: Inputs): {
    messages: ChatMessage[];
    systemPrompt: import("../DataValue.js").DataValue | undefined;
};
export declare function getCostForTokens(tokenCount: number, type: 'prompt' | 'completion', costPerThousand: number): number;
