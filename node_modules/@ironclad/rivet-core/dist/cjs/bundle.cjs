"use strict";
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  AbortGraphNodeImpl: () => AbortGraphNodeImpl,
  AppendToDatasetNodeImpl: () => AppendToDatasetNodeImpl,
  ArrayNodeImpl: () => ArrayNodeImpl,
  AssembleMessageNodeImpl: () => AssembleMessageNodeImpl,
  AssemblePromptNodeImpl: () => AssemblePromptNodeImpl,
  AudioNodeImpl: () => AudioNodeImpl,
  BooleanNodeImpl: () => BooleanNodeImpl,
  BrowserNativeApi: () => BrowserNativeApi,
  CallGraphNodeImpl: () => CallGraphNodeImpl,
  ChatLoopNodeImpl: () => ChatLoopNodeImpl,
  ChatNodeBase: () => ChatNodeBase,
  ChatNodeImpl: () => ChatNodeImpl,
  ChunkNodeImpl: () => ChunkNodeImpl,
  CoalesceNodeImpl: () => CoalesceNodeImpl,
  CodeNodeImpl: () => CodeNodeImpl,
  CommentNodeImpl: () => CommentNodeImpl,
  CompareNodeImpl: () => CompareNodeImpl,
  ContextNodeImpl: () => ContextNodeImpl,
  CreateDatasetNodeImpl: () => CreateDatasetNodeImpl,
  CronNodeImpl: () => CronNodeImpl,
  DEFAULT_CHAT_ENDPOINT: () => DEFAULT_CHAT_ENDPOINT,
  DEFAULT_CHAT_NODE_TIMEOUT: () => DEFAULT_CHAT_NODE_TIMEOUT,
  DatasetNearestNeighborsNodeImpl: () => DatasetNearestNeighborsNodeImpl,
  DelayNodeImpl: () => DelayNodeImpl,
  DelegateFunctionCallNodeImpl: () => DelegateFunctionCallNodeImpl,
  DestructureNodeImpl: () => DestructureNodeImpl,
  DocumentNodeImpl: () => DocumentNodeImpl,
  EvaluateNodeImpl: () => EvaluateNodeImpl,
  ExecutionRecorder: () => ExecutionRecorder,
  ExternalCallNodeImpl: () => ExternalCallNodeImpl,
  ExtractJsonNodeImpl: () => ExtractJsonNodeImpl,
  ExtractMarkdownCodeBlocksNodeImpl: () => ExtractMarkdownCodeBlocksNodeImpl,
  ExtractObjectPathNodeImpl: () => ExtractObjectPathNodeImpl,
  ExtractRegexNodeImpl: () => ExtractRegexNodeImpl,
  ExtractYamlNodeImpl: () => ExtractYamlNodeImpl,
  FilterNodeImpl: () => FilterNodeImpl,
  GetAllDatasetsNodeImpl: () => GetAllDatasetsNodeImpl,
  GetDatasetRowNodeImpl: () => GetDatasetRowNodeImpl,
  GetEmbeddingNodeImpl: () => GetEmbeddingNodeImpl,
  GetGlobalNodeImpl: () => GetGlobalNodeImpl,
  GptFunctionNodeImpl: () => GptFunctionNodeImpl,
  GraphInputNodeImpl: () => GraphInputNodeImpl,
  GraphOutputNodeImpl: () => GraphOutputNodeImpl,
  GraphProcessor: () => GraphProcessor,
  GraphReferenceNodeImpl: () => GraphReferenceNodeImpl,
  HashNodeImpl: () => HashNodeImpl,
  HttpCallNodeImpl: () => HttpCallNodeImpl,
  IF_PORT: () => IF_PORT,
  IfElseNodeImpl: () => IfElseNodeImpl,
  IfNodeImpl: () => IfNodeImpl,
  ImageNodeImpl: () => ImageNodeImpl,
  InMemoryDatasetProvider: () => InMemoryDatasetProvider,
  JoinNodeImpl: () => JoinNodeImpl,
  ListGraphsNodeImpl: () => ListGraphsNodeImpl,
  LoadDatasetNodeImpl: () => LoadDatasetNodeImpl,
  LoopControllerNodeImpl: () => LoopControllerNodeImpl,
  LoopUntilNodeImpl: () => LoopUntilNodeImpl,
  MatchNodeImpl: () => MatchNodeImpl,
  NodeImpl: () => NodeImpl,
  NodeRegistration: () => NodeRegistration,
  NumberNodeImpl: () => NumberNodeImpl,
  ObjectNodeImpl: () => ObjectNodeImpl,
  PassthroughNodeImpl: () => PassthroughNodeImpl,
  PlayAudioNodeImpl: () => PlayAudioNodeImpl,
  PluginNodeImplClass: () => PluginNodeImplClass,
  PopNodeImpl: () => PopNodeImpl,
  PromptNodeImpl: () => PromptNodeImpl,
  RaceInputsNodeImpl: () => RaceInputsNodeImpl,
  RaiseEventNodeImpl: () => RaiseEventNodeImpl,
  RandomNumberNodeImpl: () => RandomNumberNodeImpl,
  ReadAllFilesNodeImpl: () => ReadAllFilesNodeImpl,
  ReadDirectoryNodeImpl: () => ReadDirectoryNodeImpl,
  ReadFileNodeImpl: () => ReadFileNodeImpl,
  ReplaceDatasetNodeImpl: () => ReplaceDatasetNodeImpl,
  Rivet: () => Rivet,
  SetGlobalNodeImpl: () => SetGlobalNodeImpl,
  ShuffleNodeImpl: () => ShuffleNodeImpl,
  SliceNodeImpl: () => SliceNodeImpl,
  SplitNodeImpl: () => SplitNodeImpl,
  SubGraphNodeImpl: () => SubGraphNodeImpl,
  TextNodeImpl: () => TextNodeImpl,
  ToJsonNodeImpl: () => ToJsonNodeImpl,
  ToMarkdownTableNodeImpl: () => ToMarkdownTableNodeImpl,
  ToTreeNodeImpl: () => ToTreeNodeImpl,
  ToYamlNodeImpl: () => ToYamlNodeImpl,
  TrimChatMessagesNodeImpl: () => TrimChatMessagesNodeImpl,
  UrlReferenceNodeImpl: () => UrlReferenceNodeImpl,
  UserInputNodeImpl: () => UserInputNodeImpl,
  VectorNearestNeighborsNodeImpl: () => VectorNearestNeighborsNodeImpl,
  VectorStoreNodeImpl: () => VectorStoreNodeImpl,
  WaitForEventNodeImpl: () => WaitForEventNodeImpl,
  abortGraphNode: () => abortGraphNode,
  addWarning: () => addWarning,
  anthropicPlugin: () => anthropic_default,
  appendToDatasetNode: () => appendToDatasetNode,
  arrayNode: () => arrayNode,
  arrayTypeToScalarType: () => arrayTypeToScalarType,
  arrayizeDataValue: () => arrayizeDataValue,
  assembleMessageNode: () => assembleMessageNode,
  assemblePromptNode: () => assemblePromptNode,
  assemblyAiPlugin: () => assemblyAi_default,
  assertBaseDir: () => assertBaseDir,
  audioNode: () => audioNode,
  autoevalsPlugin: () => autoevals_default,
  base64ToUint8Array: () => base64ToUint8Array,
  baseDirs: () => baseDirs,
  booleanNode: () => booleanNode,
  callGraphNode: () => callGraphNode,
  canBeCoerced: () => canBeCoerced,
  canBeCoercedAny: () => canBeCoercedAny,
  chatLoopNode: () => chatLoopNode,
  chatNode: () => chatNode,
  chunkNode: () => chunkNode,
  chunkStringByTokenCount: () => chunkStringByTokenCount,
  cleanHeaders: () => cleanHeaders,
  coalesceNode: () => coalesceNode,
  codeNode: () => codeNode,
  coerceType: () => coerceType,
  coerceTypeOptional: () => coerceTypeOptional,
  commentNode: () => commentNode,
  compareNode: () => compareNode,
  contextNode: () => contextNode,
  coreCreateProcessor: () => coreCreateProcessor,
  coreRunGraph: () => coreRunGraph,
  createDatasetNode: () => createDatasetNode,
  cronNode: () => cronNode,
  dataTypeDisplayNames: () => dataTypeDisplayNames,
  dataTypes: () => dataTypes,
  datasetNearestNeighborsNode: () => datasetNearestNeighborsNode,
  dedent: () => import_ts_dedent.dedent,
  delayNode: () => delayNode,
  delegateFunctionCallNode: () => delegateFunctionCallNode,
  deserializeDatasets: () => deserializeDatasets,
  deserializeGraph: () => deserializeGraph,
  deserializeProject: () => deserializeProject,
  destructureNode: () => destructureNode,
  documentNode: () => documentNode,
  doubleCheckProject: () => doubleCheckProject,
  emptyNodeGraph: () => emptyNodeGraph,
  evaluateNode: () => evaluateNode,
  expectType: () => expectType,
  expectTypeOptional: () => expectTypeOptional,
  externalCallNode: () => externalCallNode,
  extractJsonNode: () => extractJsonNode,
  extractMarkdownCodeBlocksNode: () => extractMarkdownCodeBlocksNode,
  extractObjectPathNode: () => extractObjectPathNode,
  extractRegexNode: () => extractRegexNode,
  extractYamlNode: () => extractYamlNode,
  filterNode: () => filterNode,
  functionTypeToScalarType: () => functionTypeToScalarType,
  gentracePlugin: () => gentrace_default,
  getAllDatasetsNode: () => getAllDatasetsNode,
  getChatNodeMessages: () => getChatNodeMessages,
  getCostForTokens: () => getCostForTokens,
  getDatasetRowNode: () => getDatasetRowNode,
  getDefaultValue: () => getDefaultValue,
  getEmbeddingNode: () => getEmbeddingNode,
  getError: () => getError,
  getGlobalNode: () => getGlobalNode,
  getInputOrData: () => getInputOrData,
  getIntegration: () => getIntegration,
  getPluginConfig: () => getPluginConfig,
  getProcessorEvents: () => getProcessorEvents,
  getProcessorSSEStream: () => getProcessorSSEStream,
  getScalarTypeOf: () => getScalarTypeOf,
  getSingleNodeStream: () => getSingleNodeStream,
  getWarnings: () => getWarnings,
  globalRivetNodeRegistry: () => globalRivetNodeRegistry,
  googlePlugin: () => googlePlugin,
  gptFunctionNode: () => gptFunctionNode,
  graphInputNode: () => graphInputNode,
  graphOutputNode: () => graphOutputNode,
  graphReferenceNode: () => graphReferenceNode,
  handleEscapeCharacters: () => handleEscapeCharacters,
  hashNode: () => hashNode,
  httpCallNode: () => httpCallNode,
  huggingFacePlugin: () => huggingFacePlugin,
  ifElseNode: () => ifElseNode,
  ifNode: () => ifNode,
  imageNode: () => imageNode,
  inferType: () => inferType,
  isArrayDataType: () => isArrayDataType,
  isArrayDataValue: () => isArrayDataValue,
  isBuiltInInputDefinition: () => isBuiltInInputDefinition,
  isDataTypeAccepted: () => isDataTypeAccepted,
  isDataTypeCompatible: () => isDataTypeCompatible,
  isFunctionDataType: () => isFunctionDataType,
  isFunctionDataValue: () => isFunctionDataValue,
  isNotFunctionDataValue: () => isNotFunctionDataValue,
  isScalarDataType: () => isScalarDataType,
  isScalarDataValue: () => isScalarDataValue,
  joinNode: () => joinNode,
  listGraphsNode: () => listGraphsNode,
  loadDatasetNode: () => loadDatasetNode,
  loadProjectAndAttachedDataFromString: () => loadProjectAndAttachedDataFromString,
  loadProjectFromString: () => loadProjectFromString,
  loopControllerNode: () => loopControllerNode,
  loopUntilNode: () => loopUntilNode,
  looseDataValueToDataValue: () => looseDataValueToDataValue,
  looseDataValuesToDataValues: () => looseDataValuesToDataValues,
  matchNode: () => matchNode,
  newId: () => newId,
  nodeDefinition: () => nodeDefinition,
  numberNode: () => numberNode,
  objectNode: () => objectNode,
  openai: () => openai_exports,
  passthroughNode: () => passthroughNode,
  pineconePlugin: () => pinecone_default,
  playAudioNode: () => playAudioNode,
  pluginNodeDefinition: () => pluginNodeDefinition,
  plugins: () => plugins,
  popNode: () => popNode,
  promptNode: () => promptNode,
  raceInputsNode: () => raceInputsNode,
  raiseEventNode: () => raiseEventNode,
  randomNumberNode: () => randomNumberNode,
  readAllFilesNode: () => readAllFilesNode,
  readDirectoryNode: () => readDirectoryNode,
  readFileNode: () => readFileNode,
  registerBuiltInNodes: () => registerBuiltInNodes,
  registerIntegration: () => registerIntegration,
  replaceDatasetNode: () => replaceDatasetNode,
  resetGlobalRivetNodeRegistry: () => resetGlobalRivetNodeRegistry,
  scalarDefaults: () => scalarDefaults,
  scalarTypes: () => scalarTypes,
  serializeDatasets: () => serializeDatasets,
  serializeGraph: () => serializeGraph,
  serializeProject: () => serializeProject,
  setGlobalNode: () => setGlobalNode,
  shuffleNode: () => shuffleNode,
  sliceNode: () => sliceNode,
  splitNode: () => splitNode,
  subGraphNode: () => subGraphNode,
  textNode: () => textNode,
  toJsonNode: () => toJsonNode,
  toMarkdownTableNode: () => toMarkdownTableNode,
  toTreeNode: () => toTreeNode,
  toYamlNode: () => toYamlNode,
  trimChatMessagesNode: () => trimChatMessagesNode,
  uint8ArrayToBase64: () => uint8ArrayToBase64,
  unwrapDataValue: () => unwrapDataValue,
  urlReferenceNode: () => urlReferenceNode,
  userInputNode: () => userInputNode,
  vectorNearestNeighborsNode: () => vectorNearestNeighborsNode,
  vectorStoreNode: () => vectorStoreNode,
  waitForEventNode: () => waitForEventNode,
  yamlProblem: () => yamlProblem
});
module.exports = __toCommonJS(src_exports);

// src/utils/coerceType.ts
var import_ts_pattern = require("ts-pattern");

// src/utils/genericUtilFunctions.ts
function isNotNull(value) {
  return value != null;
}
var exhaustiveTuple = () => (
  // impressive inference from TS: it knows when the condition and the true branch can't both be satisfied
  (...x) => x
);

// src/model/DataValue.ts
var dataTypes = exhaustiveTuple()(
  "any",
  "any[]",
  "boolean",
  "boolean[]",
  "string",
  "string[]",
  "number",
  "number[]",
  "date",
  "date[]",
  "time",
  "time[]",
  "datetime",
  "datetime[]",
  "chat-message",
  "chat-message[]",
  "control-flow-excluded",
  "control-flow-excluded[]",
  "object",
  "object[]",
  "fn<string>",
  "fn<number>",
  "fn<boolean>",
  "fn<date>",
  "fn<time>",
  "fn<datetime>",
  "fn<any>",
  "fn<object>",
  "fn<chat-message>",
  "fn<control-flow-excluded>",
  "fn<string[]>",
  "fn<number[]>",
  "fn<boolean[]>",
  "fn<date[]>",
  "fn<time[]>",
  "fn<datetime[]>",
  "fn<any[]>",
  "fn<object[]>",
  "fn<chat-message[]>",
  "fn<control-flow-excluded[]>",
  "gpt-function",
  "gpt-function[]",
  "fn<gpt-function[]>",
  "fn<gpt-function>",
  "vector",
  "vector[]",
  "fn<vector>",
  "fn<vector[]>",
  "image",
  "image[]",
  "fn<image>",
  "fn<image[]>",
  "binary",
  "binary[]",
  "fn<binary>",
  "fn<binary[]>",
  "audio",
  "audio[]",
  "fn<audio>",
  "fn<audio[]>",
  "graph-reference",
  "graph-reference[]",
  "fn<graph-reference>",
  "fn<graph-reference[]>",
  "document",
  "document[]",
  "fn<document>",
  "fn<document[]>"
);
var scalarTypes = exhaustiveTuple()(
  "any",
  "boolean",
  "string",
  "number",
  "date",
  "time",
  "datetime",
  "chat-message",
  "control-flow-excluded",
  "object",
  "gpt-function",
  "vector",
  "image",
  "binary",
  "audio",
  "graph-reference",
  "document"
);
var dataTypeDisplayNames = {
  any: "Any",
  "any[]": "Any Array",
  boolean: "Boolean",
  "boolean[]": "Boolean Array",
  string: "String",
  "string[]": "String Array",
  number: "Number",
  "number[]": "Number Array",
  date: "Date",
  "date[]": "Date Array",
  time: "Time",
  "time[]": "Time Array",
  datetime: "DateTime",
  "datetime[]": "DateTime Array",
  "chat-message": "ChatMessage",
  "chat-message[]": "ChatMessage Array",
  "control-flow-excluded": "ControlFlowExcluded",
  "control-flow-excluded[]": "ControlFlowExcluded Array",
  object: "Object",
  "object[]": "Object Array",
  "gpt-function": "GPT Function",
  "gpt-function[]": "GPT Function Array",
  "fn<string>": "Function<String>",
  "fn<number>": "Function<Number>",
  "fn<boolean>": "Function<Boolean>",
  "fn<date>": "Function<Date>",
  "fn<time>": "Function<Time>",
  "fn<datetime>": "Function<DateTime>",
  "fn<any>": "Function<Any>",
  "fn<object>": "Function<Object>",
  "fn<chat-message>": "Function<ChatMessage>",
  "fn<control-flow-excluded>": "Function<ControlFlowExcluded>",
  "fn<gpt-function>": "Function<GPT Function>",
  "fn<string[]>": "Function<String Array>",
  "fn<number[]>": "Function<Number Array>",
  "fn<boolean[]>": "Function<Boolean Array>",
  "fn<date[]>": "Function<Date Array>",
  "fn<time[]>": "Function<Time Array>",
  "fn<datetime[]>": "Function<DateTime Array>",
  "fn<any[]>": "Function<Any Array>",
  "fn<object[]>": "Function<Object Array>",
  "fn<chat-message[]>": "Function<ChatMessage Array>",
  "fn<control-flow-excluded[]>": "Function<ControlFlowExcluded Array>",
  "fn<gpt-function[]>": "Function<GPT Function Array>",
  vector: "Vector",
  "vector[]": "Vector Array",
  "fn<vector>": "Function<Vector>",
  "fn<vector[]>": "Function<Vector Array>",
  image: "Image",
  "image[]": "Image Array",
  "fn<image>": "Function<Image>",
  "fn<image[]>": "Function<Image Array>",
  binary: "Binary",
  "binary[]": "Binary Array",
  "fn<binary>": "Function<Binary>",
  "fn<binary[]>": "Function<Binary Array>",
  audio: "Audio",
  "audio[]": "Audio Array",
  "fn<audio>": "Function<Audio>",
  "fn<audio[]>": "Function<Audio Array>",
  "graph-reference": "Graph Reference",
  "graph-reference[]": "Graph Reference Array",
  "fn<graph-reference>": "Function<Graph Reference>",
  "fn<graph-reference[]>": "Function<Graph Reference Array>",
  document: "Document",
  "document[]": "Document Array",
  "fn<document>": "Function<Document>",
  "fn<document[]>": "Function<Document Array>"
};
function isScalarDataValue(value) {
  if (!value) {
    return false;
  }
  return !isArrayDataType(value.type) && !isFunctionDataType(value.type);
}
function isScalarDataType(type) {
  return !isArrayDataType(type) && !isFunctionDataType(type);
}
function isArrayDataValue(value) {
  if (!value) {
    return false;
  }
  return isArrayDataType(value.type) || (value.type === "any" || value.type === "object") && Array.isArray(value.value);
}
function isArrayDataType(type) {
  return type.endsWith("[]");
}
function isFunctionDataType(type) {
  return type.startsWith("fn<");
}
function isFunctionDataValue(value) {
  if (!value) {
    return false;
  }
  return isFunctionDataType(value.type) || value.type === "any" && typeof value.value === "function";
}
function isNotFunctionDataValue(value) {
  return !isFunctionDataValue(value);
}
function functionTypeToScalarType(functionType) {
  return functionType.slice(3, -1);
}
function arrayTypeToScalarType(arrayType) {
  return arrayType.slice(0, -2);
}
function getScalarTypeOf(type) {
  if (isArrayDataType(type)) {
    return arrayTypeToScalarType(type);
  }
  if (isFunctionDataType(type)) {
    return functionTypeToScalarType(type);
  }
  return type;
}
function unwrapDataValue(value) {
  if (!value) {
    return void 0;
  }
  if (isFunctionDataValue(value)) {
    return { type: functionTypeToScalarType(value.type), value: value.value() };
  }
  return value;
}
var arrayizeDataValue = (value) => {
  const isArray = value.type.endsWith("[]") || (value.type === "any" || value.type === "object") && Array.isArray(value.value);
  if (!isArray) {
    return [value];
  }
  const unwrappedType = value.type.endsWith("[]") ? value.type.slice(0, -2) : value.type;
  return value.value.map((v) => ({ type: unwrappedType, value: v }));
};
var scalarDefaults = {
  string: "",
  number: 0,
  boolean: false,
  any: void 0,
  "chat-message": {
    type: "user",
    message: "",
    isCacheBreakpoint: void 0
  },
  "control-flow-excluded": void 0,
  date: (/* @__PURE__ */ new Date()).toISOString(),
  time: (/* @__PURE__ */ new Date()).toISOString(),
  datetime: (/* @__PURE__ */ new Date()).toISOString(),
  object: {},
  "gpt-function": {
    name: "unknown",
    description: "",
    parameters: {},
    namespace: void 0,
    strict: false
  },
  vector: [],
  image: {
    mediaType: "image/jpeg",
    data: new Uint8Array()
  },
  binary: new Uint8Array(),
  audio: { data: new Uint8Array() },
  "graph-reference": { graphId: "", graphName: "" },
  document: {
    mediaType: "text/plain",
    data: new Uint8Array(),
    title: void 0,
    context: void 0,
    enableCitations: false
  }
};
function getDefaultValue(type) {
  if (isArrayDataType(type)) {
    return [];
  }
  if (isFunctionDataType(type)) {
    return () => scalarDefaults[getScalarTypeOf(type)];
  }
  return scalarDefaults[getScalarTypeOf(type)];
}

// src/utils/expectType.ts
function expectType(value, type) {
  if (isArrayDataType(type) && isScalarDataValue(value) && getScalarTypeOf(type) === value.type) {
    return [value.value];
  }
  if (type === "any" || type === "any[]" || (value == null ? void 0 : value.type) === "any" || (value == null ? void 0 : value.type) === "any[]") {
    return value == null ? void 0 : value.value;
  }
  if (isFunctionDataType(type) && (value == null ? void 0 : value.type) === `fn<${type}>` || type === "fn<any>") {
    return () => value.value;
  }
  if ((value == null ? void 0 : value.type) !== type) {
    throw new Error(`Expected value of type ${type} but got ${value == null ? void 0 : value.type}`);
  }
  return value.value;
}
function expectTypeOptional(value, type) {
  if (value === void 0) {
    return void 0;
  }
  if (isArrayDataType(type) && isScalarDataValue(value) && getScalarTypeOf(type) === value.type) {
    return [value.value];
  }
  if (isFunctionDataType(value.type) && value.type === `fn<${type}>`) {
    value = unwrapDataValue(value);
  }
  if (value.type !== type) {
    throw new Error(`Expected value of type ${type} but got ${value == null ? void 0 : value.type}`);
  }
  return value.value;
}

// src/utils/coerceType.ts
function coerceTypeOptional(wrapped, type) {
  const value = wrapped ? unwrapDataValue(wrapped) : void 0;
  if (isArrayDataType(type) && !isArrayDataValue(value)) {
    const coerced = coerceTypeOptional(value, getScalarTypeOf(type));
    if (coerced === void 0) {
      return void 0;
    }
    return [coerced];
  }
  if (isArrayDataType(type) && isArrayDataValue(value) && getScalarTypeOf(type) !== getScalarTypeOf(value.type)) {
    return value.value.map(
      (v) => coerceTypeOptional({ type: getScalarTypeOf(value.type), value: v }, getScalarTypeOf(type))
    );
  }
  const result = (0, import_ts_pattern.match)(type).with("string", () => coerceToString(value)).with("boolean", () => coerceToBoolean(value)).with("chat-message", () => coerceToChatMessage(value)).with("number", () => coerceToNumber(value)).with("object", () => coerceToObject(value)).with("binary", () => coerceToBinary(value)).with("graph-reference", () => coerceToGraphReference(value)).otherwise(() => {
    if (!value) {
      return value;
    }
    if (getScalarTypeOf(value.type) === "any" || getScalarTypeOf(type) === "any") {
      return value.value;
    }
    return expectTypeOptional(value, type);
  });
  return result;
}
function coerceType(value, type) {
  const result = coerceTypeOptional(value, type);
  if (result === void 0) {
    throw new Error(`Expected value of type ${type} but got undefined`);
  }
  return result;
}
function inferType(value) {
  if (value === void 0) {
    return { type: "any", value: void 0 };
  }
  if (value === null) {
    return { type: "any", value: null };
  }
  if (typeof value === "function") {
    return { type: "fn<any>", value };
  }
  if (typeof value === "string") {
    return { type: "string", value };
  }
  if (typeof value === "boolean") {
    return { type: "boolean", value };
  }
  if (typeof value === "number") {
    return { type: "number", value };
  }
  if (value instanceof Date) {
    return { type: "datetime", value: value.toISOString() };
  }
  if (Array.isArray(value)) {
    if (value.length === 0) {
      return { type: "any[]", value: [] };
    }
    const inferredType = inferType(value[0]);
    return { type: inferredType.type + "[]", value };
  }
  if (typeof value === "object") {
    return { type: "object", value };
  }
  throw new Error(`Cannot infer type of value: ${value}`);
}
function coerceToString(value) {
  if (!value) {
    return "";
  }
  if (isArrayDataValue(value)) {
    return value.value.map((v) => coerceTypeOptional({ type: getScalarTypeOf(value.type), value: v }, "string")).join("\n");
  }
  if (value.type === "string") {
    return value.value;
  }
  if (value.type === "boolean") {
    return value.value.toString();
  }
  if (value.type === "number") {
    return value.value.toString();
  }
  if (value.type === "date") {
    return value.value;
  }
  if (value.type === "time") {
    return value.value;
  }
  if (value.type === "datetime") {
    return value.value;
  }
  if (value.type === "chat-message") {
    const messageParts = Array.isArray(value.value.message) ? value.value.message : [value.value.message];
    const singleString = messageParts.map((part) => {
      if (typeof part === "string") {
        return part;
      }
      return part.type === "url" ? `(Image: ${part.url})` : "(Image)";
    }).join("\n\n");
    return singleString;
  }
  if (value.value === void 0) {
    return void 0;
  }
  if (value.value === null) {
    return void 0;
  }
  if (typeof value.value === "object" && !Array.isArray(value.value)) {
    return JSON.stringify(value.value);
  }
  if (value.type === "any" || value.type === "object") {
    const inferred = inferType(value.value);
    return coerceTypeOptional(inferred, "string");
  }
  return JSON.stringify(value.value);
}
function coerceToChatMessage(value) {
  var _a;
  const chatMessage = coerceToChatMessageRaw(value);
  if ((chatMessage == null ? void 0 : chatMessage.type) === "assistant") {
    if (((_a = chatMessage.function_call) == null ? void 0 : _a.arguments) && typeof chatMessage.function_call.arguments !== "string") {
      chatMessage.function_call.arguments = JSON.stringify(chatMessage.function_call.arguments);
    }
  }
  return chatMessage;
}
function coerceToChatMessageRaw(value) {
  if (!value || value.value == null) {
    return void 0;
  }
  if (value.type === "chat-message") {
    return value.value;
  }
  if (value.type === "string") {
    return { type: "user", message: value.value };
  }
  if (value.type === "object" && "type" in value.value && "message" in value.value && typeof value.value.type === "string" && typeof value.value.message === "string") {
    return value.value;
  }
  if (value.type === "any") {
    const inferred = inferType(value.value);
    return coerceTypeOptional(inferred, "chat-message");
  }
}
function coerceToBoolean(value) {
  if (!value || !value.value) {
    return false;
  }
  if (isArrayDataValue(value)) {
    return value.value.map((v) => coerceTypeOptional({ type: value.type.replace("[]", ""), value: v }, "boolean")).every((v) => v);
  }
  if (value.type === "string") {
    return value.value.length > 0 && value.value !== "false";
  }
  if (value.type === "boolean") {
    return value.value;
  }
  if (value.type === "number") {
    return value.value !== 0;
  }
  if (value.type === "date") {
    return true;
  }
  if (value.type === "time") {
    return true;
  }
  if (value.type === "datetime") {
    return true;
  }
  if (value.type === "chat-message") {
    const hasValue = Array.isArray(value.value.message) && value.value.message.length > 0 || typeof value.value.message === "string" && value.value.message.length > 0 || typeof value.value.message === "object" && "type" in value.value.message && value.value.message.type === "url" && value.value.message.url.length > 0;
    return hasValue;
  }
  return !!value.value;
}
function coerceToNumber(value) {
  if (!value || value.value == null) {
    return void 0;
  }
  if (isArrayDataValue(value)) {
    return void 0;
  }
  if (value.type === "string") {
    return parseFloat(value.value);
  }
  if (value.type === "boolean") {
    return value.value ? 1 : 0;
  }
  if (value.type === "number") {
    return value.value;
  }
  if (value.type === "date") {
    return new Date(value.value).valueOf();
  }
  if (value.type === "time") {
    return new Date(value.value).valueOf();
  }
  if (value.type === "datetime") {
    return new Date(value.value).valueOf();
  }
  if (value.type === "chat-message") {
    if (typeof value.value.message === "string") {
      return parseFloat(value.value.message);
    }
    if (Array.isArray(value.value.message) && value.value.message.length === 1 && typeof value.value.message[0] === "string") {
      return parseFloat(value.value.message[0]);
    }
    return void 0;
  }
  if (value.type === "any" || value.type === "object") {
    const inferred = inferType(value.value);
    return coerceTypeOptional(inferred, "number");
  }
  return void 0;
}
function coerceToObject(value) {
  if (!value || value.value == null) {
    return void 0;
  }
  return value.value;
}
function coerceToBinary(value) {
  if (!value || value.value == null) {
    return void 0;
  }
  if (value.type === "binary") {
    return value.value;
  }
  if (value.type === "string") {
    return new TextEncoder().encode(value.value);
  }
  if (value.type === "boolean") {
    return new TextEncoder().encode(value.value.toString());
  }
  if (value.type === "vector" || value.type === "number[]") {
    return new Uint8Array(value.value);
  }
  if (value.type === "number") {
    return new Uint8Array([value.value]);
  }
  if (value.type === "audio" || value.type === "image" || value.type === "document") {
    return value.value.data;
  }
  return new TextEncoder().encode(JSON.stringify(value.value));
}
function coerceToGraphReference(value) {
  if (!value || value.value == null) {
    return void 0;
  }
  if (value.type === "graph-reference") {
    return value.value;
  }
  if (value.type === "string") {
    return { graphName: value.value, graphId: "" };
  }
  if (value.type === "object" && "graphName" in value.value && "graphId" in value.value) {
    return value.value;
  }
  return void 0;
}
function canBeCoercedAny(from, to) {
  for (const fromType of Array.isArray(from) ? from : [from]) {
    for (const toType of Array.isArray(to) ? to : [to]) {
      if (canBeCoerced(fromType, toType)) {
        return true;
      }
    }
  }
  return false;
}
function canBeCoerced(from, to) {
  if (to === "any" || from === "any") {
    return true;
  }
  if (isArrayDataType(to) && isArrayDataType(from)) {
    return canBeCoerced(getScalarTypeOf(from), getScalarTypeOf(to));
  }
  if (isArrayDataType(to) && !isArrayDataType(from)) {
    return canBeCoerced(from, getScalarTypeOf(to));
  }
  if (isArrayDataType(from) && !isArrayDataType(to)) {
    return to === "string" || to === "object";
  }
  if (to === "gpt-function") {
    return from === "object";
  }
  if (to === "audio" || to === "binary" || to === "image") {
    return false;
  }
  return true;
}

// src/utils/errors.ts
function getError(error) {
  const errorInstance = typeof error === "object" && error instanceof Error ? error : new Error(error != null ? error.toString() : "Unknown error");
  return errorInstance;
}

// src/utils/serialization/serialization.ts
var yaml4 = __toESM(require("yaml"), 1);

// src/utils/serialization/serialization_v3.ts
var import_lodash_es = require("lodash");
var import_safe_stable_stringify = __toESM(require("safe-stable-stringify"), 1);
var yaml = __toESM(require("yaml"), 1);

// src/utils/serialization/serializationUtils.ts
function doubleCheckProject(project) {
  if (!project.metadata || !project.metadata.id || !project.metadata.title || !project.graphs || typeof project.graphs !== "object") {
    throw new Error("Invalid project file");
  }
}
function yamlProblem(err) {
  const { code, message, pos, linePos } = err;
  throw new Error(`YAML error: ${code} ${message} at ${pos} ${linePos}`);
}

// src/utils/serialization/serialization_v3.ts
function projectV3Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Project v3 deserializer requires a string");
  }
  const serializedProject = yaml.parse(data);
  if (serializedProject.version !== 3) {
    throw new Error("Project v3 deserializer requires a version 3 project");
  }
  const project = fromSerializedProject(serializedProject.data);
  doubleCheckProject(project);
  return project;
}
function graphV3Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Graph v3 deserializer requires a string");
  }
  const serializedGraph = yaml.parse(data);
  if (serializedGraph.version !== 3) {
    throw new Error("Graph v3 deserializer requires a version 3 graph");
  }
  return fromSerializedGraph(serializedGraph.data);
}
function fromSerializedProject(serializedProject) {
  return {
    metadata: serializedProject.metadata,
    graphs: (0, import_lodash_es.mapValues)(serializedProject.graphs, (graph) => fromSerializedGraph(graph)),
    plugins: []
  };
}
function fromSerializedGraph(serializedGraph) {
  const allConnections = [];
  const allNodes = [];
  for (const node of Object.values(serializedGraph.nodes)) {
    const [chartNode, connections] = fromSerializedNode(node);
    allNodes.push(chartNode);
    allConnections.push(...connections);
  }
  return {
    metadata: {
      id: serializedGraph.metadata.id,
      name: serializedGraph.metadata.name,
      description: serializedGraph.metadata.description
    },
    nodes: allNodes,
    connections: allConnections
  };
}
function fromSerializedNode(serializedNode) {
  const [x, y, width, zIndex] = serializedNode.visualData.split("/");
  const connections = serializedNode.outgoingConnections.map(
    (serializedConnection) => fromSerializedConnection(serializedConnection, serializedNode)
  );
  return [
    {
      id: serializedNode.id,
      title: serializedNode.title,
      description: serializedNode.description,
      type: serializedNode.type,
      isSplitRun: serializedNode.isSplitRun,
      splitRunMax: serializedNode.splitRunMax,
      visualData: {
        x: parseFloat(x),
        y: parseFloat(y),
        width: width === "null" ? void 0 : parseFloat(width),
        zIndex: zIndex === "null" ? void 0 : parseFloat(zIndex)
      },
      data: serializedNode.data,
      variants: serializedNode.variants
    },
    connections
  ];
}
function fromSerializedConnection(connection, outgoingNode) {
  const [, outputId, , inputNodeId, inputId] = connection.match(/(.+)->"(.+)" (.+)\/(.+)/);
  return {
    outputId,
    outputNodeId: outgoingNode.id,
    inputId,
    inputNodeId
  };
}

// src/utils/serialization/serialization_v4.ts
var import_lodash_es2 = require("lodash");
var import_safe_stable_stringify2 = __toESM(require("safe-stable-stringify"), 1);
var yaml2 = __toESM(require("yaml"), 1);

// src/utils/typeSafety.ts
var entries = (object) => object == null ? [] : Object.entries(object);
function fromEntries(entries_) {
  return Object.fromEntries(entries_);
}
function keys(o) {
  return Object.keys(o);
}
function values(o) {
  return Object.values(o);
}
function mapValues2(o, fn) {
  return Object.fromEntries(Object.entries(o).map(([key, value]) => [key, fn(value)]));
}

// src/utils/serialization/serialization_v4.ts
function projectV4Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Project v4 deserializer requires a string");
  }
  const serializedProject = yaml2.parse(data);
  if (serializedProject.version !== 4) {
    throw new Error("Project v4 deserializer requires a version 4 project");
  }
  const [project, attachedData] = fromSerializedProject2(serializedProject.data);
  doubleCheckProject(project);
  return [project, attachedData];
}
function graphV4Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Graph v4 deserializer requires a string");
  }
  const serializedGraph = yaml2.parse(data);
  if (serializedGraph.version !== 4) {
    throw new Error("Graph v4 deserializer requires a version 4 graph");
  }
  return fromSerializedGraph2(serializedGraph.data);
}
function projectV4Serializer(project, attachedData) {
  const filteredProject = {
    ...project,
    metadata: {
      ...project.metadata,
      path: void 0
    }
  };
  const stabilized = JSON.parse((0, import_safe_stable_stringify2.default)(toSerializedProject(filteredProject, attachedData)));
  const serialized = yaml2.stringify(
    {
      version: 4,
      data: stabilized
    },
    null,
    {
      indent: 2
    }
  );
  return serialized;
}
function graphV4Serializer(graph) {
  const stabilized = JSON.parse((0, import_safe_stable_stringify2.default)(toSerializedGraph(graph)));
  const serialized = yaml2.stringify(
    {
      version: 4,
      data: stabilized
    },
    null,
    {
      indent: 2
    }
  );
  return serialized;
}
function toSerializedProject(project, attachedData) {
  return {
    metadata: project.metadata,
    graphs: (0, import_lodash_es2.mapValues)(project.graphs, (graph) => toSerializedGraph(graph)),
    attachedData,
    plugins: project.plugins ?? []
  };
}
function fromSerializedProject2(serializedProject) {
  return [
    {
      metadata: serializedProject.metadata,
      graphs: (0, import_lodash_es2.mapValues)(serializedProject.graphs, (graph) => fromSerializedGraph2(graph)),
      plugins: serializedProject.plugins ?? []
    },
    serializedProject.attachedData ?? {}
  ];
}
function toSerializedGraph(graph) {
  const graphMetadata = {
    id: graph.metadata.id,
    name: graph.metadata.name,
    description: graph.metadata.description
  };
  if (graph.metadata.attachedData) {
    graphMetadata.attachedData = graph.metadata.attachedData;
  }
  return {
    metadata: graphMetadata,
    nodes: graph.nodes.reduce(
      (acc, node) => ({
        ...acc,
        [getGraphNodeKey(node)]: toSerializedNode(node, graph.nodes, graph.connections)
      }),
      {}
    )
  };
}
function getGraphNodeKey(node) {
  return `[${node.id}]:${node.type} "${node.title}"`;
}
function deserializeGraphNodeKey(key) {
  var _a;
  const { nodeId, type, title } = ((_a = key.match(/^\[(?<nodeId>[^\]]+)\]:(?<type>[^\s]+) "(?<title>.*)"$/)) == null ? void 0 : _a.groups) ?? {};
  if (!nodeId || !type || !title) {
    throw new Error(`Invalid graph node key: ${key}`);
  }
  return [nodeId, type, title];
}
function fromSerializedGraph2(serializedGraph) {
  const allConnections = [];
  const allNodes = [];
  for (const [serializedNodeInfo, node] of entries(serializedGraph.nodes)) {
    const [chartNode, connections] = fromSerializedNode2(node, serializedNodeInfo);
    allNodes.push(chartNode);
    allConnections.push(...connections);
  }
  const metadata = {
    id: serializedGraph.metadata.id,
    name: serializedGraph.metadata.name,
    description: serializedGraph.metadata.description
  };
  if (serializedGraph.metadata.attachedData) {
    metadata.attachedData = serializedGraph.metadata.attachedData;
  }
  return {
    metadata,
    nodes: allNodes,
    connections: allConnections
  };
}
function toSerializedNode(node, allNodes, allConnections) {
  var _a, _b, _c, _d;
  const outgoingConnections = allConnections.filter((connection) => connection.outputNodeId === node.id).map((connection) => toSerializedConnection(connection, allNodes)).sort();
  return {
    description: ((_a = node.description) == null ? void 0 : _a.trim()) ? node.description : void 0,
    visualData: `${node.visualData.x}/${node.visualData.y}/${node.visualData.width ?? "null"}/${node.visualData.zIndex ?? "null"}/${((_b = node.visualData.color) == null ? void 0 : _b.border) ?? ""}/${((_c = node.visualData.color) == null ? void 0 : _c.bg) ?? ""}`,
    isSplitRun: node.isSplitRun ? true : void 0,
    splitRunMax: node.isSplitRun ? node.splitRunMax : void 0,
    isSplitSequential: node.isSplitSequential ? true : void 0,
    data: Object.keys(node.data ?? {}).length > 0 ? node.data : void 0,
    outgoingConnections: outgoingConnections.length > 0 ? outgoingConnections : void 0,
    variants: (((_d = node.variants) == null ? void 0 : _d.length) ?? 0) > 0 ? node.variants : void 0,
    disabled: node.disabled ? true : void 0
  };
}
function fromSerializedNode2(serializedNode, serializedNodeInfo) {
  var _a;
  const [nodeId, type, title] = deserializeGraphNodeKey(serializedNodeInfo);
  const [x, y, width, zIndex, borderColor, bgColor] = serializedNode.visualData.split("/");
  const connections = ((_a = serializedNode.outgoingConnections) == null ? void 0 : _a.map(
    (serializedConnection) => fromSerializedConnection2(serializedConnection, nodeId)
  )) ?? [];
  const color = borderColor || bgColor ? { border: borderColor, bg: bgColor } : void 0;
  return [
    {
      id: nodeId,
      type,
      title,
      description: serializedNode.description,
      isSplitRun: serializedNode.isSplitRun ?? false,
      splitRunMax: serializedNode.splitRunMax ?? 10,
      isSplitSequential: serializedNode.isSplitSequential ?? false,
      visualData: {
        x: parseFloat(x),
        y: parseFloat(y),
        width: width === "null" ? void 0 : parseFloat(width),
        zIndex: zIndex === "null" ? void 0 : parseFloat(zIndex),
        color
      },
      data: serializedNode.data ?? {},
      variants: serializedNode.variants ?? [],
      disabled: serializedNode.disabled
    },
    connections
  ];
}
function toSerializedConnection(connection, allNodes) {
  var _a;
  return `${connection.outputId}->"${(_a = allNodes.find((node) => node.id === connection.inputNodeId)) == null ? void 0 : _a.title}" ${connection.inputNodeId}/${connection.inputId}`;
}
function fromSerializedConnection2(connection, nodeId) {
  try {
    const [, outputId, , inputNodeId, inputId] = connection.match(/(.+)->"(.+)"\s+(.+)\/(.+)/);
    return {
      outputId,
      outputNodeId: nodeId,
      inputId,
      inputNodeId
    };
  } catch (err) {
    throw new Error(`Invalid connection: ${connection}`);
  }
}
function datasetV4Serializer(datasets) {
  const dataContainer = {
    datasets
  };
  const data = JSON.stringify(dataContainer);
  return data;
}
function datasetV4Deserializer(serializedDatasets) {
  const stringData = serializedDatasets;
  const dataContainer = JSON.parse(stringData);
  if (!dataContainer.datasets) {
    throw new Error("Invalid dataset data");
  }
  return dataContainer.datasets;
}

// src/utils/serialization/serialization_v2.ts
var yaml3 = __toESM(require("yaml"), 1);
function projectV2Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Project v2 deserializer requires a string");
  }
  const project = yaml3.parse(data);
  if (project.version !== 2) {
    throw new Error("Project v2 deserializer requires a version 2 project");
  }
  doubleCheckProject(project.data);
  return project.data;
}
function graphV2Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Graph v2 deserializer requires a string");
  }
  const graph = yaml3.parse(data);
  if (graph.version !== 2) {
    throw new Error("Graph v2 deserializer requires a version 2 graph");
  }
  return graph.data;
}

// src/utils/serialization/serialization_v1.ts
function projectV1Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Project v1 deserializer requires a string");
  }
  const project = JSON.parse(data);
  doubleCheckProject(project);
  return project;
}
function graphV1Deserializer(data) {
  if (typeof data !== "string") {
    throw new Error("Graph v1 deserializer requires a string");
  }
  const graph = JSON.parse(data);
  if (!graph.nodes || !graph.connections) {
    throw new Error("Invalid graph file");
  }
  return graph;
}

// src/utils/serialization/serialization.ts
function serializeProject(project, attachedData) {
  return projectV4Serializer(project, attachedData);
}
var errMessage = (err) => `${getError(err).message}
${getError(err).stack}`;
function deserializeProject(serializedProject, path = null) {
  try {
    const result = projectV4Deserializer(serializedProject);
    if (path !== null)
      result[0].metadata.path = path;
    return result;
  } catch (err) {
    if (err instanceof yaml4.YAMLError) {
      yamlProblem(err);
    }
    console.warn(`Failed to deserialize project v4: ${errMessage(err)}`);
    try {
      const project = projectV3Deserializer(serializedProject);
      return [project, {}];
    } catch (err2) {
      if (err2 instanceof yaml4.YAMLError) {
        yamlProblem(err2);
      }
      console.warn(`Failed to deserialize project v3: ${errMessage(err2)}`);
      try {
        const project = projectV2Deserializer(serializedProject);
        return [project, {}];
      } catch (err3) {
        if (err3 instanceof yaml4.YAMLError) {
          yamlProblem(err3);
        }
        console.warn(`Failed to deserialize project v2: ${errMessage(err3)}`);
        try {
          const project = projectV1Deserializer(serializedProject);
          return [project, {}];
        } catch (err4) {
          console.warn(`Failed to deserialize project v1: ${errMessage(err4)}`);
          throw new Error("Could not deserialize project");
        }
      }
    }
  }
}
function serializeGraph(graph) {
  return graphV4Serializer(graph);
}
function deserializeGraph(serializedGraph) {
  try {
    return graphV4Deserializer(serializedGraph);
  } catch (err) {
    try {
      return graphV3Deserializer(serializedGraph);
    } catch (err2) {
      try {
        return graphV2Deserializer(serializedGraph);
      } catch (err3) {
        try {
          return graphV1Deserializer(serializedGraph);
        } catch (err4) {
          throw new Error("Could not deserialize graph");
        }
      }
    }
  }
}
function serializeDatasets(datasets) {
  return datasetV4Serializer(datasets);
}
function deserializeDatasets(serializedDatasets) {
  return datasetV4Deserializer(serializedDatasets);
}

// src/utils/symbols.ts
var Warnings = "__internalPort_Warnings";
var WarningsPort = Warnings;

// src/utils/outputs.ts
function addWarning(outputs, warning) {
  if (!outputs[WarningsPort]) {
    outputs[WarningsPort] = { type: "string[]", value: [] };
  }
  outputs[WarningsPort].value.push(warning);
}
function getWarnings(outputs) {
  if (!(outputs == null ? void 0 : outputs[WarningsPort])) {
    return void 0;
  }
  return expectType(outputs[WarningsPort], "string[]");
}

// src/utils/base64.ts
async function uint8ArrayToBase64(uint8Array) {
  if (typeof window === "undefined") {
    return Buffer.from(uint8Array).toString("base64");
  } else {
    const blob = new Blob([uint8Array], { type: "application/octet-stream" });
    const dataUrl = await new Promise((resolve) => {
      const reader = new FileReader();
      reader.onload = () => resolve(reader.result);
      reader.readAsDataURL(blob);
    });
    return dataUrl.split(",")[1];
  }
}
function base64ToUint8Array(base64) {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

// src/utils/inputs.ts
function getInputOrData(data, inputs, inputAndDataKey, type, useInputToggleDataKey) {
  if (!useInputToggleDataKey) {
    const capitalized = inputAndDataKey[0].toUpperCase() + inputAndDataKey.slice(1);
    const key = `use${capitalized}Input`;
    useInputToggleDataKey = key;
  }
  const value = data[useInputToggleDataKey] && inputs[inputAndDataKey] != null ? coerceTypeOptional(inputs[inputAndDataKey], type ?? "string") ?? data[inputAndDataKey] : data[inputAndDataKey];
  return value;
}
function cleanHeaders(headers) {
  return Object.fromEntries(entries(headers).filter(([key]) => key.trim()));
}

// src/utils/misc.ts
var import_ts_dedent = require("ts-dedent");

// src/utils/getPluginConfig.ts
function getPluginConfig(plugin, settings, name) {
  var _a, _b, _c;
  if (!plugin) {
    return void 0;
  }
  const configSpec = (_a = plugin == null ? void 0 : plugin.configSpec) == null ? void 0 : _a[name];
  if (!configSpec) {
    return void 0;
  }
  const pluginSettings = (_b = settings.pluginSettings) == null ? void 0 : _b[plugin.id];
  if (pluginSettings) {
    const value = pluginSettings[name];
    if (!value || typeof value !== "string") {
      return void 0;
    }
    return value;
  }
  const envFallback = configSpec.pullEnvironmentVariable;
  const envFallbackName = envFallback === true ? name : envFallback;
  if (envFallbackName && ((_c = settings.pluginEnv) == null ? void 0 : _c[envFallbackName])) {
    return settings.pluginEnv[envFallbackName];
  }
  return void 0;
}

// src/utils/newId.ts
var import_non_secure = require("nanoid/non-secure");
function newId() {
  return (0, import_non_secure.nanoid)();
}

// src/utils/handleEscapeCharacters.ts
function handleEscapeCharacters(inputString) {
  return inputString.replace(/([^\\]|^)\\n/g, "$1\n").replace(/([^\\]|^)\\t/g, "$1	").replace(/([^\\]|^)\\r/g, "$1\r").replace(/([^\\]|^)\\f/g, "$1\f").replace(/([^\\]|^)\\b/g, "$1\b").replace(/([^\\]|^)\\v/g, "$1\v");
}

// src/utils/compatibility.ts
function isDataTypeAccepted(inputType, accepted) {
  inputType = Array.isArray(inputType) ? inputType : [inputType];
  accepted = Array.isArray(accepted) ? accepted : [accepted];
  for (const input of inputType) {
    for (const accept of accepted) {
      if (isDataTypeCompatible(input, accept)) {
        return true;
      }
    }
  }
  return false;
}
function isDataTypeCompatible(inputType, accepted) {
  if (inputType === "any" || accepted === "any") {
    return true;
  }
  if (isArrayDataType(inputType) && isArrayDataType(accepted) && (inputType === "any[]" || accepted === "any[]")) {
    return true;
  }
  if (inputType === accepted) {
    return true;
  }
  return false;
}

// src/utils/defaults.ts
var DEFAULT_CHAT_ENDPOINT = "https://api.openai.com/v1/chat/completions";
var DEFAULT_CHAT_NODE_TIMEOUT = 3e4;

// src/model/GraphProcessor.ts
var import_lodash_es15 = require("lodash");

// src/model/NodeBase.ts
var IF_PORT = {
  id: `$if`,
  title: "if",
  dataType: "boolean",
  coerced: true,
  description: "Only run the node if this condition is true",
  defaultValue: "false"
};
function isBuiltInInputDefinition(input) {
  return input.id === IF_PORT.id;
}

// src/model/GraphProcessor.ts
var import_p_queue = __toESM(require("p-queue-6"), 1);
var import_emittery2 = __toESM(require("emittery-0-13"), 1);
var import_non_secure73 = require("nanoid/non-secure");
var import_ts_pattern10 = require("ts-pattern");

// src/model/NodeImpl.ts
var NodeImpl = class {
  chartNode;
  constructor(chartNode) {
    this.chartNode = chartNode;
  }
  get id() {
    return this.chartNode.id;
  }
  get type() {
    return this.chartNode.type;
  }
  get title() {
    return this.chartNode.title;
  }
  get visualData() {
    return this.chartNode.visualData;
  }
  get data() {
    return this.chartNode.data;
  }
  getInputDefinitionsIncludingBuiltIn(connections, nodes, project) {
    const ports = [...this.getInputDefinitions(connections, nodes, project)];
    if (this.chartNode.isConditional) {
      ports.push(IF_PORT);
    }
    return ports;
  }
  getEditors(_context) {
    return [];
  }
  getBody(_context) {
    return void 0;
  }
};
var PluginNodeImplClass = class extends NodeImpl {
  impl;
  constructor(chartNode, impl) {
    super(chartNode);
    this.impl = impl;
  }
  getInputDefinitions(connections, nodes, project) {
    return this.impl.getInputDefinitions(this.data, connections, nodes, project);
  }
  getOutputDefinitions(connections, nodes, project) {
    return this.impl.getOutputDefinitions(this.data, connections, nodes, project);
  }
  process(inputData, context) {
    return this.impl.process(this.data, inputData, context);
  }
  getEditors(context) {
    return this.impl.getEditors(this.data, context);
  }
  getBody(context) {
    return this.impl.getBody(this.data, context);
  }
};

// src/model/NodeRegistration.ts
var NodeRegistration = class {
  NodesType = void 0;
  NodeTypesType = void 0;
  #infos = {};
  #plugins = [];
  #implsMap = {};
  #nodeTypes = [];
  register(definition, plugin) {
    const newRegistration = this;
    const typeStr = definition.impl.create(void 0).type;
    if (newRegistration.#infos[typeStr]) {
      throw new Error(`Duplicate node type: ${typeStr}`);
    }
    newRegistration.#infos[typeStr] = {
      displayName: definition.displayName,
      impl: definition.impl,
      plugin
    };
    newRegistration.#implsMap[typeStr] = {
      impl: definition.impl,
      pluginImpl: void 0
    };
    newRegistration.#nodeTypes.push(typeStr);
    return newRegistration;
  }
  registerPluginNode(definition, plugin) {
    const newRegistration = this;
    const typeStr = definition.impl.create().type;
    if (newRegistration.#infos[typeStr]) {
      throw new Error(`Duplicate node type: ${typeStr}`);
    }
    const pluginClass = class extends PluginNodeImplClass {
      static create() {
        return definition.impl.create();
      }
      static getUIData(context) {
        return definition.impl.getUIData(context);
      }
    };
    newRegistration.#infos[typeStr] = {
      displayName: definition.displayName,
      impl: pluginClass,
      plugin,
      pluginImpl: definition.impl
    };
    newRegistration.#implsMap[typeStr] = {
      impl: pluginClass,
      pluginImpl: definition.impl
    };
    newRegistration.#nodeTypes.push(typeStr);
    return newRegistration;
  }
  get #dynamicImpls() {
    return this.#implsMap;
  }
  get #dynamicDisplayNames() {
    const displayNameMap = mapValues2(this.#infos, (info) => info.displayName);
    return displayNameMap;
  }
  registerPlugin(plugin) {
    if (plugin.register) {
      plugin.register((definition) => this.registerPluginNode(definition, plugin));
    }
    this.#plugins.push(plugin);
  }
  create(type) {
    const info = this.#infos[type];
    if (!info) {
      throw new Error(`Unknown node type: ${type}`);
    }
    return info.impl.create(info.pluginImpl);
  }
  createDynamic(type) {
    const implClass = this.#dynamicImpls[type];
    if (!implClass) {
      throw new Error(`Unknown node type: ${type}`);
    }
    return implClass.impl.create(implClass.pluginImpl);
  }
  createImpl(node) {
    const type = node.type;
    const info = this.#infos[type];
    if (!info) {
      throw new Error(`Unknown node type: ${type}`);
    }
    const { impl: ImplClass, pluginImpl } = info;
    const impl = new ImplClass(node, pluginImpl);
    if (!impl) {
      throw new Error(`Unknown node type: ${type}`);
    }
    return impl;
  }
  createDynamicImpl(node) {
    const { type } = node;
    const ImplClass = this.#dynamicImpls[type];
    if (!ImplClass) {
      throw new Error(`Unknown node type: ${type}`);
    }
    const impl = new ImplClass.impl(node, ImplClass.pluginImpl);
    if (!impl) {
      throw new Error(`Unknown node type: ${type}`);
    }
    return impl;
  }
  getDisplayName(type) {
    const info = this.#infos[type];
    if (!info) {
      throw new Error(`Unknown node type: ${type}`);
    }
    return info.displayName;
  }
  getDynamicDisplayName(type) {
    const displayName = this.#dynamicDisplayNames[type];
    if (!displayName) {
      throw new Error(`Unknown node type: ${type}`);
    }
    return displayName;
  }
  isRegistered(type) {
    return this.#infos[type] !== void 0;
  }
  getNodeTypes() {
    return this.#nodeTypes;
  }
  getNodeConstructors() {
    return values(this.#dynamicImpls).map((info) => info.impl);
  }
  getPluginFor(type) {
    const info = this.#infos[type];
    if (!info) {
      throw new Error(`Unknown node type: ${type}`);
    }
    return info.plugin;
  }
  getPlugins() {
    return this.#plugins;
  }
};

// src/model/nodes/UserInputNode.ts
var import_non_secure2 = require("nanoid/non-secure");
var import_lodash_es3 = require("lodash");
var import_ts_dedent2 = require("ts-dedent");

// src/model/NodeDefinition.ts
function nodeDefinition(impl, displayName) {
  return {
    impl,
    displayName
  };
}
function pluginNodeDefinition(impl, displayName) {
  return {
    impl,
    displayName
  };
}

// src/model/nodes/UserInputNode.ts
var UserInputNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "userInput",
      title: "User Input",
      id: (0, import_non_secure2.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        prompt: "This is an example question?",
        useInput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    if (this.chartNode.data.useInput) {
      return [
        {
          dataType: "string[]",
          id: "questions",
          title: "Questions"
        }
      ];
    }
    return [];
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "string[]",
        id: "output",
        title: "Answers Only"
      },
      {
        dataType: "string[]",
        id: "questionsAndAnswers",
        title: "Q & A"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "code",
        label: "Prompt",
        dataKey: "prompt",
        useInputToggleDataKey: "useInput",
        language: "plain-text"
      },
      {
        type: "group",
        label: "Rendering",
        editors: [
          {
            type: "dropdown",
            dataKey: "renderingFormat",
            label: "Format",
            options: [
              { label: "Preformatted", value: "preformatted" },
              { label: "Markdown", value: "markdown" }
            ],
            defaultValue: "markdown"
          }
        ]
      }
    ];
  }
  getBody() {
    return this.data.useInput ? "(Using input)" : this.data.prompt;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent2.dedent`
        Prompts the user for input during the execution of the graph. The user's response becomes the output of this node.
      `,
      infoBoxTitle: "User Input Node",
      contextMenuTitle: "User Input",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    const questions = this.data.useInput ? coerceType(inputs["questions"], "string[]") : [this.data.prompt];
    const renderingFormat = this.data.renderingFormat === "preformatted" ? "text" : "markdown";
    const response = await context.requestUserInput(questions, renderingFormat);
    return {
      ["output"]: {
        type: "string[]",
        value: response.value
      },
      ["questionsAndAnswers"]: {
        type: "string[]",
        value: (0, import_lodash_es3.zip)(questions, response.value).map(([q, a]) => `${q}
${a}`)
      }
    };
  }
};
var userInputNode = nodeDefinition(UserInputNodeImpl, "User Input");

// src/model/nodes/TextNode.ts
var import_non_secure3 = require("nanoid/non-secure");
var import_ts_dedent3 = require("ts-dedent");

// src/utils/interpolation.ts
var TOKEN_MATCH_REGEX = /\{\{(?!\{)([^{}\s][^{}]*[^{}\s]|[^{}\s])\}\}(?!\})/g;
var ESCAPED_TOKEN_REGEX = /\{{3}([^{}]+)\}{3}/g;
var processingFunctions = {
  indent: (input, spaces = 0) => {
    const indent = " ".repeat(spaces);
    return input.split("\n").map((line) => `${indent}${line}`).join("\n");
  },
  quote: (input, level = 1) => {
    const quotePrefix = "> ".repeat(level);
    return input.split("\n").map((line) => `${quotePrefix}${line}`).join("\n");
  },
  uppercase: (input) => {
    return input.toUpperCase();
  },
  lowercase: (input) => {
    return input.toLowerCase();
  },
  trim: (input) => {
    return input.trim();
  },
  truncate: (input, length = 50) => {
    if (input.length <= length)
      return input;
    return input.slice(0, length) + "...";
  },
  list: (input, level = 1) => {
    const indent = "  ".repeat(level - 1);
    return input.split("\n").map((line) => `${indent}- ${line}`).join("\n");
  },
  sort: (input) => {
    return input.split("\n").sort().join("\n");
  },
  dedent: (input) => {
    return (0, import_ts_dedent.dedent)(input);
  },
  wrap: (input, width = 80) => {
    const words = input.split(/\s+/);
    const lines = [];
    let currentLine = "";
    for (const word of words) {
      if (currentLine.length + word.length + 1 <= width) {
        currentLine += (currentLine ? " " : "") + word;
      } else {
        lines.push(currentLine);
        currentLine = word;
      }
    }
    if (currentLine) {
      lines.push(currentLine);
    }
    return lines.join("\n");
  }
};
function parseProcessing(instruction) {
  const parts = instruction.trim().split(/\s+/);
  return {
    func: parts[0],
    param: parts[1] ? parseInt(parts[1], 10) : void 0
  };
}
function applyProcessing(value, processingChain) {
  const instructions = processingChain.split("|").slice(1);
  return instructions.reduce((result, instruction) => {
    const { func, param } = parseProcessing(instruction);
    const processingFunc = processingFunctions[func];
    if (!processingFunc) {
      console.warn(`Unknown processing function: ${func}`);
      return result;
    }
    return processingFunc(result, param);
  }, value);
}
function interpolate(baseString, values3) {
  return baseString.replace(TOKEN_MATCH_REGEX, (_m, p1) => {
    const [token, ...processing] = p1.split("|");
    const value = values3[token.trim()];
    if (value === void 0)
      return "";
    if (processing.length > 0) {
      return applyProcessing(value, p1);
    }
    return value;
  }).replace(ESCAPED_TOKEN_REGEX, (_m, p1) => {
    return `{{${p1}}}`;
  });
}
function extractInterpolationVariables(template) {
  const matches = template.matchAll(TOKEN_MATCH_REGEX);
  const variables = /* @__PURE__ */ new Set();
  for (const match15 of matches) {
    const [token] = match15[1].split("|");
    variables.add(token.trim());
  }
  return Array.from(variables);
}

// src/model/nodes/TextNode.ts
var TextNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "text",
      title: "Text",
      id: (0, import_non_secure3.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 300
      },
      data: {
        text: "{{input}}"
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputNames = extractInterpolationVariables(this.data.text);
    return (inputNames == null ? void 0 : inputNames.map((inputName) => {
      return {
        type: "string",
        // id and title should not have the {{ and }}
        id: inputName,
        title: inputName,
        dataType: "string",
        required: false
      };
    })) ?? [];
  }
  getOutputDefinitions() {
    return [
      {
        id: "output",
        title: "Output",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "custom",
        label: "AI Assist",
        customEditorId: "TextNodeAiAssist"
      },
      {
        type: "code",
        label: "Text",
        dataKey: "text",
        language: "prompt-interpolation-markdown",
        theme: "prompt-interpolation"
      }
    ];
  }
  getBody() {
    const truncated = this.data.text.split("\n").slice(0, 15).join("\n").trim();
    return {
      type: "colorized",
      language: "prompt-interpolation-markdown",
      theme: "prompt-interpolation",
      text: truncated
    };
  }
  async process(inputs) {
    const inputMap = Object.keys(inputs).reduce(
      (acc, key) => {
        const stringValue = coerceTypeOptional(inputs[key], "string") ?? "";
        acc[key] = stringValue;
        return acc;
      },
      {}
    );
    const outputValue = interpolate(this.chartNode.data.text, inputMap);
    return {
      output: {
        type: "string",
        value: outputValue
      }
    };
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent3.dedent`
        Outputs a string of text. It can also interpolate values using <span style="color: var(--primary)">{{tags}}</span>.

        The inputs are dynamic based on the interpolation tags.
      `,
      contextMenuTitle: "Text",
      infoBoxTitle: "Text Node",
      group: ["Common", "Text"]
    };
  }
};
var textNode = nodeDefinition(TextNodeImpl, "Text");

// src/model/nodes/ChatNode.ts
var import_non_secure4 = require("nanoid/non-secure");
var import_ts_dedent4 = require("ts-dedent");

// src/model/nodes/ChatNodeBase.ts
var import_ts_pattern3 = require("ts-pattern");

// src/utils/openai.ts
var openai_exports = {};
__export(openai_exports, {
  OpenAIError: () => OpenAIError,
  chatCompletions: () => chatCompletions,
  openAIFilePurposeOptions: () => openAIFilePurposeOptions,
  openAIFileUploadPurposeOptions: () => openAIFileUploadPurposeOptions,
  openAiModelOptions: () => openAiModelOptions,
  openaiModels: () => openaiModels,
  streamChatCompletions: () => streamChatCompletions
});
var import_lodash_es4 = require("lodash");

// src/utils/fetchEventSource.ts
var EventSourceResponse = class extends Response {
  name;
  timeout;
  streams;
  constructor(body, init2, timeout) {
    if (body == null) {
      super(null, init2);
      this.name = "EventSourceResponse";
      this.streams = null;
      this.timeout = timeout;
      return;
    }
    const [bodyForString, bodyForEvents] = body.tee();
    const streams = createEventStream(bodyForEvents);
    super(bodyForString, init2);
    this.name = "EventSourceResponse";
    this.streams = streams;
    this.timeout = timeout;
  }
  async *events() {
    if (this.streams == null) {
      return;
    }
    const reader = this.streams.eventStream.getReader();
    try {
      while (true) {
        const { done, value } = await this.raceWithTimeout(reader.read(), this.timeout);
        if (done) {
          break;
        }
        yield value;
      }
    } finally {
      try {
        reader.releaseLock();
      } catch (err) {
        console.error(`Failed to release read lock on event source: ${getError(err).toString()}`);
      }
    }
  }
  async raceWithTimeout(promise, timeout) {
    const raceTimeout = timeout ?? DEFAULT_CHAT_NODE_TIMEOUT;
    return new Promise(async (resolve, reject) => {
      const timer = setTimeout(() => {
        reject(new Error("Timeout: API response took too long."));
      }, raceTimeout);
      try {
        const result = await promise;
        clearTimeout(timer);
        resolve(result);
      } catch (error) {
        clearTimeout(timer);
        reject(error);
      }
    });
  }
};
async function fetchEventSource(url, init2, timeout) {
  const headers = {
    ...init2 == null ? void 0 : init2.headers,
    accept: "text/event-stream"
  };
  const response = await fetch(url, {
    ...init2,
    headers
  });
  return new EventSourceResponse(response.body, response, timeout);
}
var LineSplitter = class {
  constructor(separator = /\n+/) {
    this.separator = separator;
  }
  buffer = "";
  transform(chunk, controller) {
    this.buffer += chunk;
    const lines = this.buffer.split(this.separator);
    this.buffer = lines.pop() ?? "";
    for (const line of lines) {
      controller.enqueue(line);
    }
  }
  flush(controller) {
    if (this.buffer.length > 0) {
      controller.enqueue(this.buffer);
      this.buffer = "";
    }
  }
};
function createEventStream(body) {
  if (body == null) {
    return null;
  }
  const textStream = body.pipeThrough(new TextDecoderStream());
  const eventStream = textStream.pipeThrough(new TransformStream(new LineSplitter())).pipeThrough(
    new TransformStream({
      transform(line, controller) {
        if (line.trim().length === 0) {
          return;
        }
        if (line.startsWith("data: ")) {
          const data = line.slice(6).trim();
          controller.enqueue(data);
        } else if (line.startsWith("event: ")) {
          const event = line.slice(7).trim();
          controller.enqueue(`[${event}]`);
        }
      }
    })
  );
  return { eventStream, textStream };
}

// src/utils/openai.ts
var openaiModels = {
  "gpt-4": {
    maxTokens: 8192,
    cost: {
      prompt: 0.03,
      completion: 0.06
    },
    displayName: "GPT-4"
  },
  "gpt-4-32k": {
    maxTokens: 32768,
    cost: {
      prompt: 0.06,
      completion: 0.12
    },
    displayName: "GPT-4 32k"
  },
  "gpt-4-0613": {
    maxTokens: 8192,
    cost: {
      prompt: 0.03,
      completion: 0.06
    },
    displayName: "GPT-4 (v0613)"
  },
  "gpt-4-32k-0613": {
    maxTokens: 32768,
    cost: {
      prompt: 0.06,
      completion: 0.12
    },
    displayName: "GPT-4 32k (v0613)"
  },
  "gpt-4-0314": {
    maxTokens: 8192,
    cost: {
      prompt: 0.03,
      completion: 0.06
    },
    displayName: "GPT-4 (v0314)"
  },
  "gpt-4-32k-0314": {
    maxTokens: 32768,
    cost: {
      prompt: 0.06,
      completion: 0.12
    },
    displayName: "GPT-4 32k (v0314)"
  },
  "gpt-4-1106-preview": {
    maxTokens: 128e3,
    cost: {
      prompt: 0.01,
      completion: 0.03
    },
    displayName: "GPT-4 Turbo 128K (1106 Preview)"
  },
  "gpt-4-turbo": {
    maxTokens: 128e3,
    cost: {
      prompt: 0.01,
      completion: 0.03
    },
    displayName: "GPT-4 Turbo 128K with Vision"
  },
  "gpt-4-vision-preview": {
    maxTokens: 128e3,
    cost: {
      prompt: 0.01,
      completion: 0.03
    },
    displayName: "GPT-4 Vision (Preview)"
  },
  "gpt-4o": {
    maxTokens: 128e3,
    cost: {
      prompt: 5e-3,
      completion: 0.015
    },
    displayName: "GPT-4o"
  },
  "gpt-4o-mini": {
    maxTokens: 128e3,
    cost: {
      prompt: 15e-5,
      completion: 75e-5
    },
    displayName: "GPT-4o mini"
  },
  "gpt-4o-mini-2024-07-18": {
    maxTokens: 128e3,
    cost: {
      prompt: 15e-5,
      completion: 75e-5
    },
    displayName: "GPT-4o mini (2024-07-18)"
  },
  o1: {
    maxTokens: 128e3,
    cost: {
      prompt: 0.015,
      completion: 0.6
    },
    displayName: "o1"
  },
  "o1-preview": {
    maxTokens: 128e3,
    cost: {
      prompt: 0.015,
      completion: 0.06
    },
    displayName: "o1-preview"
  },
  "o1-preview-2024-09-12": {
    maxTokens: 128e3,
    cost: {
      prompt: 0.015,
      completion: 0.06
    },
    displayName: "o1-preview (2024-09-12)"
  },
  "o1-mini": {
    maxTokens: 128e3,
    cost: {
      prompt: 11e-4,
      completion: 44e-4
    },
    displayName: "o1-mini"
  },
  "o1-mini-2024-09-12": {
    maxTokens: 128e3,
    cost: {
      prompt: 11e-4,
      completion: 44e-4
    },
    displayName: "o1-mini (2024-09-12)"
  },
  "o3-mini": {
    maxTokens: 2e5,
    cost: {
      prompt: 11e-4,
      completion: 44e-4
    },
    displayName: "o3-mini"
  },
  "o3-mini-2025-01-31": {
    maxTokens: 2e5,
    cost: {
      prompt: 11e-4,
      completion: 44e-4
    },
    displayName: "o3-mini (2025-01-31)"
  },
  "gpt-4o-audio-preview": {
    maxTokens: 128e3,
    cost: {
      prompt: 25e-4,
      completion: 0.01,
      audioPrompt: 0.04,
      audioCompletion: 0.08
    },
    displayName: "GPT-4o Audio (Preview)"
  },
  "local-model": {
    maxTokens: Number.MAX_SAFE_INTEGER,
    cost: {
      prompt: 0,
      completion: 0
    },
    displayName: "Local Model"
  }
};
var openAiModelOptions = (0, import_lodash_es4.orderBy)(
  Object.entries(openaiModels).map(([id, { displayName }]) => ({
    value: id,
    label: displayName
  })),
  "label"
);
var OpenAIError = class extends Error {
  constructor(status, responseJson) {
    super(`OpenAIError: ${status} ${JSON.stringify(responseJson)}`);
    this.status = status;
    this.responseJson = responseJson;
    this.name = "OpenAIError";
  }
};
async function chatCompletions({
  endpoint,
  auth,
  signal,
  headers,
  timeout,
  ...rest
}) {
  const abortSignal = signal ?? new AbortController().signal;
  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${auth.apiKey}`,
      ...auth.organization ? { "OpenAI-Organization": auth.organization } : {},
      ...headers
    },
    body: JSON.stringify(rest),
    signal: abortSignal
  });
  return response.json();
}
async function* streamChatCompletions({
  endpoint,
  auth,
  signal,
  headers,
  timeout,
  ...rest
}) {
  const abortSignal = signal ?? new AbortController().signal;
  const response = await fetchEventSource(
    endpoint,
    {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${auth.apiKey}`,
        ...auth.organization ? { "OpenAI-Organization": auth.organization } : {},
        ...headers
      },
      body: JSON.stringify({
        ...rest,
        stream: true,
        stream_options: {
          include_usage: true
        }
      }),
      signal: abortSignal
    },
    timeout ?? DEFAULT_CHAT_NODE_TIMEOUT
  );
  let hadChunks = false;
  for await (const chunk of response.events()) {
    hadChunks = true;
    if (chunk === "[DONE]" || (abortSignal == null ? void 0 : abortSignal.aborted)) {
      return;
    }
    let data;
    try {
      data = JSON.parse(chunk);
    } catch (err) {
      console.error("JSON parse failed on chunk: ", chunk);
      throw err;
    }
    yield data;
  }
  if (!hadChunks) {
    const responseJson = await response.json();
    throw new OpenAIError(response.status, responseJson);
  }
}
var openAIFilePurposeOptions = [
  { value: "fine-tune", label: "Fine-tuning" },
  { value: "fine-tune-results", label: "Fine-tuning Results" },
  { value: "assistants", label: "Assistants" },
  { value: "assistants_output", label: "Assistants Output" }
];
var openAIFileUploadPurposeOptions = [
  { value: "fine-tune", label: "Fine-tuning" },
  { value: "assistants", label: "Assistants" },
  { value: "assistants_output", label: "Assistants Output" }
];

// src/utils/chatMessageToOpenAIChatCompletionMessage.ts
var import_ts_pattern2 = require("ts-pattern");
async function chatMessageToOpenAIChatCompletionMessage(message) {
  const onlyStringContent = (message2) => {
    const parts = Array.isArray(message2.message) ? message2.message : [message2.message];
    const stringContent = parts.map((part) => {
      if (typeof part !== "string") {
        throw new Error("System prompt must be a string");
      }
      return part;
    }).join("\n\n");
    return stringContent;
  };
  return (0, import_ts_pattern2.match)(message).with({ type: "system" }, (m) => ({ role: m.type, content: onlyStringContent(m) })).with({ type: "user" }, async (m) => {
    const parts = Array.isArray(m.message) ? m.message : [m.message];
    if (parts.length === 1 && typeof parts[0] === "string") {
      return { role: m.type, content: parts[0] };
    }
    const chatMessageParts = await Promise.all(
      parts.map(async (part) => {
        if (typeof part === "string") {
          return { type: "text", text: part };
        }
        const url = part.type === "url" ? part.url : `data:${part.mediaType};base64,${await uint8ArrayToBase64(part.data)}`;
        return {
          type: "image_url",
          image_url: { url }
        };
      })
    );
    return { role: m.type, content: chatMessageParts };
  }).with(
    { type: "assistant" },
    (m) => ({
      role: m.type,
      content: onlyStringContent(m),
      tool_calls: m.function_calls ? m.function_calls.map((fc) => ({
        id: fc.id ?? "unknown_function_call",
        type: "function",
        function: fc
      })) : m.function_call ? [
        {
          id: m.function_call.id ?? "unknown_function_call",
          type: "function",
          function: m.function_call
        }
      ] : void 0
    })
  ).with(
    { type: "function" },
    (m) => ({
      role: "tool",
      content: onlyStringContent(m),
      tool_call_id: m.name ?? "unknown_function_call"
    })
  ).exhaustive();
}

// src/model/nodes/ChatNodeBase.ts
var import_p_retry = __toESM(require("p-retry-4"), 1);
var cache = /* @__PURE__ */ new Map();
var ChatNodeBase = {
  defaultData: () => ({
    model: "gpt-4o-mini",
    useModelInput: false,
    temperature: 0.5,
    useTemperatureInput: false,
    top_p: 1,
    useTopPInput: false,
    useTopP: false,
    useUseTopPInput: false,
    maxTokens: 1024,
    useMaxTokensInput: false,
    useStop: false,
    stop: "",
    useStopInput: false,
    presencePenalty: void 0,
    usePresencePenaltyInput: false,
    frequencyPenalty: void 0,
    useFrequencyPenaltyInput: false,
    user: void 0,
    useUserInput: false,
    enableFunctionUse: false,
    cache: false,
    useAsGraphPartialOutput: true,
    parallelFunctionCalling: true,
    additionalParameters: [],
    useAdditionalParametersInput: false,
    useServerTokenCalculation: true,
    outputUsage: false,
    usePredictedOutput: false,
    modalitiesIncludeAudio: false,
    modalitiesIncludeText: false,
    reasoningEffort: "medium",
    useReasoningEffortInput: false
  }),
  getInputDefinitions: (data) => {
    const inputs = [];
    if (data.useEndpointInput) {
      inputs.push({
        dataType: "string",
        id: "endpoint",
        title: "Endpoint",
        description: "The endpoint to use for the OpenAI API. You can use this to replace with any OpenAI-compatible API. Leave blank for the default: https://api.openai.com/api/v1/chat/completions"
      });
    }
    inputs.push({
      id: "systemPrompt",
      title: "System Prompt",
      dataType: "string",
      required: false,
      description: "The system prompt to send to the model.",
      coerced: true
    });
    if (data.useModelInput) {
      inputs.push({
        id: "model",
        title: "Model",
        dataType: "string",
        required: false,
        description: "The model to use for the chat."
      });
    }
    if (data.useTemperatureInput) {
      inputs.push({
        dataType: "number",
        id: "temperature",
        title: "Temperature",
        description: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
      });
    }
    if (data.useTopPInput) {
      inputs.push({
        dataType: "number",
        id: "top_p",
        title: "Top P",
        description: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."
      });
    }
    if (data.useUseTopPInput) {
      inputs.push({
        dataType: "boolean",
        id: "useTopP",
        title: "Use Top P",
        description: "Whether to use top p sampling, or temperature sampling."
      });
    }
    if (data.useMaxTokensInput) {
      inputs.push({
        dataType: "number",
        id: "maxTokens",
        title: "Max Tokens",
        description: "The maximum number of tokens to generate in the chat completion."
      });
    }
    if (data.useStopInput) {
      inputs.push({
        dataType: "string",
        id: "stop",
        title: "Stop",
        description: "A sequence where the API will stop generating further tokens."
      });
    }
    if (data.usePresencePenaltyInput) {
      inputs.push({
        dataType: "number",
        id: "presencePenalty",
        title: "Presence Penalty",
        description: `Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.`
      });
    }
    if (data.useFrequencyPenaltyInput) {
      inputs.push({
        dataType: "number",
        id: "frequencyPenalty",
        title: "Frequency Penalty",
        description: `Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.`
      });
    }
    if (data.useUserInput) {
      inputs.push({
        dataType: "string",
        id: "user",
        title: "User",
        description: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse."
      });
    }
    if (data.useNumberOfChoicesInput) {
      inputs.push({
        dataType: "number",
        id: "numberOfChoices",
        title: "Number of Choices",
        description: "If greater than 1, the model will return multiple choices and the response will be an array."
      });
    }
    if (data.useHeadersInput) {
      inputs.push({
        dataType: "object",
        id: "headers",
        title: "Headers",
        description: "Additional headers to send to the API."
      });
    }
    inputs.push({
      dataType: ["chat-message", "chat-message[]"],
      id: "prompt",
      title: "Prompt",
      description: "The prompt message or messages to send to the model.",
      coerced: true
    });
    if (data.enableFunctionUse) {
      inputs.push({
        dataType: ["gpt-function", "gpt-function[]"],
        id: "functions",
        title: "Functions",
        description: "Functions to use in the model. To connect multiple functions, use an Array node.",
        coerced: false
      });
    }
    if (data.useSeedInput) {
      inputs.push({
        dataType: "number",
        id: "seed",
        title: "Seed",
        coerced: true,
        description: "If specified, OpenAI will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result."
      });
    }
    if (data.useToolChoiceInput) {
      inputs.push({
        dataType: "string",
        id: "toolChoice",
        title: "Tool Choice",
        coerced: true,
        description: "Controls which (if any) function is called by the model. `none` is the default when no functions are present. `auto` is the default if functions are present. `function` forces the model to call a function."
      });
    }
    if (data.useToolChoiceInput || data.useToolChoiceFunctionInput) {
      inputs.push({
        dataType: "string",
        id: "toolChoiceFunction",
        title: "Tool Choice Function",
        coerced: true,
        description: "The name of the function to force the model to call."
      });
    }
    if (data.useResponseFormatInput) {
      inputs.push({
        dataType: "string",
        id: "responseFormat",
        title: "Response Format",
        coerced: true,
        description: "The format to force the model to reply in."
      });
    }
    if (data.useAdditionalParametersInput) {
      inputs.push({
        dataType: "object",
        id: "additionalParameters",
        title: "Additional Parameters",
        description: "Additional chat completion parameters to send to the API."
      });
    }
    if (data.responseFormat === "json_schema") {
      inputs.push({
        dataType: "object",
        id: "responseSchema",
        title: "Response Schema",
        description: "The JSON schema that the response will adhere to (Structured Outputs).",
        required: true
      });
      if (data.useResponseSchemaNameInput) {
        inputs.push({
          dataType: "string",
          id: "responseSchemaName",
          title: "Response Schema Name",
          description: "The name of the JSON schema that the response will adhere to (Structured Outputs).",
          required: false
        });
      }
    }
    if (data.usePredictedOutput) {
      inputs.push({
        dataType: "string[]",
        id: "predictedOutput",
        title: "Predicted Output",
        description: "The predicted output from the model.",
        coerced: true
      });
    }
    if (data.useAudioVoiceInput) {
      inputs.push({
        dataType: "string",
        id: "audioVoice",
        title: "Audio Voice",
        description: "The voice to use for audio responses. See your model for supported voices."
      });
    }
    if (data.useAudioFormatInput) {
      inputs.push({
        dataType: "string",
        id: "audioFormat",
        title: "Audio Format",
        description: "The format to use for audio responses."
      });
    }
    return inputs;
  },
  getOutputDefinitions: (data) => {
    const outputs = [];
    if (data.useNumberOfChoicesInput || (data.numberOfChoices ?? 1) > 1) {
      outputs.push({
        dataType: "string[]",
        id: "response",
        title: "Responses",
        description: "All responses from the model."
      });
    } else {
      outputs.push({
        dataType: "string",
        id: "response",
        title: "Response",
        description: "The textual response from the model."
      });
    }
    if (data.enableFunctionUse) {
      if (data.parallelFunctionCalling) {
        outputs.push({
          dataType: "object[]",
          id: "function-calls",
          title: "Function Calls",
          description: "The function calls that were made, if any."
        });
      } else {
        outputs.push({
          dataType: "object",
          id: "function-call",
          title: "Function Call",
          description: "The function call that was made, if any."
        });
      }
    }
    outputs.push({
      dataType: "chat-message[]",
      id: "in-messages",
      title: "Messages Sent",
      description: "All messages sent to the model."
    });
    if (!(data.useNumberOfChoicesInput || (data.numberOfChoices ?? 1) > 1)) {
      outputs.push({
        dataType: "chat-message[]",
        id: "all-messages",
        title: "All Messages",
        description: "All messages, with the response appended."
      });
    }
    outputs.push({
      dataType: "number",
      id: "responseTokens",
      title: "Response Tokens",
      description: "The number of tokens in the response from the LLM. For a multi-response, this is the sum."
    });
    if (data.outputUsage) {
      outputs.push({
        dataType: "object",
        id: "usage",
        title: "Usage",
        description: "Usage statistics for the model."
      });
    }
    if (data.modalitiesIncludeAudio) {
      outputs.push({
        dataType: "audio",
        id: "audio",
        title: "Audio",
        description: "The audio response from the model."
      });
      outputs.push({
        dataType: "string",
        id: "audioTranscript",
        title: "Transcript",
        description: "The transcript of the audio response."
      });
    }
    return outputs;
  },
  getEditors: () => {
    return [
      {
        type: "dropdown",
        label: "GPT Model",
        dataKey: "model",
        useInputToggleDataKey: "useModelInput",
        options: openAiModelOptions,
        disableIf: (data) => {
          var _a;
          return !!((_a = data.overrideModel) == null ? void 0 : _a.trim());
        },
        helperMessage: (data) => {
          var _a;
          if ((_a = data.overrideModel) == null ? void 0 : _a.trim()) {
            return `Model overridden to: ${data.overrideModel}`;
          }
          if (data.model === "local-model") {
            return "Local model is an indicator for your own convenience, it does not affect the local LLM used.";
          }
        }
      },
      {
        type: "group",
        label: "Parameters",
        editors: [
          {
            type: "number",
            label: "Temperature",
            dataKey: "temperature",
            useInputToggleDataKey: "useTemperatureInput",
            min: 0,
            max: 2,
            step: 0.1,
            helperMessage: "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic."
          },
          {
            type: "number",
            label: "Top P",
            dataKey: "top_p",
            useInputToggleDataKey: "useTopPInput",
            min: 0,
            max: 1,
            step: 0.1,
            helperMessage: "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered."
          },
          {
            type: "toggle",
            label: "Use Top P",
            dataKey: "useTopP",
            useInputToggleDataKey: "useUseTopPInput",
            helperMessage: "Whether to use top p sampling, or temperature sampling."
          },
          {
            type: "number",
            label: "Max Tokens",
            dataKey: "maxTokens",
            useInputToggleDataKey: "useMaxTokensInput",
            min: 0,
            max: Number.MAX_SAFE_INTEGER,
            step: 1,
            helperMessage: "The maximum number of tokens to generate in the chat completion."
          },
          {
            type: "string",
            label: "Stop",
            dataKey: "stop",
            useInputToggleDataKey: "useStopInput",
            helperMessage: "A sequence where the API will stop generating further tokens."
          },
          {
            type: "number",
            label: "Presence Penalty",
            dataKey: "presencePenalty",
            useInputToggleDataKey: "usePresencePenaltyInput",
            min: 0,
            max: 2,
            step: 0.1,
            allowEmpty: true,
            helperMessage: `Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.`
          },
          {
            type: "number",
            label: "Frequency Penalty",
            dataKey: "frequencyPenalty",
            useInputToggleDataKey: "useFrequencyPenaltyInput",
            min: 0,
            max: 2,
            step: 0.1,
            allowEmpty: true,
            helperMessage: `Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.`
          },
          {
            type: "dropdown",
            label: "Reasoning Effort",
            dataKey: "reasoningEffort",
            useInputToggleDataKey: "useReasoningEffortInput",
            options: [
              { value: "low", label: "Low" },
              { value: "medium", label: "Medium" },
              { value: "high", label: "High" }
            ],
            defaultValue: "medium",
            helperMessage: "Adjust the level of reasoning depth the model should apply. Only applies to reasoning models such as o3-mini."
          },
          {
            type: "dropdown",
            label: "Response Format",
            dataKey: "responseFormat",
            useInputToggleDataKey: "useResponseFormatInput",
            options: [
              { value: "", label: "Default" },
              { value: "text", label: "Text" },
              { value: "json", label: "JSON Object" },
              { value: "json_schema", label: "JSON Schema" }
            ],
            defaultValue: "",
            helperMessage: "The format to force the model to reply in."
          },
          {
            type: "string",
            label: "Response Schema Name",
            dataKey: "responseSchemaName",
            useInputToggleDataKey: "useResponseSchemaNameInput",
            helperMessage: "The name of the JSON schema that the response will adhere to (Structured Outputs). Defaults to response_schema",
            hideIf: (data) => data.responseFormat !== "json_schema"
          },
          {
            type: "number",
            label: "Seed",
            dataKey: "seed",
            useInputToggleDataKey: "useSeedInput",
            step: 1,
            allowEmpty: true,
            helperMessage: "If specified, OpenAI will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result."
          }
        ]
      },
      {
        type: "group",
        label: "GPT Tools",
        editors: [
          {
            type: "toggle",
            label: "Enable Function Use",
            dataKey: "enableFunctionUse"
          },
          {
            type: "toggle",
            label: "Enable Parallel Function Calling",
            dataKey: "parallelFunctionCalling",
            hideIf: (data) => !data.enableFunctionUse
          },
          {
            type: "dropdown",
            label: "Tool Choice",
            dataKey: "toolChoice",
            useInputToggleDataKey: "useToolChoiceInput",
            options: [
              { value: "", label: "Default" },
              { value: "none", label: "None" },
              { value: "auto", label: "Auto" },
              { value: "function", label: "Function" },
              { value: "required", label: "Required" }
            ],
            defaultValue: "",
            helperMessage: "Controls which (if any) function is called by the model. None is the default when no functions are present. Auto is the default if functions are present.",
            hideIf: (data) => !data.enableFunctionUse
          },
          {
            type: "string",
            label: "Tool Choice Function",
            dataKey: "toolChoiceFunction",
            useInputToggleDataKey: "useToolChoiceFunctionInput",
            helperMessage: "The name of the function to force the model to call.",
            hideIf: (data) => data.toolChoice !== "function" || !data.enableFunctionUse
          }
        ]
      },
      {
        type: "group",
        label: "Features",
        editors: [
          {
            type: "toggle",
            label: "Enable Predicted Output",
            dataKey: "usePredictedOutput",
            helperMessage: "If on, enables an input port for the predicted output from the model, when many of the output tokens are known ahead of time."
          },
          {
            type: "toggle",
            label: "Modalities: Text",
            dataKey: "modalitiesIncludeText",
            helperMessage: "If on, the model will include text in its responses. Only relevant for multimodal models."
          },
          {
            type: "toggle",
            label: "Modalities: Audio",
            dataKey: "modalitiesIncludeAudio",
            helperMessage: "If on, the model will include audio in its responses. Only relevant for multimodal models."
          },
          {
            type: "string",
            label: "Audio Voice",
            dataKey: "audioVoice",
            useInputToggleDataKey: "useAudioVoiceInput",
            helperMessage: "The voice to use for audio responses. See your model for supported voices. OpenAI voices are: alloy, ash, coral, echo, fable, onyx, nova, sage, and shimmer.",
            hideIf: (data) => !data.modalitiesIncludeAudio
          },
          {
            type: "dropdown",
            label: "Audio Format",
            dataKey: "audioFormat",
            useInputToggleDataKey: "useAudioFormatInput",
            options: [
              { value: "wav", label: "WAV" },
              { value: "mp3", label: "MP3" },
              { value: "flac", label: "FLAC" },
              { value: "opus", label: "OPUS" },
              { value: "pcm16", label: "PCM16" }
            ],
            defaultValue: "wav",
            hideIf: (data) => !data.modalitiesIncludeAudio
          }
        ]
      },
      {
        type: "group",
        label: "Advanced",
        editors: [
          {
            type: "toggle",
            label: "Use Server Token Calculation",
            dataKey: "useServerTokenCalculation",
            helperMessage: "If on, do not calculate token counts on the client side, and rely on the server providing the token count."
          },
          {
            type: "toggle",
            label: "Output Usage Statistics",
            dataKey: "outputUsage",
            helperMessage: "If on, output usage statistics for the model, such as token counts and cost."
          },
          {
            type: "string",
            label: "User",
            dataKey: "user",
            useInputToggleDataKey: "useUserInput",
            helperMessage: "A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse."
          },
          {
            type: "number",
            label: "Number of Choices",
            dataKey: "numberOfChoices",
            useInputToggleDataKey: "useNumberOfChoicesInput",
            min: 1,
            max: 10,
            step: 1,
            defaultValue: 1,
            helperMessage: "If greater than 1, the model will return multiple choices and the response will be an array."
          },
          {
            type: "string",
            label: "Endpoint",
            dataKey: "endpoint",
            useInputToggleDataKey: "useEndpointInput",
            helperMessage: "The endpoint to use for the OpenAI API. You can use this to replace with any OpenAI-compatible API. Leave blank for the default: https://api.openai.com/api/v1/chat/completions"
          },
          {
            type: "string",
            label: "Custom Model",
            dataKey: "overrideModel",
            helperMessage: "Overrides the model selected above with a custom string for the model."
          },
          {
            type: "number",
            label: "Custom Max Tokens",
            dataKey: "overrideMaxTokens",
            allowEmpty: true,
            helperMessage: "Overrides the max number of tokens a model can support. Leave blank for preconfigured token limits."
          },
          {
            type: "keyValuePair",
            label: "Headers",
            dataKey: "headers",
            useInputToggleDataKey: "useHeadersInput",
            keyPlaceholder: "Header",
            helperMessage: "Additional headers to send to the API."
          },
          {
            type: "toggle",
            label: "Cache In Rivet",
            dataKey: "cache",
            helperMessage: "If on, requests with the same parameters and messages will be cached in Rivet, for immediate responses without an API call."
          },
          {
            type: "toggle",
            label: "Use for subgraph partial output",
            dataKey: "useAsGraphPartialOutput",
            helperMessage: "If on, streaming responses from this node will be shown in Subgraph nodes that call this graph."
          },
          {
            type: "keyValuePair",
            label: "Additional Parameters",
            dataKey: "additionalParameters",
            useInputToggleDataKey: "useAdditionalParametersInput",
            keyPlaceholder: "Parameter",
            valuePlaceholder: "Value",
            helperMessage: "Additional chat completion parameters to send to the API. If the value appears to be a number, it will be sent as a number."
          }
        ]
      }
    ];
  },
  getBody: (data) => {
    return import_ts_dedent.dedent`
      ${data.endpoint ? `${data.endpoint}` : ""}
      ${data.useMaxTokensInput ? "Max Tokens: (Using Input)" : `${data.maxTokens} tokens`}
      Model: ${data.useModelInput ? "(Using Input)" : data.overrideModel || data.model}
      ${data.useTopP ? "Top P" : "Temperature"}:
      ${data.useTopP ? data.useTopPInput ? "(Using Input)" : data.top_p : data.useTemperatureInput ? "(Using Input)" : data.temperature}
      ${data.useStop ? `Stop: ${data.useStopInput ? "(Using Input)" : data.stop}` : ""}
      ${(data.frequencyPenalty ?? 0) !== 0 ? `Frequency Penalty: ${data.useFrequencyPenaltyInput ? "(Using Input)" : data.frequencyPenalty}` : ""}
      ${(data.presencePenalty ?? 0) !== 0 ? `Presence Penalty: ${data.usePresencePenaltyInput ? "(Using Input)" : data.presencePenalty}` : ""}
    `.trim();
  },
  process: async (data, node, inputs, context) => {
    const output = {};
    const model = getInputOrData(data, inputs, "model");
    const temperature = getInputOrData(data, inputs, "temperature", "number");
    const topP = data.useTopPInput ? coerceTypeOptional(inputs["top_p"], "number") ?? data.top_p : data.top_p;
    const useTopP = getInputOrData(data, inputs, "useTopP", "boolean");
    const stop = data.useStopInput ? data.useStop ? coerceTypeOptional(inputs["stop"], "string") ?? data.stop : void 0 : data.stop;
    const presencePenalty = getInputOrData(data, inputs, "presencePenalty", "number");
    const frequencyPenalty = getInputOrData(data, inputs, "frequencyPenalty", "number");
    const numberOfChoices = getInputOrData(data, inputs, "numberOfChoices", "number");
    const endpoint = getInputOrData(data, inputs, "endpoint");
    const overrideModel = getInputOrData(data, inputs, "overrideModel");
    const seed = getInputOrData(data, inputs, "seed", "number");
    const responseFormat = getInputOrData(data, inputs, "responseFormat");
    const toolChoiceMode = getInputOrData(data, inputs, "toolChoice", "string");
    const predictedOutput = data.usePredictedOutput ? coerceTypeOptional(inputs["predictedOutput"], "string[]") : void 0;
    const toolChoice = !toolChoiceMode || !data.enableFunctionUse ? void 0 : toolChoiceMode === "function" ? {
      type: "function",
      function: {
        name: getInputOrData(data, inputs, "toolChoiceFunction", "string")
      }
    } : toolChoiceMode;
    let responseSchema;
    const responseSchemaInput = inputs["responseSchema"];
    if ((responseSchemaInput == null ? void 0 : responseSchemaInput.type) === "gpt-function") {
      responseSchema = responseSchemaInput.value.parameters;
    } else if (responseSchemaInput != null) {
      responseSchema = coerceType(responseSchemaInput, "object");
    }
    const openaiResponseFormat = !(responseFormat == null ? void 0 : responseFormat.trim()) ? void 0 : responseFormat === "json" ? {
      type: "json_object"
    } : responseFormat === "json_schema" ? {
      type: "json_schema",
      json_schema: {
        name: getInputOrData(data, inputs, "responseSchemaName", "string") || "response_schema",
        strict: true,
        schema: responseSchema ?? {}
      }
    } : {
      type: "text"
    };
    const headersFromData = (data.headers ?? []).reduce(
      (acc, header) => {
        acc[header.key] = header.value;
        return acc;
      },
      {}
    );
    const additionalHeaders = data.useHeadersInput ? coerceTypeOptional(inputs["headers"], "object") ?? headersFromData : headersFromData;
    const additionalParametersFromData = (data.additionalParameters ?? []).reduce(
      (acc, param) => {
        acc[param.key] = Number.isNaN(parseFloat(param.value)) ? param.value : parseFloat(param.value);
        return acc;
      },
      {}
    );
    const additionalParameters = data.useAdditionalParametersInput ? coerceTypeOptional(inputs["additionalParameters"], "object") ?? additionalParametersFromData : additionalParametersFromData;
    const finalModel = data.useModelInput && inputs["model"] != null ? model : overrideModel || model;
    const functions = coerceTypeOptional(inputs["functions"], "gpt-function[]");
    const tools = (functions ?? []).map(
      (fn) => ({
        function: fn,
        type: "function"
      })
    );
    const { messages } = getChatNodeMessages(inputs);
    const completionMessages = await Promise.all(
      messages.map((message) => chatMessageToOpenAIChatCompletionMessage(message))
    );
    let { maxTokens } = data;
    const openaiModel = {
      ...openaiModels[model] ?? {
        maxTokens: data.overrideMaxTokens ?? 8192,
        cost: {
          completion: 0,
          prompt: 0
        },
        displayName: "Custom Model"
      }
    };
    if (data.overrideMaxTokens) {
      openaiModel.maxTokens = data.overrideMaxTokens;
    }
    const isMultiResponse = data.useNumberOfChoicesInput || (data.numberOfChoices ?? 1) > 1;
    const configuredEndpoint = endpoint || context.settings.openAiEndpoint || DEFAULT_CHAT_ENDPOINT;
    const resolvedEndpointAndHeaders = context.getChatNodeEndpoint ? await context.getChatNodeEndpoint(configuredEndpoint, finalModel) : {
      endpoint: configuredEndpoint,
      headers: {}
    };
    const allAdditionalHeaders = cleanHeaders({
      ...context.settings.chatNodeHeaders,
      ...additionalHeaders,
      ...resolvedEndpointAndHeaders.headers
    });
    let inputTokenCount = 0;
    const tokenizerInfo = {
      node,
      model: finalModel,
      endpoint: resolvedEndpointAndHeaders.endpoint
    };
    if (!data.useServerTokenCalculation) {
      inputTokenCount = await context.tokenizer.getTokenCountForMessages(messages, functions, tokenizerInfo);
      if (inputTokenCount >= openaiModel.maxTokens) {
        throw new Error(
          `The model ${model} can only handle ${openaiModel.maxTokens} tokens, but ${inputTokenCount} were provided in the prompts alone.`
        );
      }
      if (inputTokenCount + maxTokens > openaiModel.maxTokens) {
        const message = `The model can only handle a maximum of ${openaiModel.maxTokens} tokens, but the prompts and max tokens together exceed this limit. The max tokens has been reduced to ${openaiModel.maxTokens - inputTokenCount}.`;
        addWarning(output, message);
        maxTokens = Math.floor((openaiModel.maxTokens - inputTokenCount) * 0.95);
      }
    }
    const predictionObject = predictedOutput ? predictedOutput.length === 1 ? { type: "content", content: predictedOutput[0] } : { type: "content", content: predictedOutput.map((part) => ({ type: "text", text: part })) } : void 0;
    const voice = getInputOrData(data, inputs, "audioVoice");
    let modalities = [];
    if (data.modalitiesIncludeText) {
      modalities.push("text");
    }
    if (data.modalitiesIncludeAudio) {
      modalities.push("audio");
      if (!voice) {
        throw new Error("Audio voice must be specified if audio is enabled.");
      }
    }
    if (modalities.length === 0) {
      modalities = void 0;
    }
    const audio = (modalities == null ? void 0 : modalities.includes("audio")) ? {
      voice,
      format: getInputOrData(data, inputs, "audioFormat") ?? "wav"
    } : void 0;
    const reasoningEffort = getInputOrData(data, inputs, "reasoningEffort");
    const includeReasoningEffort = finalModel.startsWith("o1") || finalModel.startsWith("o3");
    try {
      return await (0, import_p_retry.default)(
        async () => {
          var _a, _b, _c, _d, _e, _f;
          const options2 = {
            messages: completionMessages,
            model: finalModel,
            top_p: useTopP ? topP : void 0,
            n: numberOfChoices,
            frequency_penalty: frequencyPenalty,
            presence_penalty: presencePenalty,
            stop: stop || void 0,
            tools: tools.length > 0 ? tools : void 0,
            endpoint: resolvedEndpointAndHeaders.endpoint,
            seed,
            response_format: openaiResponseFormat,
            tool_choice: toolChoice,
            prediction: predictionObject,
            modalities,
            audio,
            reasoning_effort: includeReasoningEffort ? reasoningEffort : void 0,
            ...additionalParameters
          };
          const isO1Beta = finalModel.startsWith("o1-preview") || finalModel.startsWith("o1-mini");
          const isReasoningModel = finalModel.startsWith("o1") || finalModel.startsWith("o3");
          if (isReasoningModel) {
            options2.max_completion_tokens = maxTokens;
          } else {
            options2.temperature = useTopP ? void 0 : temperature;
            options2.max_tokens = maxTokens;
          }
          const cacheKey = JSON.stringify(options2);
          if (data.cache) {
            const cached = cache.get(cacheKey);
            if (cached) {
              return cached;
            }
          }
          const startTime = Date.now();
          if (isO1Beta || audio) {
            const response = await chatCompletions({
              auth: {
                apiKey: context.settings.openAiKey ?? "",
                organization: context.settings.openAiOrganization
              },
              headers: allAdditionalHeaders,
              signal: context.signal,
              timeout: context.settings.chatNodeTimeout,
              ...options2
            });
            if (isMultiResponse) {
              output["response"] = {
                type: "string[]",
                value: response.choices.map((c) => c.message.content)
              };
            } else {
              output["response"] = {
                type: "string",
                value: response.choices[0].message.content ?? ""
              };
            }
            if (!isMultiResponse) {
              output["all-messages"] = {
                type: "chat-message[]",
                value: [
                  ...messages,
                  {
                    type: "assistant",
                    message: response.choices[0].message.content ?? "",
                    function_calls: void 0,
                    isCacheBreakpoint: false,
                    function_call: void 0
                  }
                ]
              };
            }
            if (modalities == null ? void 0 : modalities.includes("audio")) {
              const audioData = response.choices[0].message.audio;
              output["audio"] = {
                type: "audio",
                value: {
                  data: base64ToUint8Array(audioData.data),
                  mediaType: audioFormatToMediaType(audio.format)
                }
              };
              output["audioTranscript"] = {
                type: "string",
                value: response.choices[0].message.audio.transcript
              };
            }
            output["duration"] = { type: "number", value: Date.now() - startTime };
            if (response.usage) {
              output["usage"] = {
                type: "object",
                value: response.usage
              };
              const costs = finalModel in openaiModels ? openaiModels[finalModel].cost : void 0;
              const promptCostPerThousand2 = (costs == null ? void 0 : costs.prompt) ?? 0;
              const completionCostPerThousand2 = (costs == null ? void 0 : costs.completion) ?? 0;
              const audioPromptCostPerThousand = costs ? "audioPrompt" in costs ? costs.audioPrompt : 0 : 0;
              const audioCompletionCostPerThousand = costs ? "audioCompletion" in costs ? costs.audioCompletion : 0 : 0;
              const promptCost2 = getCostForTokens(
                response.usage.prompt_tokens_details.text_tokens,
                "prompt",
                promptCostPerThousand2
              );
              const completionCost2 = getCostForTokens(
                response.usage.completion_tokens_details.text_tokens,
                "completion",
                completionCostPerThousand2
              );
              const audioPromptCost = getCostForTokens(
                response.usage.prompt_tokens_details.audio_tokens,
                "prompt",
                audioPromptCostPerThousand
              );
              const audioCompletionCost = getCostForTokens(
                response.usage.completion_tokens_details.audio_tokens,
                "completion",
                audioCompletionCostPerThousand
              );
              output["cost"] = {
                type: "number",
                value: promptCost2 + completionCost2 + audioPromptCost + audioCompletionCost
              };
            }
            Object.freeze(output);
            cache.set(cacheKey, output);
            return output;
          }
          const chunks = streamChatCompletions({
            auth: {
              apiKey: context.settings.openAiKey ?? "",
              organization: context.settings.openAiOrganization
            },
            headers: allAdditionalHeaders,
            signal: context.signal,
            timeout: context.settings.chatNodeTimeout,
            ...options2
          });
          const responseChoicesParts = [];
          const functionCalls = [];
          let usage;
          let throttleLastCalledTime = Date.now();
          const onPartialOutput = (output2) => {
            var _a2;
            const now = Date.now();
            if (now - throttleLastCalledTime > (context.settings.throttleChatNode ?? 100)) {
              (_a2 = context.onPartialOutputs) == null ? void 0 : _a2.call(context, output2);
              throttleLastCalledTime = now;
            }
          };
          for await (const chunk of chunks) {
            if (chunk.usage) {
              usage = chunk.usage;
            }
            if (!chunk.choices) {
              continue;
            }
            for (const { delta, index } of chunk.choices) {
              if (delta.content != null) {
                responseChoicesParts[index] ??= [];
                responseChoicesParts[index].push(delta.content);
              }
              if (delta.tool_calls) {
                functionCalls[index] ??= [];
                for (const toolCall of delta.tool_calls) {
                  functionCalls[index][toolCall.index] ??= {
                    type: "function",
                    arguments: "",
                    lastParsedArguments: void 0,
                    name: "",
                    id: ""
                  };
                  if (toolCall.id) {
                    functionCalls[index][toolCall.index].id = toolCall.id;
                  }
                  if (toolCall.function.name) {
                    functionCalls[index][toolCall.index].name += toolCall.function.name;
                  }
                  if (toolCall.function.arguments) {
                    functionCalls[index][toolCall.index].arguments += toolCall.function.arguments;
                    try {
                      functionCalls[index][toolCall.index].lastParsedArguments = JSON.parse(
                        functionCalls[index][toolCall.index].arguments
                      );
                    } catch (error) {
                    }
                  }
                }
              }
            }
            if (isMultiResponse) {
              output["response"] = {
                type: "string[]",
                value: responseChoicesParts.map((parts) => parts.join(""))
              };
            } else {
              output["response"] = {
                type: "string",
                value: ((_a = responseChoicesParts[0]) == null ? void 0 : _a.join("")) ?? ""
              };
            }
            if (functionCalls.length > 0) {
              if (isMultiResponse) {
                output["function-call"] = {
                  type: "object[]",
                  value: functionCalls.map((functionCalls2) => {
                    var _a2, _b2, _c2;
                    return {
                      name: (_a2 = functionCalls2[0]) == null ? void 0 : _a2.name,
                      arguments: (_b2 = functionCalls2[0]) == null ? void 0 : _b2.lastParsedArguments,
                      id: (_c2 = functionCalls2[0]) == null ? void 0 : _c2.id
                    };
                  })
                };
              } else {
                if (data.parallelFunctionCalling) {
                  output["function-calls"] = {
                    type: "object[]",
                    value: functionCalls[0].map((functionCall) => ({
                      name: functionCall.name,
                      arguments: functionCall.lastParsedArguments,
                      id: functionCall.id
                    }))
                  };
                } else {
                  output["function-call"] = {
                    type: "object",
                    value: {
                      name: (_b = functionCalls[0][0]) == null ? void 0 : _b.name,
                      arguments: (_c = functionCalls[0][0]) == null ? void 0 : _c.lastParsedArguments,
                      id: (_d = functionCalls[0][0]) == null ? void 0 : _d.id
                    }
                  };
                }
              }
            }
            onPartialOutput(output);
          }
          (_e = context.onPartialOutputs) == null ? void 0 : _e.call(context, output);
          if (!isMultiResponse) {
            output["all-messages"] = {
              type: "chat-message[]",
              value: [
                ...messages,
                {
                  type: "assistant",
                  message: ((_f = responseChoicesParts[0]) == null ? void 0 : _f.join("")) ?? "",
                  function_call: functionCalls[0] ? {
                    name: functionCalls[0][0].name,
                    arguments: functionCalls[0][0].arguments,
                    // Needs the stringified one here in chat list
                    id: functionCalls[0][0].id
                  } : void 0,
                  function_calls: functionCalls[0] ? functionCalls[0].map((fc) => ({
                    name: fc.name,
                    arguments: fc.arguments,
                    id: fc.id
                  })) : void 0
                }
              ]
            };
          }
          const endTime = Date.now();
          if (responseChoicesParts.length === 0 && functionCalls.length === 0) {
            throw new Error("No response from OpenAI");
          }
          let outputTokenCount = 0;
          if (usage) {
            inputTokenCount = usage.prompt_tokens;
            outputTokenCount = usage.completion_tokens;
          }
          output["in-messages"] = { type: "chat-message[]", value: messages };
          output["requestTokens"] = { type: "number", value: inputTokenCount * (numberOfChoices ?? 1) };
          if (!data.useServerTokenCalculation) {
            let responseTokenCount = 0;
            for (const choiceParts of responseChoicesParts) {
              responseTokenCount += await context.tokenizer.getTokenCountForString(choiceParts.join(), tokenizerInfo);
            }
            outputTokenCount = responseTokenCount;
          }
          output["responseTokens"] = { type: "number", value: outputTokenCount };
          const outputTokensForCostCalculation = (usage == null ? void 0 : usage.completion_tokens_details) ? usage.completion_tokens_details.rejected_prediction_tokens > 0 ? usage.completion_tokens_details.rejected_prediction_tokens : usage.completion_tokens : outputTokenCount;
          const promptCostPerThousand = model in openaiModels ? openaiModels[model].cost.prompt : 0;
          const completionCostPerThousand = model in openaiModels ? openaiModels[model].cost.completion : 0;
          const promptCost = getCostForTokens(inputTokenCount, "prompt", promptCostPerThousand);
          const completionCost = getCostForTokens(
            outputTokensForCostCalculation,
            "completion",
            completionCostPerThousand
          );
          const cost = promptCost + completionCost;
          if (usage) {
            output["usage"] = {
              type: "object",
              value: {
                ...usage,
                prompt_cost: promptCost,
                completion_cost: completionCost,
                total_cost: cost
              }
            };
          } else {
            output["usage"] = {
              type: "object",
              value: {
                prompt_tokens: inputTokenCount,
                completion_tokens: outputTokenCount
              }
            };
          }
          output["cost"] = { type: "number", value: cost };
          output["__hidden_token_count"] = { type: "number", value: inputTokenCount + outputTokenCount };
          const duration = endTime - startTime;
          output["duration"] = { type: "number", value: duration };
          Object.freeze(output);
          cache.set(cacheKey, output);
          return output;
        },
        {
          forever: true,
          retries: 1e4,
          maxRetryTime: 1e3 * 60 * 5,
          factor: 2.5,
          minTimeout: 500,
          maxTimeout: 5e3,
          randomize: true,
          signal: context.signal,
          onFailedAttempt(err) {
            var _a, _b;
            if (err.toString().includes("fetch failed") && err.cause) {
              const cause = getError(err.cause) instanceof AggregateError ? err.cause.errors[0] : getError(err.cause);
              err = cause;
            }
            context.trace(`ChatNode failed, retrying: ${err.toString()}`);
            if (context.signal.aborted) {
              throw new Error("Aborted");
            }
            const { retriesLeft } = err;
            if (!(err instanceof OpenAIError)) {
              if ("code" in err) {
                throw err;
              }
              return;
            }
            if (err.status === 429) {
              if (retriesLeft) {
                (_a = context.onPartialOutputs) == null ? void 0 : _a.call(context, {
                  ["response"]: {
                    type: "string",
                    value: "OpenAI API rate limit exceeded, retrying..."
                  }
                });
                return;
              }
            }
            if (err.status === 408) {
              if (retriesLeft) {
                (_b = context.onPartialOutputs) == null ? void 0 : _b.call(context, {
                  ["response"]: {
                    type: "string",
                    value: "OpenAI API timed out, retrying..."
                  }
                });
                return;
              }
            }
            if (err.status >= 400 && err.status < 500) {
              throw new Error(err.message);
            }
          }
        }
      );
    } catch (error) {
      context.trace(getError(error).stack ?? "Missing stack");
      throw new Error(`Error processing ChatNode: ${error.message}`);
    }
  }
};
function getChatNodeMessages(inputs) {
  const prompt = inputs["prompt"];
  let messages = (0, import_ts_pattern3.match)(prompt).with({ type: "chat-message" }, (p) => [p.value]).with({ type: "chat-message[]" }, (p) => p.value).with({ type: "string" }, (p) => [{ type: "user", message: p.value }]).with({ type: "string[]" }, (p) => p.value.map((v) => ({ type: "user", message: v }))).otherwise((p) => {
    if (!p) {
      return [];
    }
    if (isArrayDataValue(p)) {
      const stringValues = p.value.map(
        (v) => coerceType(
          {
            type: getScalarTypeOf(p.type),
            value: v
          },
          "string"
        )
      );
      return stringValues.filter((v) => v != null).map((v) => ({ type: "user", message: v }));
    }
    const coercedMessage = coerceTypeOptional(p, "chat-message");
    if (coercedMessage != null) {
      return [coercedMessage];
    }
    const coercedString = coerceTypeOptional(p, "string");
    return coercedString != null ? [{ type: "user", message: coerceType(p, "string") }] : [];
  });
  const systemPrompt = inputs["systemPrompt"];
  if (systemPrompt) {
    if (messages.length > 0 && messages.at(0).type === "system") {
      messages.splice(0, 1);
    }
    messages = [{ type: "system", message: coerceType(systemPrompt, "string") }, ...messages];
  }
  return { messages, systemPrompt };
}
function getCostForTokens(tokenCount, type, costPerThousand) {
  return tokenCount / 1e3 * costPerThousand;
}
function audioFormatToMediaType(format) {
  switch (format) {
    case "wav":
      return "audio/wav";
    case "mp3":
      return "audio/mpeg";
    case "flac":
      return "audio/flac";
    case "opus":
      return "audio/opus";
    case "pcm16":
      return "audio/wav";
  }
}

// src/model/nodes/ChatNode.ts
var ChatNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "chat",
      title: "Chat",
      id: (0, import_non_secure4.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: ChatNodeBase.defaultData()
    };
    return chartNode;
  }
  getInputDefinitions() {
    return ChatNodeBase.getInputDefinitions(this.data);
  }
  getOutputDefinitions() {
    return ChatNodeBase.getOutputDefinitions(this.data);
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent4.dedent`
        Makes a call to an LLM chat model. Supports GPT and any OpenAI-compatible API. The settings contains many options for tweaking the model's behavior.

        The \`System Prompt\` input specifies a system prompt as the first message to the model. This is useful for providing context to the model.

        The \`Prompt\` input takes one or more strings or chat-messages (from a Prompt node) to send to the model.
      `,
      contextMenuTitle: "Chat",
      infoBoxTitle: "Chat Node",
      group: ["Common", "AI"]
    };
  }
  getEditors() {
    return ChatNodeBase.getEditors();
  }
  getBody() {
    return ChatNodeBase.getBody(this.data);
  }
  async process(inputs, context) {
    return ChatNodeBase.process(this.data, this.chartNode, inputs, context);
  }
};
var chatNode = nodeDefinition(ChatNodeImpl, "Chat");

// src/model/nodes/PromptNode.ts
var import_non_secure5 = require("nanoid/non-secure");
var import_lodash_es5 = require("lodash");
var import_ts_dedent5 = require("ts-dedent");
var import_ts_pattern4 = require("ts-pattern");
var PromptNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "prompt",
      title: "Prompt",
      id: (0, import_non_secure5.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        type: "user",
        useTypeInput: false,
        promptText: "{{input}}",
        enableFunctionCall: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    let inputs = [];
    if (this.data.enableFunctionCall) {
      inputs.push({
        id: "function-call",
        title: "Function Call",
        dataType: "object"
      });
    }
    if (this.data.useTypeInput) {
      inputs.push({
        id: "type",
        title: "Type",
        dataType: "string"
      });
    }
    if (this.data.useNameInput) {
      inputs.push({
        id: "name",
        title: "Name/ID",
        dataType: "string"
      });
    }
    if (this.data.useIsCacheBreakpointInput) {
      inputs.push({
        id: "isCacheBreakpoint",
        title: "Is Cache Breakpoint",
        dataType: "boolean"
      });
    }
    const inputNames = extractInterpolationVariables(this.data.promptText);
    inputs = [
      ...inputs,
      ...(inputNames == null ? void 0 : inputNames.map((inputName) => {
        return {
          id: inputName,
          title: inputName,
          dataType: "string",
          required: false
        };
      })) ?? []
    ];
    return inputs;
  }
  getOutputDefinitions() {
    const outputs = [
      {
        id: "output",
        title: "Output",
        dataType: "chat-message"
      }
    ];
    if (this.chartNode.data.computeTokenCount) {
      outputs.push({
        id: "tokenCount",
        title: "Token Count",
        dataType: "number"
      });
    }
    return outputs;
  }
  getEditors() {
    return [
      {
        type: "custom",
        customEditorId: "PromptNodeAiAssist",
        label: "Generate Using AI"
      },
      {
        type: "dropdown",
        label: "Type",
        options: [
          { value: "system", label: "System" },
          { value: "user", label: "User" },
          { value: "assistant", label: "Assistant" },
          { value: "function", label: "Function" }
        ],
        dataKey: "type",
        useInputToggleDataKey: "useTypeInput"
      },
      {
        type: "string",
        label: "Name",
        dataKey: "name",
        useInputToggleDataKey: "useNameInput",
        hideIf: (data) => data.type !== "function",
        helperMessage: "For OpenAI, this is the tool call ID. Otherwise, it is the name of the function that is outputting the message."
      },
      {
        type: "toggle",
        label: "Enable Function Call",
        dataKey: "enableFunctionCall",
        hideIf: (data) => data.type !== "assistant"
      },
      {
        type: "toggle",
        label: "Compute Token Count",
        dataKey: "computeTokenCount"
      },
      {
        type: "toggle",
        label: "Is Cache Breakpoint",
        dataKey: "isCacheBreakpoint",
        helperMessage: "For Anthropic, marks this message as a cache breakpoint - this message and every message before it will be cached using Prompt Caching.",
        useInputToggleDataKey: "useIsCacheBreakpointInput"
      },
      {
        type: "code",
        label: "Prompt Text",
        dataKey: "promptText",
        language: "prompt-interpolation-markdown",
        theme: "prompt-interpolation"
      }
    ];
  }
  getBody() {
    return [
      {
        type: "markdown",
        text: import_ts_dedent5.dedent`
          _${typeDisplay[this.data.type]}${this.data.name ? ` (${this.data.name})` : ""}_ ${this.data.isCacheBreakpoint ? " (Cache Breakpoint)" : ""}
      `
      },
      {
        type: "colorized",
        text: this.data.promptText.split("\n").slice(0, 15).join("\n").trim(),
        language: "prompt-interpolation-markdown",
        theme: "prompt-interpolation"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent5.dedent`
        Outputs a chat message, which is a string of text with an attached "type" saying who sent the message (User, Assistant, System) and optionally an attached "name".

        Also provides the same <span style="color: var(--primary)">{{interpolation}}</span> capabilities as a Text node.

        Can change one chat message type into another chat message type. For example, changing a User message into a System message.
      `,
      infoBoxTitle: "Prompt Node",
      contextMenuTitle: "Prompt",
      group: ["Text"]
    };
  }
  async process(inputs, context) {
    const inputMap = (0, import_lodash_es5.mapValues)(inputs, (input) => coerceType(input, "string"));
    const outputValue = interpolate(this.chartNode.data.promptText, inputMap);
    const type = getInputOrData(this.data, inputs, "type", "string");
    const isCacheBreakpoint = getInputOrData(this.data, inputs, "isCacheBreakpoint", "boolean");
    if (["assistant", "system", "user", "function"].includes(type) === false) {
      throw new Error(`Invalid type: ${type}`);
    }
    const message = (0, import_ts_pattern4.match)(type).with(
      "system",
      (type2) => ({
        type: type2,
        message: outputValue,
        isCacheBreakpoint
      })
    ).with(
      "user",
      (type2) => ({
        type: type2,
        message: outputValue,
        isCacheBreakpoint
      })
    ).with("assistant", (type2) => {
      let functionCall = this.data.enableFunctionCall ? coerceTypeOptional(inputs["function-call"], "object") : void 0;
      if (!(functionCall == null ? void 0 : functionCall.name) || !(functionCall == null ? void 0 : functionCall.arguments)) {
        functionCall = void 0;
      }
      if ((functionCall == null ? void 0 : functionCall.arguments) && typeof functionCall.arguments !== "string") {
        functionCall.arguments = JSON.stringify(functionCall.arguments);
      }
      return {
        type: type2,
        message: outputValue,
        function_call: functionCall,
        function_calls: functionCall ? [functionCall] : void 0,
        isCacheBreakpoint
      };
    }).with(
      "function",
      (type2) => ({
        type: type2,
        message: outputValue,
        name: getInputOrData(this.data, inputs, "name", "string"),
        isCacheBreakpoint
      })
    ).otherwise(() => {
      throw new Error(`Invalid chat-message type: ${type}`);
    });
    const outputs = {
      ["output"]: {
        type: "chat-message",
        value: message
      }
    };
    if (this.chartNode.data.computeTokenCount) {
      const tokenCount = await context.tokenizer.getTokenCountForMessages([message], void 0, {
        node: this.chartNode
      });
      outputs["tokenCount"] = {
        type: "number",
        value: tokenCount
      };
    }
    return outputs;
  }
};
var promptNode = nodeDefinition(PromptNodeImpl, "Prompt");
var typeDisplay = {
  assistant: "Assistant",
  system: "System",
  user: "User",
  function: "Function"
};

// src/model/nodes/ExtractRegexNode.ts
var import_non_secure6 = require("nanoid/non-secure");
var import_ts_dedent6 = require("ts-dedent");
var ExtractRegexNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "extractRegex",
      title: "Extract Regex",
      id: (0, import_non_secure6.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        regex: "([a-zA-Z]+)",
        useRegexInput: false,
        errorOnFailed: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "input",
        title: "Input",
        dataType: "string",
        required: true,
        coerced: false
      }
    ];
    if (this.chartNode.data.useRegexInput) {
      inputs.push({
        id: "regex",
        title: "Regex",
        dataType: "string",
        required: false,
        coerced: false
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    const regex = this.chartNode.data.regex;
    try {
      const regExp = new RegExp(regex, "g");
      const captureGroupCount = countCaptureGroups(regExp);
      const outputs = [];
      for (let i = 0; i < captureGroupCount; i++) {
        outputs.push({
          id: `output${i + 1}`,
          title: `Output ${i + 1}`,
          dataType: "string"
        });
      }
      outputs.push({
        id: "matches",
        title: "Matches",
        dataType: "string[]"
      });
      outputs.push(
        {
          id: "succeeded",
          title: "Succeeded",
          dataType: "boolean"
        },
        {
          id: "failed",
          title: "Failed",
          dataType: "boolean"
        }
      );
      return outputs;
    } catch (err) {
      return [];
    }
  }
  getEditors() {
    return [
      {
        type: "custom",
        customEditorId: "ExtractRegexNodeAiAssist",
        label: "AI Assist"
      },
      {
        type: "toggle",
        label: "Error on failed",
        dataKey: "errorOnFailed"
      },
      {
        type: "toggle",
        label: "Multiline mode",
        dataKey: "multilineMode"
      },
      {
        type: "code",
        label: "Regex",
        dataKey: "regex",
        useInputToggleDataKey: "useRegexInput",
        language: "regex"
      }
    ];
  }
  getBody() {
    return this.data.useRegexInput ? "(Using regex input)" : this.data.regex;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent6.dedent`
        Extracts data from the input text using the configured regular expression. The regular expression can contain capture groups to extract specific parts of the text.

        Each capture group corresponds to an output port of the node.
      `,
      infoBoxTitle: "Extract With Regex Node",
      contextMenuTitle: "Extract With Regex",
      group: ["Text"]
    };
  }
  async process(inputs) {
    const inputString = expectType(inputs["input"], "string");
    const regex = expectTypeOptional(inputs["regex"], "string") ?? this.chartNode.data.regex;
    const regExp = new RegExp(regex, this.data.multilineMode ? "gm" : "g");
    let matches = [];
    let match15;
    let firstMatch;
    while ((match15 = regExp.exec(inputString)) !== null) {
      if (!firstMatch) {
        firstMatch = match15;
      }
      matches.push(match15[1]);
    }
    matches = matches.filter((m) => m);
    if (matches.length === 0 && this.chartNode.data.errorOnFailed) {
      throw new Error(`No match found for regex ${regex}`);
    }
    const outputArray = {
      type: "string[]",
      value: matches
    };
    if (!firstMatch) {
      if (this.chartNode.data.errorOnFailed) {
        throw new Error(`No match found for regex ${regex}`);
      }
      return {
        ["succeeded"]: {
          type: "boolean",
          value: false
        },
        ["failed"]: {
          type: "boolean",
          value: true
        }
      };
    }
    const output = {};
    for (let i = 1; i < firstMatch.length; i++) {
      output[`output${i}`] = {
        type: "string",
        value: firstMatch[i]
      };
    }
    output["matches"] = outputArray;
    output["succeeded"] = {
      type: "boolean",
      value: true
    };
    output["failed"] = {
      type: "boolean",
      value: false
    };
    return output;
  }
};
function countCaptureGroups(regex) {
  const regexSource = regex.source;
  let count = 0;
  let inCharacterClass = false;
  for (let i = 0; i < regexSource.length; i++) {
    const currentChar = regexSource[i];
    const prevChar = i > 0 ? regexSource[i - 1] : null;
    if (currentChar === "[" && prevChar !== "\\") {
      inCharacterClass = true;
    } else if (currentChar === "]" && prevChar !== "\\") {
      inCharacterClass = false;
    } else if (currentChar === "(" && prevChar !== "\\" && !inCharacterClass) {
      if (regexSource[i + 1] !== "?" || regexSource[i + 2] === ":") {
        count++;
      }
    }
  }
  return count;
}
var extractRegexNode = nodeDefinition(ExtractRegexNodeImpl, "Extract Regex");

// src/model/nodes/CodeNode.ts
var import_non_secure7 = require("nanoid/non-secure");
var import_ts_dedent7 = require("ts-dedent");
var maskInput = (name) => name.trim().replace(/[^a-zA-Z0-9_]/g, "_");
var asValidNames = (names) => Array(...new Set(names.map(maskInput))).filter(Boolean);
var CodeNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "code",
      title: "Code",
      id: (0, import_non_secure7.nanoid)(),
      visualData: {
        x: 0,
        y: 0
      },
      data: {
        code: import_ts_dedent7.dedent`
          // This is a code node, you can write and JS in here and it will be executed.
          // Inputs are accessible via an object \`inputs\` and data is typed (i.e. inputs.foo.type, inputs.foo.value)
          // Return an object with named outputs that match the output names specified in the node's config.
          // Output values must by typed as well (e.g. { bar: { type: 'string', value: 'bar' } }
          return {
            output1: {
              type: inputs.input1.type,
              value: inputs.input1.value
            }
          };
        `,
        inputNames: "input1",
        outputNames: "output1"
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputNames = this.data.inputNames ? Array.isArray(this.data.inputNames) ? this.data.inputNames : [this.data.inputNames] : [];
    return asValidNames(inputNames).map((inputName) => {
      return {
        type: "any",
        id: inputName.trim(),
        title: inputName.trim(),
        dataType: "string",
        required: false
      };
    });
  }
  getOutputDefinitions() {
    const outputNames = this.data.outputNames ? Array.isArray(this.data.outputNames) ? this.data.outputNames : [this.data.outputNames] : [];
    return asValidNames(outputNames).map((outputName) => {
      return {
        id: outputName.trim(),
        title: outputName.trim(),
        dataType: "any"
      };
    });
  }
  getEditors() {
    return [
      {
        type: "custom",
        customEditorId: "CodeNodeAIAssist",
        label: "AI Assist"
      },
      {
        type: "code",
        label: "Code",
        dataKey: "code",
        language: "javascript"
      },
      {
        type: "stringList",
        label: "Inputs",
        dataKey: "inputNames"
      },
      {
        type: "stringList",
        label: "Outputs",
        dataKey: "outputNames"
      }
    ];
  }
  getBody() {
    const trimmed = this.data.code.split("\n").slice(0, 15).map((line) => line.length > 50 ? line.slice(0, 50) + "..." : line).join("\n").trim();
    return {
      type: "colorized",
      text: trimmed,
      language: "javascript",
      fontSize: 12,
      fontFamily: "monospace"
    };
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent7.dedent`
        Executes a piece of JavaScript code. See the Rivet Documentation for more information on how to write code for the Code Node.
      `,
      infoBoxTitle: "Code Node",
      contextMenuTitle: "Code",
      group: ["Advanced"]
    };
  }
  async process(inputs) {
    const codeFunction = new Function("inputs", this.chartNode.data.code);
    const outputs = codeFunction(inputs);
    if (outputs == null || typeof outputs !== "object" || "then" in outputs && typeof outputs.then === "function") {
      throw new Error("Code node must return an object with output values.");
    }
    const missingOutputs = this.getOutputDefinitions().filter((output) => !(output.id in outputs));
    if (missingOutputs.length > 0) {
      throw new Error(
        `Code node must return an object with output values for all outputs. To not run an output, return { "type": "control-flow-excluded", "value": undefiend }. To return undefined, return { "type": "any", "value": undefined }. Missing: ${missingOutputs.map((output) => output.id).join(", ")}`
      );
    }
    return outputs;
  }
};
var codeNode = nodeDefinition(CodeNodeImpl, "Code");

// src/model/nodes/MatchNode.ts
var import_non_secure8 = require("nanoid/non-secure");
var import_ts_dedent8 = require("ts-dedent");
var MatchNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "match",
      title: "Match",
      id: (0, import_non_secure8.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        cases: ["YES", "NO"]
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "input",
        title: "Test",
        dataType: "string",
        required: true,
        description: "The value that will be tested against each of the cases."
      },
      {
        id: "value",
        title: "Value",
        dataType: "any",
        description: "The value passed through to the output port that matches. If unconnected, the test value will be passed through."
      }
    ];
    return inputs;
  }
  getOutputDefinitions() {
    var _a;
    const outputs = [];
    for (let i = 0; i < this.data.cases.length; i++) {
      outputs.push({
        id: `case${i + 1}`,
        title: ((_a = this.data.cases[i]) == null ? void 0 : _a.trim()) ? this.data.cases[i] : `Case ${i + 1}`,
        dataType: "string",
        description: `The 'value' (or 'test' if value is unconnected) passed through if the test value matches this regex: /${this.data.cases[i]}/`
      });
    }
    outputs.push({
      id: "unmatched",
      title: "Unmatched",
      dataType: "string",
      description: "The value (or test if value is unconnected) passed through if no regexes match."
    });
    return outputs;
  }
  getBody() {
    return import_ts_dedent8.dedent`
      ${this.data.exclusive ? "First Matching Case" : "All Matching Cases"}
      ${this.data.cases.length} Cases
    `;
  }
  getEditors() {
    return [
      {
        type: "toggle",
        dataKey: "exclusive",
        label: "Exclusive",
        helperMessage: "If enabled, only the first matching branch will be ran."
      },
      {
        type: "stringList",
        dataKey: "cases",
        label: "Cases",
        placeholder: "Case (regular expression)",
        helperMessage: "(Regular expressions)"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent8.dedent`
        Any number of regular expressions can be configured, each corresponding to an output of the node. The output port of the first matching regex will be ran, and all other output ports will not be ran.
      `,
      infoBoxTitle: "Match Node",
      contextMenuTitle: "Match",
      group: ["Logic"]
    };
  }
  async process(inputs) {
    const inputString = coerceType(inputs["input"], "string");
    const value = inputs["value"];
    const outputType = value === void 0 ? "string" : value.type;
    const outputValue = value === void 0 ? inputString : value.value;
    const cases = this.data.cases;
    let matched = false;
    const output = {};
    for (let i = 0; i < cases.length; i++) {
      const regExp = new RegExp(cases[i]);
      const match15 = regExp.test(inputString);
      const canMatch = !this.data.exclusive || !matched;
      if (match15 && canMatch) {
        matched = true;
        output[`case${i + 1}`] = {
          type: outputType,
          value: outputValue
        };
      } else {
        output[`case${i + 1}`] = {
          type: "control-flow-excluded",
          value: void 0
        };
      }
    }
    if (!matched) {
      output["unmatched"] = {
        type: outputType,
        value: outputValue
      };
    } else {
      output["unmatched"] = {
        type: "control-flow-excluded",
        value: void 0
      };
    }
    return output;
  }
};
var matchNode = nodeDefinition(MatchNodeImpl, "Match");

// src/model/nodes/IfNode.ts
var import_non_secure9 = require("nanoid/non-secure");
var import_ts_dedent9 = require("ts-dedent");
var IfNodeImpl = class extends NodeImpl {
  static create = () => {
    const chartNode = {
      type: "if",
      title: "If",
      id: (0, import_non_secure9.nanoid)(),
      data: {
        // Legacy behavior is false
        unconnectedControlFlowExcluded: true
      },
      visualData: {
        x: 0,
        y: 0,
        width: 125
      }
    };
    return chartNode;
  };
  getInputDefinitions() {
    return [
      {
        id: "if",
        title: "If",
        dataType: "any",
        description: "If this is truthy, the value will be passed through the True port. Otherwise, it will be passed through the False port. An unconnected port is considered false."
      },
      {
        id: "value",
        title: "Value",
        dataType: "any",
        description: "The value to pass through the True or False port. If unconnected, it will be undefined."
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "output",
        title: "True",
        dataType: "any",
        description: "The `value` passed through if the condition is truthy."
      },
      {
        id: "falseOutput",
        title: "False",
        dataType: "any",
        description: "The `value` passed through if the condition is falsy."
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent9.dedent`
        Takes in a condition and a value. If the condition is truthy, the value is passed through the True port, and the False port is not ran.
        If the condition is falsy, the value is passed through the False port, and the True port is not ran.
      `,
      infoBoxTitle: "If Node",
      contextMenuTitle: "If",
      group: ["Logic"]
    };
  }
  getEditors() {
    return [
      {
        type: "toggle",
        label: "Don't run unconnected value",
        dataKey: "unconnectedControlFlowExcluded"
      }
    ];
  }
  async process(inputData) {
    const unconnectedValue = this.data.unconnectedControlFlowExcluded ? { type: "control-flow-excluded", value: void 0 } : { type: "any", value: void 0 };
    const ifValue = inputData["if"];
    const value = inputData["value"] ?? unconnectedValue;
    const isFalse = {
      output: {
        type: "control-flow-excluded",
        value: void 0
      },
      falseOutput: value
    };
    if (!ifValue) {
      return isFalse;
    }
    if (ifValue.type === "control-flow-excluded") {
      return isFalse;
    }
    if (ifValue.type === "string" && !ifValue.value) {
      return isFalse;
    }
    if (ifValue.type === "boolean" && !ifValue.value) {
      return isFalse;
    }
    if (ifValue.type === "chat-message") {
      const asString = coerceType(ifValue, "string");
      if (!asString) {
        return isFalse;
      }
    }
    if (ifValue.type.endsWith("[]")) {
      const value2 = ifValue;
      if (!value2.value || value2.value.length === 0) {
        return isFalse;
      }
    }
    return {
      ["output"]: value,
      ["falseOutput"]: {
        type: "control-flow-excluded",
        value: void 0
      }
    };
  }
};
var ifNode = nodeDefinition(IfNodeImpl, "If");

// src/model/nodes/ReadDirectoryNode.ts
var import_non_secure10 = require("nanoid/non-secure");
var import_ts_dedent10 = require("ts-dedent");

// src/utils/paths.ts
function createTreeFromPaths(paths, rootPath) {
  const getParentPaths = (path) => {
    const parts = path.split("/").filter((p) => p);
    return parts.slice(0, -1).map((_, index) => parts.slice(0, index + 1).join("/"));
  };
  const directories = /* @__PURE__ */ new Set();
  paths.forEach((path) => {
    const cleanPath = path.replace(/^\/+|\/+$/g, "");
    getParentPaths(cleanPath).forEach((dir) => directories.add(dir));
    if (path.endsWith("/")) {
      directories.add(cleanPath);
    }
  });
  const root = {
    path: rootPath,
    name: rootPath || "root",
    isDirectory: true,
    children: []
  };
  const nodeMap = /* @__PURE__ */ new Map();
  nodeMap.set(rootPath, root);
  const getOrCreateNode = (fullPath) => {
    const cleanPath = fullPath.replace(/^\/+|\/+$/g, "");
    if (nodeMap.has(cleanPath)) {
      return nodeMap.get(cleanPath);
    }
    const parts = cleanPath.split("/").filter((p) => p);
    const name = parts[parts.length - 1] || cleanPath;
    const node = {
      path: name,
      // Just use the name as the path
      name,
      isDirectory: directories.has(cleanPath),
      children: []
    };
    nodeMap.set(cleanPath, node);
    if (parts.length > 1) {
      const parentPath = parts.slice(0, -1).join("/");
      const parent = getOrCreateNode(parentPath);
      if (!parent.children.some((child) => child.name === name)) {
        parent.children.push(node);
      }
    } else if (cleanPath && rootPath !== cleanPath) {
      if (!root.children.some((child) => child.name === name)) {
        root.children.push(node);
      }
    }
    return node;
  };
  paths.filter((path) => path.trim()).forEach((path) => {
    const cleanPath = path.replace(/^\/+|\/+$/g, "");
    if (cleanPath) {
      getOrCreateNode(cleanPath);
    }
  });
  const sortNode = (node) => {
    node.children.sort((a, b) => {
      if (a.isDirectory !== b.isDirectory) {
        return a.isDirectory ? -1 : 1;
      }
      return a.name.localeCompare(b.name);
    });
    node.children.forEach(sortNode);
  };
  sortNode(root);
  return root;
}

// src/model/nodes/ReadDirectoryNode.ts
var ReadDirectoryNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure10.nanoid)(),
      type: "readDirectory",
      title: "Read Directory",
      visualData: { x: 0, y: 0 },
      data: {
        path: "examples",
        recursive: false,
        usePathInput: false,
        useRecursiveInput: false,
        includeDirectories: false,
        useIncludeDirectoriesInput: false,
        filterGlobs: [],
        useFilterGlobsInput: false,
        relative: false,
        useRelativeInput: false,
        ignores: [],
        useIgnoresInput: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.usePathInput) {
      inputDefinitions.push({
        id: "path",
        title: "Path",
        dataType: "string",
        required: true,
        coerced: false
      });
    }
    if (this.chartNode.data.useRecursiveInput) {
      inputDefinitions.push({
        id: "recursive",
        title: "Recursive",
        dataType: "boolean",
        required: true,
        coerced: false
      });
    }
    if (this.chartNode.data.useIncludeDirectoriesInput) {
      inputDefinitions.push({
        id: "includeDirectories",
        title: "Include Directories",
        dataType: "boolean",
        required: true,
        coerced: false
      });
    }
    if (this.chartNode.data.useFilterGlobsInput) {
      inputDefinitions.push({
        id: "filterGlobs",
        title: "Filter Globs",
        dataType: "string[]",
        required: true,
        coerced: false
      });
    }
    if (this.chartNode.data.useRelativeInput) {
      inputDefinitions.push({
        id: "relative",
        title: "Relative",
        dataType: "boolean",
        required: true,
        coerced: false
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "rootPath",
        title: "Root Path",
        dataType: "string"
      },
      {
        id: "paths",
        title: "Paths",
        dataType: "string[]"
      },
      {
        id: "tree",
        title: "Tree",
        dataType: "object"
      }
    ];
  }
  getBody() {
    return import_ts_dedent10.dedent`
      Path: ${this.data.usePathInput ? "(Input)" : this.data.path}
      Recursive: ${this.data.useRecursiveInput ? "(Input)" : this.data.recursive}
      Include Directories: ${this.data.useIncludeDirectoriesInput ? "(Input)" : this.data.includeDirectories}
      Relative: ${this.data.useRelativeInput ? "(Input)" : this.data.relative}
      Filters: ${this.data.useFilterGlobsInput ? "(Input)" : this.data.filterGlobs.length > 0 ? this.data.filterGlobs.join(", ") : "None"}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent10.dedent`
        Reads the contents of the specified directory and outputs:
        1. An array of filenames
        2. The root path of the search
        3. A tree structure representing the directory hierarchy
      `,
      infoBoxTitle: "Read Directory Node",
      contextMenuTitle: "Read Directory",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    const { nativeApi } = context;
    if (nativeApi == null) {
      throw new Error("This node requires a native API to run.");
    }
    const path = getInputOrData(this.data, inputs, "path");
    const recursive = getInputOrData(this.data, inputs, "recursive", "boolean");
    const includeDirectories = getInputOrData(this.data, inputs, "includeDirectories", "boolean");
    const filterGlobs = getInputOrData(this.data, inputs, "filterGlobs", "string[]");
    const relative = getInputOrData(this.data, inputs, "relative", "boolean");
    const ignores = getInputOrData(this.data, inputs, "ignores", "string[]");
    try {
      const files = await nativeApi.readdir(path, void 0, {
        recursive,
        includeDirectories,
        filterGlobs,
        relative,
        ignores
      });
      const tree = createTreeFromPaths(files, path);
      return {
        ["paths"]: { type: "string[]", value: files },
        ["rootPath"]: { type: "string", value: path },
        ["tree"]: { type: "object", value: tree }
      };
    } catch (err) {
      return {
        ["paths"]: { type: "string[]", value: ["(no such path)"] },
        ["rootPath"]: { type: "string", value: path },
        ["tree"]: {
          type: "object",
          value: {
            path,
            name: path.split("/").pop() || path,
            isDirectory: true,
            children: []
          }
        }
      };
    }
  }
};
var readDirectoryNode = nodeDefinition(ReadDirectoryNodeImpl, "Read Directory");

// src/model/nodes/ReadFileNode.ts
var import_non_secure11 = require("nanoid/non-secure");
var import_ts_dedent11 = require("ts-dedent");
var ReadFileNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure11.nanoid)(),
      type: "readFile",
      title: "Read File",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        path: "",
        asBinary: false,
        usePathInput: true,
        errorOnMissingFile: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.usePathInput) {
      inputDefinitions.push({
        id: "path",
        title: "Path",
        dataType: "string",
        coerced: false
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "content",
        title: "Content",
        dataType: this.data.asBinary ? "binary" : "string"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent11.dedent`
        Reads the contents of the specified file and outputs it as a string.
      `,
      infoBoxTitle: "Read File Node",
      contextMenuTitle: "Read File",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [
      {
        type: "filePathBrowser",
        label: "Path",
        dataKey: "path",
        useInputToggleDataKey: "usePathInput"
      },
      {
        type: "toggle",
        label: "Error on Missing File",
        dataKey: "errorOnMissingFile"
      },
      {
        type: "toggle",
        label: "Read as Binary",
        dataKey: "asBinary"
      }
    ];
  }
  getBody() {
    return import_ts_dedent11.dedent`
      ${this.data.asBinary ? "Read as Binary" : "Read as Text"}
      ${this.data.usePathInput ? "" : `Path: ${this.data.path}`}
    `;
  }
  async process(inputData, context) {
    const { nativeApi } = context;
    if (nativeApi == null) {
      throw new Error("This node requires a native API to run.");
    }
    const path = getInputOrData(this.chartNode.data, inputData, "path");
    try {
      if (this.data.asBinary) {
        const content = await nativeApi.readBinaryFile(path);
        const buffer = await content.arrayBuffer();
        return {
          ["content"]: { type: "binary", value: new Uint8Array(buffer) }
        };
      } else {
        const content = await nativeApi.readTextFile(path, void 0);
        return {
          ["content"]: { type: "string", value: content }
        };
      }
    } catch (err) {
      if (this.chartNode.data.errorOnMissingFile) {
        throw err;
      } else {
        return {
          ["content"]: { type: "control-flow-excluded", value: void 0 }
        };
      }
    }
  }
};
var readFileNode = nodeDefinition(ReadFileNodeImpl, "Read File");

// src/model/nodes/IfElseNode.ts
var import_non_secure12 = require("nanoid/non-secure");
var import_ts_dedent12 = require("ts-dedent");
var IfElseNodeImpl = class extends NodeImpl {
  static create = () => {
    const chartNode = {
      type: "ifElse",
      title: "If/Else",
      id: (0, import_non_secure12.nanoid)(),
      data: {
        // Legacy behavior is false
        unconnectedControlFlowExcluded: true
      },
      visualData: {
        x: 0,
        y: 0,
        width: 175
      }
    };
    return chartNode;
  };
  getInputDefinitions() {
    return [
      {
        id: "if",
        title: "If",
        dataType: "any",
        description: "If this is truthy, the `true` value will be passed through the output port. Otherwise, the `false` value will be passed through the output port. An unconnected port is considered false. A `Not Ran` value is considered false."
      },
      {
        id: "true",
        title: "True",
        dataType: "any",
        description: "The value to pass through the output port if the condition is truthy. "
      },
      {
        id: "false",
        title: "False",
        dataType: "any",
        description: "The value to pass through the output port if the condition is not truthy."
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "output",
        title: "Output",
        dataType: "any",
        description: "The `true` or `false` value, depending on the `if` condition."
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent12.dedent`
        Takes in three inputs: a condition, a true value, and a false value. If the condition is truthy, the true value is passed through the output port. If the condition is not truthy, the false value is passed through the output port.

        This node can "consume" a \`Not Ran\` to continue a graph from that point.
      `,
      infoBoxTitle: "If/Else Node",
      contextMenuTitle: "If/Else",
      group: ["Logic"]
    };
  }
  getEditors() {
    return [
      {
        type: "toggle",
        label: "Don't run unconnected ports",
        dataKey: "unconnectedControlFlowExcluded"
      }
    ];
  }
  async process(inputData) {
    const unconnectedValue = this.data.unconnectedControlFlowExcluded ? { type: "control-flow-excluded", value: void 0 } : {
      type: "any",
      value: void 0
    };
    const ifValue = inputData["if"];
    const trueValue = inputData["true"] ?? unconnectedValue;
    const falseValue = inputData["false"] ?? unconnectedValue;
    if (!(trueValue || falseValue)) {
      return {
        ["output"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    if ((ifValue == null ? void 0 : ifValue.type) === "control-flow-excluded") {
      return {
        ["output"]: falseValue
      };
    }
    if ((ifValue == null ? void 0 : ifValue.value) == null) {
      return {
        ["output"]: falseValue
      };
    }
    if ((ifValue == null ? void 0 : ifValue.type) && ifValue.type === "boolean") {
      return {
        ["output"]: ifValue.value ? trueValue : falseValue
      };
    }
    if ((ifValue == null ? void 0 : ifValue.type) === "string") {
      return {
        ["output"]: ifValue.value.length > 0 ? trueValue : falseValue
      };
    }
    if ((ifValue == null ? void 0 : ifValue.type) === "chat-message") {
      const asString = coerceType(ifValue, "string");
      return {
        ["output"]: asString ? trueValue : falseValue
      };
    }
    if (ifValue == null ? void 0 : ifValue.type.endsWith("[]")) {
      return {
        ["output"]: ifValue.value.length > 0 ? trueValue : falseValue
      };
    }
    if ((ifValue == null ? void 0 : ifValue.type) === "any" || (ifValue == null ? void 0 : ifValue.type) === "object") {
      return {
        ["output"]: !!ifValue.value ? trueValue : falseValue
      };
    }
    return {
      ["output"]: falseValue
    };
  }
};
var ifElseNode = nodeDefinition(IfElseNodeImpl, "If/Else");

// src/model/nodes/ChunkNode.ts
var import_non_secure13 = require("nanoid/non-secure");
var import_ts_dedent13 = require("ts-dedent");
var ChunkNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "chunk",
      title: "Chunk",
      id: (0, import_non_secure13.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        model: "gpt-4o",
        useModelInput: false,
        numTokensPerChunk: 1024,
        overlap: 0
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "input",
        title: "Input",
        dataType: "string"
      }
    ];
    if (this.data.useModelInput) {
      inputs.push({
        id: "model",
        title: "Model",
        dataType: "string"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "chunks",
        title: "Chunks",
        dataType: "string[]"
      },
      {
        id: "first",
        title: "First",
        dataType: "string"
      },
      {
        id: "last",
        title: "Last",
        dataType: "string"
      },
      {
        id: "indexes",
        title: "Indexes",
        dataType: "number[]"
      },
      {
        id: "count",
        title: "Count",
        dataType: "number"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Model",
        dataKey: "model",
        options: openAiModelOptions,
        useInputToggleDataKey: "useModelInput"
      },
      {
        type: "number",
        label: "Number of tokens per chunk",
        dataKey: "numTokensPerChunk",
        min: 1,
        max: 32768,
        step: 1
      },
      {
        type: "number",
        label: "Overlap (in %)",
        dataKey: "overlap",
        min: 0,
        max: 100,
        step: 1
      }
    ];
  }
  getBody() {
    return import_ts_dedent13.dedent`
      Model: ${this.data.model}
      Token Count: ${this.data.numTokensPerChunk.toLocaleString()}
      ${this.data.overlap ? `Overlap: ${this.data.overlap}%` : ""}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent13.dedent`
          Splits the input text into an array of chunks based on an approximate GPT token count per chunk.

          The "overlap" setting allows you to partially overlap the chunks for redundancy.

          Can also be used for string length truncation by only using the \`First\` or \`Last\` outputs of the node.
        `,
      infoBoxTitle: "Chunk Node",
      contextMenuTitle: "Chunk",
      group: ["Text"]
    };
  }
  async process(inputs, context) {
    const input = coerceType(inputs["input"], "string");
    const overlapPercent = this.chartNode.data.overlap / 100;
    const chunked = await chunkStringByTokenCount(
      context.tokenizer,
      {
        node: this.chartNode,
        endpoint: void 0,
        model: this.data.model
      },
      input,
      this.chartNode.data.numTokensPerChunk,
      overlapPercent
    );
    return {
      ["chunks"]: {
        type: "string[]",
        value: chunked
      },
      ["first"]: {
        type: "string",
        value: chunked[0]
      },
      ["last"]: {
        type: "string",
        value: chunked.at(-1)
      },
      ["indexes"]: {
        type: "number[]",
        value: chunked.map((_, i) => i + 1)
      },
      ["count"]: {
        type: "number",
        value: chunked.length
      }
    };
  }
};
var chunkNode = nodeDefinition(ChunkNodeImpl, "Chunk");
async function chunkStringByTokenCount(tokenizer, tokenizerInfo, input, targetTokenCount, overlapPercent) {
  overlapPercent = Number.isNaN(overlapPercent) ? 0 : Math.max(0, Math.min(1, overlapPercent));
  const chunks = [];
  const guess = Math.floor(
    targetTokenCount * (input.length / await tokenizer.getTokenCountForString(input, tokenizerInfo))
  );
  let remaining = input;
  while (remaining.length > 0) {
    chunks.push(remaining.slice(0, guess));
    remaining = remaining.slice(guess - Math.floor(guess * overlapPercent));
  }
  return chunks;
}

// src/model/nodes/GraphInputNode.ts
var import_non_secure14 = require("nanoid/non-secure");
var import_ts_dedent14 = require("ts-dedent");
var GraphInputNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "graphInput",
      title: "Graph Input",
      id: (0, import_non_secure14.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 300
      },
      data: {
        id: "input",
        dataType: "string",
        defaultValue: void 0,
        useDefaultValueInput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    if (this.data.useDefaultValueInput) {
      return [
        {
          id: "default",
          title: "Default Value",
          dataType: this.chartNode.data.dataType
        }
      ];
    }
    return [];
  }
  getOutputDefinitions() {
    return [
      {
        id: "data",
        title: this.data.id,
        dataType: this.chartNode.data.dataType
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "ID",
        dataKey: "id"
      },
      {
        type: "dataTypeSelector",
        label: "Data Type",
        dataKey: "dataType"
      },
      {
        type: "anyData",
        label: "Default Value",
        dataKey: "defaultValue",
        useInputToggleDataKey: "useDefaultValueInput"
      },
      {
        type: "dropdown",
        label: "Editor",
        dataKey: "editor",
        defaultValue: "auto",
        options: [
          { label: "None", value: "none" },
          { label: "Auto", value: "auto" },
          { label: "String", value: "string" },
          { label: "Number", value: "number" },
          { label: "Code", value: "code" },
          { label: "Data Type", value: "dataTypeSelector" },
          { label: "String List", value: "stringList" },
          { label: "Key Value Pairs", value: "keyValuePair" },
          { label: "Toggle", value: "toggle" }
        ],
        helperMessage: "The editor to use when editing this value in the UI. Make sure this matches the data type."
      }
    ];
  }
  getBody() {
    return import_ts_dedent14.dedent`
      ${this.data.id}
      Type: ${this.data.dataType}
      ${this.data.defaultValue == null ? "" : `Default: ${this.data.defaultValue}`}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent14.dedent`
        Defines an input for the graph which can be passed in when the graph is called, or defines one of the input ports when the graph is a subgraph.
      `,
      infoBoxTitle: "Graph Input Node",
      contextMenuTitle: "Graph Input",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    let inputValue = context.graphInputs[this.data.id] == null ? void 0 : coerceTypeOptional(context.graphInputs[this.data.id], this.data.dataType);
    if (inputValue == null && this.data.useDefaultValueInput) {
      inputValue = coerceTypeOptional(inputs["default"], this.data.dataType);
    }
    if (inputValue == null) {
      inputValue = coerceTypeOptional(inferType(this.data.defaultValue), this.data.dataType) || getDefaultValue(this.data.dataType);
    }
    if (inputValue == null && isArrayDataType(this.data.dataType)) {
      inputValue = { type: this.data.dataType, value: [] };
    }
    const value = {
      type: this.data.dataType,
      value: inputValue
    };
    return { ["data"]: value };
  }
};
var graphInputNode = nodeDefinition(GraphInputNodeImpl, "Graph Input");

// src/model/nodes/GraphOutputNode.ts
var import_non_secure15 = require("nanoid/non-secure");
var import_ts_dedent15 = require("ts-dedent");
var GraphOutputNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "graphOutput",
      title: "Graph Output",
      id: (0, import_non_secure15.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 300
      },
      data: {
        id: "output",
        dataType: "string"
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "value",
        title: this.data.id,
        dataType: this.chartNode.data.dataType
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "valueOutput",
        title: this.data.id,
        dataType: this.chartNode.data.dataType
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "ID",
        dataKey: "id"
      },
      {
        type: "dataTypeSelector",
        label: "Data Type",
        dataKey: "dataType"
      }
    ];
  }
  getBody() {
    return import_ts_dedent15.dedent`
      ${this.data.id}
      Type: ${this.data.dataType}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent15.dedent`
        Each instance of this node represents an individual output of the graph. The value passed into this node becomes part of the overall output of the graph.
      `,
      infoBoxTitle: "Graph Output Node",
      contextMenuTitle: "Graph Output",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    var _a;
    const value = inputs["value"] ?? { type: "any", value: void 0 };
    const isExcluded = value.type === "control-flow-excluded";
    if (isExcluded && context.graphOutputs[this.data.id] == null) {
      context.graphOutputs[this.data.id] = {
        type: "control-flow-excluded",
        value: void 0
      };
    } else if ((context.graphOutputs[this.data.id] == null || ((_a = context.graphOutputs[this.data.id]) == null ? void 0 : _a.type) === "control-flow-excluded") && inputs["value"]) {
      context.graphOutputs[this.data.id] = value;
    }
    if (isExcluded) {
      return {
        ["valueOutput"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    return {
      ["valueOutput"]: context.graphOutputs[this.data.id]
    };
  }
};
var graphOutputNode = nodeDefinition(GraphOutputNodeImpl, "Graph Output");

// src/model/NodeGraph.ts
var import_non_secure16 = require("nanoid/non-secure");
function emptyNodeGraph() {
  return {
    nodes: [],
    connections: [],
    metadata: {
      id: (0, import_non_secure16.nanoid)(),
      name: "Untitled Graph",
      description: ""
    }
  };
}

// src/model/nodes/SubGraphNode.ts
var import_non_secure17 = require("nanoid/non-secure");
var import_ts_dedent16 = require("ts-dedent");
var import_ts_pattern5 = require("ts-pattern");
var SubGraphNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "subGraph",
      title: "Subgraph",
      id: (0, import_non_secure17.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 300
      },
      data: {
        graphId: "",
        useErrorOutput: false,
        useAsGraphPartialOutput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions(_connections, _nodes, project) {
    const graph = project.graphs[this.data.graphId];
    if (!graph) {
      return [];
    }
    const inputNodes = graph.nodes.filter((node) => node.type === "graphInput");
    const inputIds = [...new Set(inputNodes.map((node) => node.data.id))].sort();
    return inputIds.map(
      (id) => ({
        id,
        title: id,
        dataType: inputNodes.find((node) => node.data.id === id).data.dataType
      })
    );
  }
  getGraphOutputs(project) {
    const graph = project.graphs[this.data.graphId];
    if (!graph) {
      return [];
    }
    const outputNodes = graph.nodes.filter((node) => node.type === "graphOutput");
    const outputIds = [...new Set(outputNodes.map((node) => node.data.id))].sort();
    const outputs = outputIds.map(
      (id) => ({
        id,
        title: id,
        dataType: outputNodes.find((node) => node.data.id === id).data.dataType
      })
    );
    return outputs;
  }
  getOutputDefinitions(_connections, _nodes, project) {
    const outputs = [];
    outputs.push(...this.getGraphOutputs(project));
    if (this.data.useErrorOutput) {
      outputs.push({
        id: "error",
        title: "Error",
        dataType: "string"
      });
    }
    return outputs;
  }
  getEditors(context) {
    const definitions = [
      {
        type: "graphSelector",
        label: "Graph",
        dataKey: "graphId"
      },
      {
        type: "toggle",
        label: "Use Error Output",
        dataKey: "useErrorOutput"
      }
    ];
    if (this.data.graphId) {
      const graph = context.project.graphs[this.data.graphId];
      if (graph) {
        const inputNodes = graph.nodes.filter((node) => node.type === "graphInput");
        const inputIds = [...new Set(inputNodes.map((node) => node.data.id))].sort();
        for (const inputId of inputIds) {
          const inputNode = inputNodes.find((node) => node.data.id === inputId);
          definitions.push({
            type: "dynamic",
            dataKey: "inputData",
            dynamicDataKey: inputNode.data.id,
            dataType: inputNode.data.dataType,
            label: inputNode.data.id,
            editor: inputNode.data.editor ?? "auto"
          });
        }
      }
    }
    return definitions;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent16.dedent`
        Executes another graph. Inputs and outputs are defined by Graph Input and Graph Output nodes within the subgraph.
      `,
      infoBoxTitle: "Subgraph Node",
      contextMenuTitle: "Subgraph",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    const { project } = context;
    if (!project) {
      throw new Error("SubGraphNode requires a project to be set in the context.");
    }
    const graph = project.graphs[this.data.graphId];
    if (!graph) {
      throw new Error(`SubGraphNode requires a graph with id ${this.data.graphId} to be present in the project.`);
    }
    const inputNodes = graph.nodes.filter((node) => node.type === "graphInput");
    const inputIds = [...new Set(inputNodes.map((node) => node.data.id))].sort();
    const inputData = inputIds.reduce((obj, id) => {
      var _a;
      if (inputs[id] != null) {
        return {
          ...obj,
          [id]: inputs[id]
        };
      }
      if (((_a = this.data.inputData) == null ? void 0 : _a[id]) != null) {
        return {
          ...obj,
          [id]: this.data.inputData[id]
        };
      }
      return obj;
    }, {});
    const subGraphProcessor = context.createSubProcessor(this.data.graphId, { signal: context.signal });
    try {
      const startTime = Date.now();
      const outputs = await subGraphProcessor.processGraph(
        context,
        inputData,
        context.contextValues
      );
      const duration = Date.now() - startTime;
      if (this.data.useErrorOutput) {
        outputs["error"] = {
          type: "control-flow-excluded",
          value: void 0
        };
      }
      if (outputs["duration"] == null) {
        outputs["duration"] = {
          type: "number",
          value: duration
        };
      }
      return outputs;
    } catch (err) {
      if (!this.data.useErrorOutput) {
        throw err;
      }
      const outputs = this.getGraphOutputs(context.project).reduce(
        (obj, output) => ({
          ...obj,
          [output.id]: {
            type: "control-flow-excluded",
            value: void 0
          }
        }),
        {}
      );
      outputs["error"] = {
        type: "string",
        value: getError(err).message
      };
      return outputs;
    }
  }
};
var subGraphNode = nodeDefinition(SubGraphNodeImpl, "Subgraph");

// src/model/nodes/ArrayNode.ts
var import_non_secure18 = require("nanoid/non-secure");
var import_lodash_es6 = require("lodash");
var import_ts_dedent17 = require("ts-dedent");
var ArrayNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "array",
      title: "Array",
      id: (0, import_non_secure18.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        flatten: true,
        flattenDeep: false
      }
    };
    return chartNode;
  }
  getInputDefinitions(connections) {
    const inputs = [];
    const inputCount = this.#getInputPortCount(connections);
    for (let i = 1; i <= inputCount; i++) {
      inputs.push({
        dataType: "any",
        id: `input${i}`,
        title: `Input ${i}`,
        description: 'An input to create the array from. If an array, will be flattened if the "Flatten" option is enabled.'
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "any[]",
        id: "output",
        title: "Output",
        description: "The array created from the inputs."
      },
      {
        dataType: "number[]",
        id: "indices",
        title: "Indices",
        description: "The indices of the array. I.e. [0, 1, 2, 3, etc]. Useful for zipping with the output array to get the indexes."
      },
      {
        dataType: "number",
        id: "length",
        title: "Length",
        description: "The length of the output array."
      }
    ];
  }
  getEditors() {
    return [
      { type: "toggle", label: "Flatten", dataKey: "flatten" },
      {
        type: "toggle",
        label: "Deep",
        dataKey: "flattenDeep"
      }
    ];
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const inputConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("input")
    );
    let maxInputNumber = 0;
    for (const connection of inputConnections) {
      const inputNumber = parseInt(connection.inputId.replace("input", ""));
      if (inputNumber > maxInputNumber) {
        maxInputNumber = inputNumber;
      }
    }
    return maxInputNumber + 1;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent17.dedent`
        Creates an array from the input values. By default, flattens any arrays which are inputs into a single array. Can be configured to keep the arrays separate, or deeply flatten arrays.

        Useful for both creating and merging arrays.

        The number of inputs is dynamic based on the number of connections.
      `,
      infoBoxTitle: "Array Node",
      contextMenuTitle: "Array",
      group: ["Lists"]
    };
  }
  getBody() {
    return import_ts_dedent17.dedent`
      ${this.data.flatten ? this.data.flattenDeep ? "Flatten (Deep)" : "Flatten" : "No Flatten"}
    `;
  }
  async process(inputs) {
    const outputArray = [];
    for (const [key, input] of entries(inputs)) {
      if (key.startsWith("input")) {
        if (this.data.flatten) {
          if (Array.isArray(input == null ? void 0 : input.value)) {
            for (const value of (input == null ? void 0 : input.value) ?? []) {
              if (this.data.flattenDeep) {
                outputArray.push(...Array.isArray(value) ? (0, import_lodash_es6.flattenDeep)(value) : [value]);
              } else {
                outputArray.push(value);
              }
            }
          } else {
            outputArray.push(input == null ? void 0 : input.value);
          }
        } else {
          outputArray.push(input == null ? void 0 : input.value);
        }
      }
    }
    return {
      ["output"]: {
        type: "any[]",
        value: outputArray
      },
      ["indices"]: {
        type: "number[]",
        value: outputArray.map((_, index) => index)
      },
      ["length"]: {
        type: "number",
        value: outputArray.length
      }
    };
  }
};
var arrayNode = nodeDefinition(ArrayNodeImpl, "Array");

// src/model/nodes/ExtractJsonNode.ts
var import_non_secure19 = require("nanoid/non-secure");
var import_ts_dedent18 = require("ts-dedent");
var ExtractJsonNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "extractJson",
      title: "Extract JSON",
      id: (0, import_non_secure19.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {}
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "input",
        title: "Input",
        dataType: "string",
        required: true,
        coerced: false
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "output",
        title: "Output",
        dataType: "object"
      },
      {
        id: "noMatch",
        title: "No Match",
        dataType: "string"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent18.dedent`
        Finds and parses the first JSON object in the input text.

        Outputs the parsed object.
      `,
      infoBoxTitle: "Extract JSON Node",
      contextMenuTitle: "Extract JSON",
      group: ["Objects"]
    };
  }
  async process(inputs) {
    const inputString = expectType(inputs["input"], "string");
    try {
      const parsed = JSON.parse(inputString);
      return {
        ["output"]: {
          type: "object",
          value: parsed
        },
        ["noMatch"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    } catch (_err) {
    }
    const firstBracket = inputString.indexOf("{");
    const lastBracket = inputString.lastIndexOf("}");
    const firstSquareBracket = inputString.indexOf("[");
    const lastSquareBracket = inputString.lastIndexOf("]");
    const firstIndex = firstBracket >= 0 && firstSquareBracket >= 0 ? Math.min(firstBracket, firstSquareBracket) : firstBracket >= 0 ? firstBracket : firstSquareBracket;
    const lastIndex = lastBracket >= 0 && lastSquareBracket >= 0 ? Math.max(lastBracket, lastSquareBracket) : lastBracket >= 0 ? lastBracket : lastSquareBracket;
    const substring = inputString.substring(firstIndex, lastIndex + 1);
    let jsonObject = void 0;
    try {
      jsonObject = JSON.parse(substring);
    } catch (err) {
      return {
        ["noMatch"]: {
          type: "string",
          value: inputString
        },
        ["output"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    return {
      ["output"]: {
        type: "object",
        value: jsonObject
      },
      ["noMatch"]: {
        type: "control-flow-excluded",
        value: void 0
      }
    };
  }
};
var extractJsonNode = nodeDefinition(ExtractJsonNodeImpl, "Extract JSON");

// src/model/nodes/AssemblePromptNode.ts
var import_non_secure20 = require("nanoid/non-secure");
var import_lodash_es7 = require("lodash");
var import_ts_dedent19 = require("ts-dedent");
var AssemblePromptNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "assemblePrompt",
      title: "Assemble Prompt",
      id: (0, import_non_secure20.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {}
    };
    return chartNode;
  }
  getInputDefinitions(connections) {
    const inputs = [];
    const messageCount = this.#getMessagePortCount(connections);
    if (this.data.useIsLastMessageCacheBreakpointInput) {
      inputs.push({
        dataType: "boolean",
        id: "isLastMessageCacheBreakpoint",
        title: "Is Last Message Cache Breakpoint",
        description: "Whether the last message in the prompt should be a cache breakpoint."
      });
    }
    for (let i = 1; i <= messageCount; i++) {
      inputs.push({
        dataType: ["chat-message", "chat-message[]"],
        id: `message${i}`,
        title: `Message ${i}`,
        description: "A message, or messages, to include in the full prompt."
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    const outputs = [
      {
        dataType: "chat-message[]",
        id: "prompt",
        title: "Prompt",
        description: "The assembled prompt, a list of chat messages."
      }
    ];
    if (this.data.computeTokenCount) {
      outputs.push({
        dataType: "number",
        id: "tokenCount",
        title: "Token Count",
        description: "The number of tokens in the full output prompt."
      });
    }
    return outputs;
  }
  #getMessagePortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const messageConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("message")
    );
    let maxMessageNumber = 0;
    for (const connection of messageConnections) {
      const messageNumber = parseInt(connection.inputId.replace("message", ""));
      if (messageNumber > maxMessageNumber) {
        maxMessageNumber = messageNumber;
      }
    }
    return maxMessageNumber + 1;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent19.dedent`
        Assembles an array of chat messages for use with a Chat node. The inputs can be strings or chat messages.

        The number of inputs is dynamic based on the number of connections.

        Strings are converted to User type chat messages.
      `,
      infoBoxTitle: "Assemble Prompt Node",
      contextMenuTitle: "Assemble Prompt",
      group: ["AI"]
    };
  }
  getEditors(_context) {
    return [
      {
        type: "toggle",
        label: "Compute Token Count",
        dataKey: "computeTokenCount"
      },
      {
        type: "toggle",
        label: "Is Last Message Cache Breakpoint",
        dataKey: "isLastMessageCacheBreakpoint",
        helperMessage: "For Anthropic, marks the last message as a cache breakpoint - this message and every message before it will be cached using Prompt Caching."
      }
    ];
  }
  getBody(_context) {
    return this.data.isLastMessageCacheBreakpoint ? "Last message is cache breakpoint" : "";
  }
  async process(inputs, context) {
    const output = {};
    const isLastMessageCacheBreakpoint = getInputOrData(this.data, inputs, "isLastMessageCacheBreakpoint", "boolean");
    const outMessages = [];
    const inputMessages = (0, import_lodash_es7.orderBy)(
      Object.entries(inputs).filter(([key]) => key.startsWith("message")),
      ([key]) => key,
      "asc"
    );
    for (const [, inputMessage] of inputMessages) {
      if (!inputMessage || inputMessage.type === "control-flow-excluded" || !inputMessage.value) {
        continue;
      }
      const inMessages = arrayizeDataValue(unwrapDataValue(inputMessage));
      for (const message of inMessages) {
        if (message.type === "chat-message") {
          outMessages.push(message.value);
        } else {
          const coerced = coerceType(message, "chat-message");
          if (coerced) {
            outMessages.push(coerced);
          }
        }
      }
    }
    if (isLastMessageCacheBreakpoint && outMessages.length > 1) {
      outMessages.at(-1).isCacheBreakpoint = true;
    }
    output["prompt"] = {
      type: "chat-message[]",
      value: outMessages
    };
    if (this.data.computeTokenCount) {
      const tokenCount = await context.tokenizer.getTokenCountForMessages(outMessages, void 0, {
        node: this.chartNode
      });
      output["tokenCount"] = {
        type: "number",
        value: tokenCount
      };
    }
    return output;
  }
};
var assemblePromptNode = nodeDefinition(AssemblePromptNodeImpl, "Assemble Prompt");

// src/model/nodes/ExtractYamlNode.ts
var import_non_secure21 = require("nanoid/non-secure");
var import_yaml = __toESM(require("yaml"), 1);
var import_jsonpath_plus = require("jsonpath-plus");
var import_ts_dedent20 = require("ts-dedent");
var ExtractYamlNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "extractYaml",
      title: "Extract YAML",
      id: (0, import_non_secure21.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        rootPropertyName: "yamlDocument",
        useRootPropertyNameInput: false,
        useObjectPathInput: false,
        objectPath: void 0
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "input",
        title: "Input",
        dataType: "string",
        required: true,
        coerced: false
      }
    ];
    if (this.data.useRootPropertyNameInput) {
      inputs.push({
        id: "rootPropertyName",
        title: "Root Property Name",
        dataType: "string",
        required: true
      });
    }
    if (this.data.useObjectPathInput) {
      inputs.push({
        id: "objectPath",
        title: "Object Path",
        dataType: "string",
        required: true
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "output",
        title: "Output",
        dataType: "object"
      },
      {
        id: "matches",
        title: "Matches",
        dataType: "any[]"
      },
      {
        id: "noMatch",
        title: "No Match",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "Root Property Name",
        dataKey: "rootPropertyName",
        useInputToggleDataKey: "useRootPropertyNameInput"
      },
      {
        type: "code",
        label: "Object Path",
        dataKey: "objectPath",
        language: "jsonpath",
        useInputToggleDataKey: "useObjectPathInput"
      }
    ];
  }
  getBody() {
    return import_ts_dedent20.dedent`
      Root: ${this.data.useRootPropertyNameInput ? "(Using Input)" : this.data.rootPropertyName}
      ${this.data.useObjectPathInput ? "Path: (Using Input)" : this.data.objectPath ? `Path: ${this.data.objectPath}` : ``}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent20.dedent`
        Finds and parses a YAML object in the input text with a predefined root property name (configurable).

        Defaults to \`yamlDocument\`, which means the input text must have a \`yamlDocument:\` root node somewhere in it. All indented text after that is considered part of the YAML.

        Outputs the parsed object.
      `,
      infoBoxTitle: "Extract YAML Node",
      contextMenuTitle: "Extract YAML",
      group: ["Objects"]
    };
  }
  async process(inputs) {
    var _a, _b;
    const inputString = expectType(inputs["input"], "string");
    const rootPropertyName = this.data.useRootPropertyNameInput ? coerceType(inputs["rootPropertyName"], "string") : this.data.rootPropertyName;
    const objectPath = this.data.useObjectPathInput ? coerceType(inputs["objectPath"], "string") : this.data.objectPath;
    const match15 = new RegExp(`^${rootPropertyName}:`, "m").exec(inputString);
    const rootPropertyStart = (match15 == null ? void 0 : match15.index) ?? -1;
    const nextLines = inputString.slice(rootPropertyStart).split("\n");
    const yamlLines = [nextLines.shift()];
    while (((_a = nextLines[0]) == null ? void 0 : _a.startsWith(" ")) || ((_b = nextLines[0]) == null ? void 0 : _b.startsWith("	")) || nextLines[0] === "") {
      yamlLines.push(nextLines.shift());
    }
    const potentialYaml = yamlLines.join("\n");
    let yamlObject = void 0;
    try {
      yamlObject = import_yaml.default.parse(potentialYaml);
    } catch (err) {
      return {
        ["noMatch"]: {
          type: "string",
          value: potentialYaml
        },
        ["output"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    if (!(yamlObject == null ? void 0 : yamlObject.hasOwnProperty(rootPropertyName))) {
      return {
        ["noMatch"]: {
          type: "string",
          value: potentialYaml
        },
        ["output"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    let matches = [];
    if (objectPath) {
      try {
        const extractedValue = (0, import_jsonpath_plus.JSONPath)({ json: yamlObject, path: objectPath.trim() });
        matches = extractedValue;
        yamlObject = extractedValue.length > 0 ? extractedValue[0] : void 0;
      } catch (err) {
        return {
          ["noMatch"]: {
            type: "string",
            value: potentialYaml
          },
          ["output"]: {
            type: "control-flow-excluded",
            value: void 0
          },
          ["matches"]: {
            type: "control-flow-excluded",
            value: void 0
          }
        };
      }
    }
    return {
      ["output"]: yamlObject === void 0 ? {
        type: "control-flow-excluded",
        value: void 0
      } : this.data.objectPath ? {
        type: "any",
        value: yamlObject
      } : {
        type: "object",
        value: yamlObject
      },
      ["noMatch"]: {
        type: "control-flow-excluded",
        value: void 0
      },
      ["matches"]: {
        type: "any[]",
        value: matches
      }
    };
  }
};
var extractYamlNode = nodeDefinition(ExtractYamlNodeImpl, "Extract YAML");

// src/model/nodes/LoopControllerNode.ts
var import_non_secure22 = require("nanoid/non-secure");
var import_ts_dedent21 = require("ts-dedent");
var LoopControllerNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "loopController",
      title: "Loop Controller",
      id: (0, import_non_secure22.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        maxIterations: 100
      }
    };
    return chartNode;
  }
  getInputDefinitions(connections, nodes) {
    const inputs = [];
    const messageCount = this.#getInputPortCount(connections);
    inputs.push({
      dataType: "any",
      id: "continue",
      title: "Continue"
    });
    let i = 1;
    for (; i <= messageCount + 1; i++) {
      const input = {
        dataType: "any",
        id: `input${i}`,
        title: `Input ${i}`
      };
      const inputConnection = connections.find(
        (connection) => connection.inputId === input.id && connection.inputNodeId === this.id
      );
      if (inputConnection && nodes[inputConnection.outputNodeId]) {
        input.title = nodes[inputConnection.outputNodeId].title;
      }
      const inputDefault = {
        dataType: "any",
        id: `input${i}Default`,
        title: `Input ${i} Default`
      };
      const inputDefaultConnection = connections.find(
        (connection) => connection.inputId === inputDefault.id && connection.inputNodeId === this.id
      );
      if (inputDefaultConnection && nodes[inputDefaultConnection.outputNodeId]) {
        inputDefault.title = `${nodes[inputDefaultConnection.outputNodeId].title} (Default)`;
      }
      inputs.push(input);
      inputs.push(inputDefault);
    }
    return inputs;
  }
  getOutputDefinitions(connections, nodes) {
    const messageCount = this.#getInputPortCount(connections);
    const outputs = [];
    outputs.push({
      dataType: "any",
      id: "break",
      title: "Break"
    });
    outputs.push({
      dataType: "number",
      id: "iteration",
      title: "Iteration"
    });
    for (let i = 1; i <= messageCount; i++) {
      const output = {
        dataType: "any",
        id: `output${i}`,
        title: `Output ${i}`
      };
      const inputConnection = connections.find(
        (connection) => connection.inputId === `input${i}` && connection.inputNodeId === this.id
      );
      if (inputConnection && nodes[inputConnection.outputNodeId]) {
        output.title = `${nodes[inputConnection.outputNodeId].title}?`;
      }
      outputs.push(output);
    }
    return outputs;
  }
  getEditors() {
    return [
      {
        type: "number",
        label: "Max Iterations",
        dataKey: "maxIterations"
      },
      {
        type: "dropdown",
        options: [
          {
            label: "Break",
            value: "break"
          },
          {
            label: "Error",
            value: "error"
          }
        ],
        label: "At Max Iterations",
        dataKey: "atMaxIterationsAction",
        defaultValue: "error",
        helperMessage: "What should happen when the max iterations is reached?"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent21.dedent`
        Defines the entry point for a loop. Values from inside the loop should be passed back through the "Input" ports, and their corresponding "Default" values can be specified on the input ports as well.

        If the "continue" input is falsey, then the "break" output will run.
      `,
      infoBoxTitle: "Loop Controller Node",
      contextMenuTitle: "Loop Controller",
      group: ["Logic"]
    };
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const messageConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("input")
    );
    let maxMessageNumber = 0;
    for (const connection of messageConnections) {
      const messageNumber = parseInt(connection.inputId.replace("input", ""));
      if (messageNumber > maxMessageNumber) {
        maxMessageNumber = messageNumber;
      }
    }
    return maxMessageNumber;
  }
  async process(inputs, context) {
    var _a, _b;
    const output = {};
    let inputCount = 0;
    while (inputs[`input${inputCount + 1}`] || inputs[`input${inputCount + 1}Default`]) {
      inputCount++;
    }
    const defaultInputs = entries(inputs).filter(([key]) => key.endsWith("Default"));
    if (defaultInputs.some(([, value]) => (value == null ? void 0 : value.type) === "control-flow-excluded")) {
      for (let i = 0; i <= inputCount; i++) {
        output[`output${i}`] = { type: "control-flow-excluded", value: void 0 };
      }
      output["break"] = { type: "control-flow-excluded", value: void 0 };
      return output;
    }
    const iterationCount = ((_a = context.attachedData.loopInfo) == null ? void 0 : _a.iterationCount) ?? 0;
    output["iteration"] = { type: "number", value: iterationCount + 1 };
    if (iterationCount >= (this.data.maxIterations ?? 100) && this.data.atMaxIterationsAction !== "break") {
      throw new Error(`Loop controller exceeded max iterations of ${this.data.maxIterations ?? 100}`);
    }
    let continueValue = false;
    if (inputs["continue"] === void 0) {
      continueValue = true;
    } else {
      const continueDataValue = inputs["continue"];
      if (continueDataValue.type === "control-flow-excluded") {
        continueValue = false;
      } else {
        continueValue = coerceType(continueDataValue, "boolean");
      }
    }
    if (iterationCount >= (this.data.maxIterations ?? 100) && this.data.atMaxIterationsAction === "break") {
      continueValue = false;
    }
    if (continueValue) {
      output["break"] = { type: "control-flow-excluded", value: "loop-not-broken" };
    } else {
      const inputValues = [];
      for (let i = 1; i <= inputCount; i++) {
        inputValues.push((_b = inputs[`input${i}`]) == null ? void 0 : _b.value);
      }
      output["break"] = { type: "any[]", value: inputValues };
    }
    for (let i = 1; i <= inputCount; i++) {
      if (continueValue) {
        const inputId = `input${i}`;
        const outputId = `output${i}`;
        if (inputs[inputId]) {
          output[outputId] = inputs[inputId];
        } else {
          output[outputId] = inputs[`${inputId}Default`];
        }
      } else {
        output[`output${i}`] = { type: "control-flow-excluded", value: void 0 };
      }
    }
    return output;
  }
};
var loopControllerNode = nodeDefinition(LoopControllerNodeImpl, "Loop Controller");

// src/model/nodes/TrimChatMessagesNode.ts
var import_non_secure23 = require("nanoid/non-secure");
var import_ts_dedent22 = require("ts-dedent");
var TrimChatMessagesNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "trimChatMessages",
      title: "Trim Chat Messages",
      id: (0, import_non_secure23.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        maxTokenCount: 4096,
        removeFromBeginning: true
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "input",
        title: "Input",
        dataType: "chat-message[]"
      }
    ];
    if (this.data.useMaxTokenCountInput) {
      inputs.push({
        id: "maxTokenCount",
        title: "Max Token Count",
        dataType: "number"
      });
    }
    if (this.data.useRemoveFromBeginningInput) {
      inputs.push({
        id: "removeFromBeginning",
        title: "Remove From Beginning",
        dataType: "boolean"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "trimmed",
        title: "Trimmed",
        dataType: "chat-message[]"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "number",
        label: "Max Token Count",
        dataKey: "maxTokenCount",
        useInputToggleDataKey: "useMaxTokenCountInput"
      },
      {
        type: "toggle",
        label: "Remove From Beginning",
        dataKey: "removeFromBeginning",
        useInputToggleDataKey: "useRemoveFromBeginningInput"
      }
    ];
  }
  getBody() {
    return import_ts_dedent22.dedent`
      Max Token Count: ${this.data.useMaxTokenCountInput ? "(From Input)" : this.data.maxTokenCount}
      Remove From Beginning: ${this.data.useRemoveFromBeginningInput ? "(From Input)" : this.data.removeFromBeginning ? "Yes" : "No"}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent22.dedent`
        Takes an array of chat messages, and slices messages from the beginning or the end of the list until the total length of the messages is under the configured token length.

        Useful for setting up infinite message chains that stay under the LLM context limit.
      `,
      infoBoxTitle: "Trim Chat Messages Node",
      contextMenuTitle: "Trim Chat Messages",
      group: ["AI"]
    };
  }
  async process(inputs, context) {
    const input = coerceType(inputs["input"], "chat-message[]");
    const maxTokenCount = getInputOrData(this.data, inputs, "maxTokenCount", "number");
    const removeFromBeginning = getInputOrData(this.data, inputs, "removeFromBeginning", "boolean");
    const trimmedMessages = [...input];
    const tokenizerInfo = {
      node: this.chartNode
    };
    let tokenCount = await context.tokenizer.getTokenCountForMessages(trimmedMessages, void 0, tokenizerInfo);
    while (tokenCount > maxTokenCount) {
      if (removeFromBeginning) {
        trimmedMessages.shift();
      } else {
        trimmedMessages.pop();
      }
      tokenCount = await context.tokenizer.getTokenCountForMessages(trimmedMessages, void 0, tokenizerInfo);
    }
    return {
      ["trimmed"]: {
        type: "chat-message[]",
        value: trimmedMessages
      }
    };
  }
};
var trimChatMessagesNode = nodeDefinition(TrimChatMessagesNodeImpl, "Trim Chat Messages");

// src/model/nodes/ExternalCallNode.ts
var import_non_secure24 = require("nanoid/non-secure");
var import_lodash_es8 = require("lodash");
var import_ts_dedent23 = require("ts-dedent");
var ExternalCallNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure24.nanoid)(),
      type: "externalCall",
      title: "External Call",
      visualData: { x: 0, y: 0, width: 150 },
      data: {
        functionName: "",
        useFunctionNameInput: false,
        useErrorOutput: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.useFunctionNameInput) {
      inputDefinitions.push({
        id: "functionName",
        title: "Function Name",
        dataType: "string"
      });
    }
    inputDefinitions.push({
      id: "arguments",
      title: "Arguments",
      dataType: "any[]"
    });
    return inputDefinitions;
  }
  getOutputDefinitions() {
    const outputs = [
      {
        id: "result",
        title: "Result",
        dataType: "any"
      }
    ];
    if (this.chartNode.data.useErrorOutput) {
      outputs.push({
        id: "error",
        title: "Error",
        dataType: "string"
      });
    }
    return outputs;
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "Function Name",
        dataKey: "functionName",
        useInputToggleDataKey: "useFunctionNameInput"
      },
      {
        type: "toggle",
        label: "Use Error Output",
        dataKey: "useErrorOutput"
      }
    ];
  }
  getBody() {
    return this.data.useFunctionNameInput ? "(Using Input)" : this.data.functionName;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent23.dedent`
        Provides a way to call into the host project from inside a Rivet graph when Rivet graphs are integrated into another project.
      `,
      infoBoxTitle: "External Call Node",
      contextMenuTitle: "External Call",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    const functionName = this.chartNode.data.useFunctionNameInput ? coerceType(inputs["functionName"], "string") : this.chartNode.data.functionName;
    const args = inputs["arguments"];
    let arrayArgs = {
      type: "any[]",
      value: []
    };
    if (args) {
      if (args.type.endsWith("[]") === false) {
        arrayArgs = {
          type: "any[]",
          value: [args.value]
        };
      } else {
        arrayArgs = args;
      }
    }
    const fn = context.externalFunctions[functionName];
    const externalContext = (0, import_lodash_es8.omit)(context, ["setGlobal"]);
    if (!fn) {
      if (this.data.useErrorOutput) {
        return {
          ["result"]: {
            type: "control-flow-excluded",
            value: void 0
          },
          ["error"]: {
            type: "string",
            value: `Function ${functionName} not was not defined using setExternalCall`
          }
        };
      } else {
        throw new Error(`Function ${functionName} not was not defined using setExternalCall`);
      }
    }
    if (this.data.useErrorOutput) {
      try {
        const result2 = await fn(externalContext, ...arrayArgs.value);
        return {
          ["result"]: result2,
          ["cost"]: {
            type: "number",
            value: result2.cost ?? 0
          },
          ["error"]: {
            type: "control-flow-excluded",
            value: void 0
          }
        };
      } catch (error) {
        return {
          ["result"]: {
            type: "control-flow-excluded",
            value: void 0
          },
          ["error"]: {
            type: "string",
            value: getError(error).message
          }
        };
      }
    }
    const result = await fn(externalContext, ...arrayArgs.value);
    return {
      ["result"]: result
    };
  }
};
var externalCallNode = nodeDefinition(ExternalCallNodeImpl, "External Call");

// src/model/nodes/ExtractObjectPathNode.ts
var import_non_secure25 = require("nanoid/non-secure");
var import_jsonpath_plus2 = require("jsonpath-plus");
var import_ts_dedent24 = require("ts-dedent");
var ExtractObjectPathNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "extractObjectPath",
      title: "Extract Object Path",
      id: (0, import_non_secure25.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        path: "$",
        usePathInput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputDefinitions = [
      {
        id: "object",
        title: "Object",
        dataType: "object",
        required: true
      }
    ];
    if (this.chartNode.data.usePathInput) {
      inputDefinitions.push({
        id: "path",
        title: "Path",
        dataType: "string",
        required: true,
        coerced: false
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "match",
        title: "Match",
        dataType: "any"
      },
      {
        id: "all_matches",
        title: "All Matches",
        dataType: "any[]"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "code",
        label: "Path",
        dataKey: "path",
        language: "jsonpath",
        useInputToggleDataKey: "usePathInput"
      }
    ];
  }
  getBody() {
    return this.data.usePathInput ? "(Using Input)" : this.data.path;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent24.dedent`
        Extracts the value at the specified path from the input value. The path uses JSONPath notation to navigate through the value.
      `,
      infoBoxTitle: "Extract Object Path Node",
      contextMenuTitle: "Extract Object Path",
      group: ["Objects"]
    };
  }
  async process(inputs) {
    const inputObject = coerceTypeOptional(inputs["object"], "object");
    const inputPath = this.chartNode.data.usePathInput ? expectType(inputs["path"], "string") : this.chartNode.data.path;
    if (!inputPath) {
      throw new Error("Path input is not provided");
    }
    let matches;
    try {
      const match15 = (0, import_jsonpath_plus2.JSONPath)({ json: inputObject ?? null, path: inputPath.trim(), wrap: true });
      matches = match15 == null ? [] : match15;
    } catch (err) {
      matches = [];
    }
    if (matches.length === 0) {
      return {
        ["match"]: {
          type: "control-flow-excluded",
          value: void 0
        },
        ["all_matches"]: {
          type: "any[]",
          value: []
        }
      };
    }
    return {
      ["match"]: {
        type: "any",
        value: matches[0]
      },
      ["all_matches"]: {
        type: "any[]",
        value: matches
      }
    };
  }
};
var extractObjectPathNode = nodeDefinition(ExtractObjectPathNodeImpl, "Extract Object Path");

// src/model/nodes/RaiseEventNode.ts
var import_non_secure26 = require("nanoid/non-secure");
var import_ts_dedent25 = require("ts-dedent");
var RaiseEventNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure26.nanoid)(),
      type: "raiseEvent",
      title: "Raise Event",
      visualData: { x: 0, y: 0, width: 150 },
      data: {
        eventName: "toast",
        useEventNameInput: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.useEventNameInput) {
      inputDefinitions.push({
        id: "eventName",
        title: "Event Name",
        dataType: "string"
      });
    }
    inputDefinitions.push({
      id: "data",
      title: "Data",
      dataType: "any"
    });
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "result",
        title: "Result",
        dataType: "any"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "Event Name",
        dataKey: "eventName",
        useInputToggleDataKey: "useEventNameInput"
      }
    ];
  }
  getBody() {
    return this.data.useEventNameInput ? "(Using Input)" : this.data.eventName;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent25.dedent`
        Raises an event that the host project or a 'Wait For Event' node can listen for.
      `,
      infoBoxTitle: "Raise Event Node",
      contextMenuTitle: "Raise Event",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    const eventName = this.chartNode.data.useEventNameInput ? coerceType(inputs["eventName"], "string") : this.chartNode.data.eventName;
    const eventData = inputs["data"];
    context.raiseEvent(eventName, eventData);
    return {
      result: eventData
    };
  }
};
var raiseEventNode = nodeDefinition(RaiseEventNodeImpl, "Raise Event");

// src/model/nodes/ContextNode.ts
var import_non_secure27 = require("nanoid/non-secure");
var import_ts_dedent26 = require("ts-dedent");
var ContextNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "context",
      title: "Context",
      id: (0, import_non_secure27.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 300
      },
      data: {
        id: "input",
        dataType: "string",
        defaultValue: void 0,
        useDefaultValueInput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    if (this.data.useDefaultValueInput) {
      return [
        {
          id: "default",
          title: "Default Value",
          dataType: this.chartNode.data.dataType
        }
      ];
    }
    return [];
  }
  getOutputDefinitions() {
    return [
      {
        id: "data",
        title: this.data.id,
        dataType: this.chartNode.data.dataType
      }
    ];
  }
  getEditors() {
    return [
      { type: "string", label: "ID", dataKey: "id" },
      { type: "dataTypeSelector", label: "Data Type", dataKey: "dataType" },
      {
        type: "anyData",
        label: "Default Value",
        dataKey: "defaultValue",
        useInputToggleDataKey: "useDefaultValueInput"
      }
    ];
  }
  getBody() {
    return import_ts_dedent26.dedent`
      ${this.data.id}
      Type: ${this.data.dataType}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent26.dedent`
        Retrieves a value from the graph's context using a configured id. The context serves as a "global graph input", allowing the same values to be accessible from any graph or subgraph.
      `,
      infoBoxTitle: "Context Node",
      contextMenuTitle: "Context",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    const contextValue = context.contextValues[this.data.id];
    if (contextValue !== void 0) {
      return {
        ["data"]: contextValue
      };
    }
    let defaultValue;
    if (this.data.useDefaultValueInput) {
      defaultValue = inputs["default"];
    } else {
      defaultValue = { type: this.data.dataType, value: this.data.defaultValue };
    }
    return {
      ["data"]: defaultValue
    };
  }
};
var contextNode = nodeDefinition(ContextNodeImpl, "Context");

// src/model/nodes/CoalesceNode.ts
var import_non_secure28 = require("nanoid/non-secure");
var import_ts_dedent27 = require("ts-dedent");
var CoalesceNodeImpl = class extends NodeImpl {
  static create = () => {
    const chartNode = {
      type: "coalesce",
      title: "Coalesce",
      id: (0, import_non_secure28.nanoid)(),
      data: {},
      visualData: {
        x: 0,
        y: 0,
        width: 150
      }
    };
    return chartNode;
  };
  getInputDefinitions(connections) {
    const inputs = [];
    const inputCount = this.#getInputPortCount(connections);
    inputs.push({
      dataType: "boolean",
      id: "conditional",
      title: "Conditional"
    });
    for (let i = 1; i <= inputCount; i++) {
      inputs.push({
        dataType: "any",
        id: `input${i}`,
        title: `Input ${i}`
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "any",
        id: "output",
        title: "Output"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent27.dedent`
        Takes in any number of inputs and outputs the first value that exists. Useful for consolidating branches after a Match node. This node can also "consume" the "Not Ran" value.
      `,
      infoBoxTitle: "Coalesce Node",
      contextMenuTitle: "Coalesce",
      group: ["Logic"]
    };
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const inputConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("input")
    );
    let maxInputNumber = 0;
    for (const connection of inputConnections) {
      const messageNumber = parseInt(connection.inputId.replace("input", ""), 10);
      if (messageNumber > maxInputNumber) {
        maxInputNumber = messageNumber;
      }
    }
    return maxInputNumber + 1;
  }
  async process(inputData) {
    const conditional = inputData["conditional"];
    if ((conditional == null ? void 0 : conditional.type) === "control-flow-excluded") {
      return {
        ["output"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    const inputCount = Object.keys(inputData).filter((key) => key.startsWith("input")).length;
    const okInputValues = [];
    for (let i = 1; i <= inputCount; i++) {
      const inputValue = inputData[`input${i}`];
      if (inputValue && inputValue.type !== "control-flow-excluded" && unwrapDataValue(inputValue) != null) {
        okInputValues.push(inputValue);
      }
    }
    if (okInputValues.length === 0) {
      return {
        ["output"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    return {
      ["output"]: okInputValues[0]
    };
  }
};
var coalesceNode = nodeDefinition(CoalesceNodeImpl, "Coalesce");

// src/model/nodes/PassthroughNode.ts
var import_non_secure29 = require("nanoid/non-secure");
var import_ts_dedent28 = require("ts-dedent");
var PassthroughNodeImpl = class extends NodeImpl {
  static create = () => {
    const chartNode = {
      type: "passthrough",
      title: "Passthrough",
      id: (0, import_non_secure29.nanoid)(),
      data: {},
      visualData: {
        x: 0,
        y: 0,
        width: 175
      }
    };
    return chartNode;
  };
  getInputDefinitions(connections) {
    const inputs = [];
    const inputCount = this.#getInputPortCount(connections);
    for (let i = 1; i <= inputCount; i++) {
      inputs.push({
        dataType: "any",
        id: `input${i}`,
        title: `Input ${i}`
      });
    }
    return inputs;
  }
  getOutputDefinitions(connections) {
    const outputs = [];
    const inputCount = this.#getInputPortCount(connections);
    for (let i = 1; i <= inputCount - 1; i++) {
      outputs.push({
        dataType: "any",
        id: `output${i}`,
        title: `Output ${i}`
      });
    }
    return outputs;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent28.dedent`
        Simply passes the input value to the output without any modifications.
      `,
      infoBoxTitle: "Passthrough Node",
      contextMenuTitle: "Passthrough",
      group: ["Logic"]
    };
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const inputConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("input")
    );
    let maxInputNumber = 0;
    for (const connection of inputConnections) {
      const messageNumber = parseInt(connection.inputId.replace("input", ""), 10);
      if (messageNumber > maxInputNumber) {
        maxInputNumber = messageNumber;
      }
    }
    return maxInputNumber + 1;
  }
  async process(inputData) {
    const inputCount = Object.keys(inputData).filter((key) => key.startsWith("input")).length;
    const outputs = {};
    for (let i = 1; i <= inputCount; i++) {
      const input = inputData[`input${i}`];
      outputs[`output${i}`] = input;
    }
    return outputs;
  }
};
var passthroughNode = nodeDefinition(PassthroughNodeImpl, "Passthrough");

// src/model/nodes/PopNode.ts
var import_non_secure30 = require("nanoid/non-secure");
var import_ts_dedent29 = require("ts-dedent");
var PopNodeImpl = class extends NodeImpl {
  static create() {
    const baseNode = {
      type: "pop",
      title: "Pop",
      id: (0, import_non_secure30.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {}
    };
    return baseNode;
  }
  getInputDefinitions() {
    return [
      {
        dataType: "any[]",
        id: "array",
        title: "Array",
        coerced: false
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "any",
        id: "lastItem",
        title: this.data.fromFront ? "First" : "Last"
      },
      {
        dataType: "any",
        id: "restOfArray",
        title: "Rest"
      }
    ];
  }
  getEditors(_context) {
    return [
      {
        label: "Pop from front",
        type: "toggle",
        dataKey: "fromFront"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent29.dedent`
        Pops the last value off the input array and outputs the new array and the popped value.

        Can also be used to just extract the last value from an array.
      `,
      infoBoxTitle: "Pop Node",
      contextMenuTitle: "Pop",
      group: ["Lists"]
    };
  }
  getBody(_context) {
    return this.data.fromFront ? "From front" : "From back";
  }
  async process(inputs) {
    var _a;
    const inputArray = (_a = inputs["array"]) == null ? void 0 : _a.value;
    if (!Array.isArray(inputArray) || inputArray.length === 0) {
      throw new Error("Input array is empty or not an array");
    }
    const lastItem = this.data.fromFront ? inputArray[0] : inputArray[inputArray.length - 1];
    const rest = this.data.fromFront ? inputArray.slice(1) : inputArray.slice(0, inputArray.length - 1);
    return {
      ["lastItem"]: {
        type: "any",
        value: lastItem
      },
      ["restOfArray"]: {
        type: "any[]",
        value: rest
      }
    };
  }
};
var popNode = nodeDefinition(PopNodeImpl, "Pop");

// src/model/nodes/SetGlobalNode.ts
var import_non_secure31 = require("nanoid/non-secure");
var import_ts_dedent30 = require("ts-dedent");
var SetGlobalNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "setGlobal",
      title: "Set Global",
      id: (0, import_non_secure31.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        id: "variable-name",
        dataType: "string",
        useIdInput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "value",
        title: "Value",
        dataType: this.chartNode.data.dataType
      }
    ];
    if (this.data.useIdInput) {
      inputs.push({
        id: "id",
        title: "Variable ID",
        dataType: "string"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "saved-value",
        title: "Value",
        dataType: this.data.dataType
      },
      {
        id: "previous-value",
        title: "Previous Value",
        dataType: this.data.dataType
      },
      {
        id: "variable_id_out",
        title: "Variable ID",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "id",
        useInputToggleDataKey: "useIdInput",
        label: "ID"
      },
      {
        type: "dataTypeSelector",
        dataKey: "dataType",
        label: "Data Type",
        useInputToggleDataKey: "useIdInput"
      }
    ];
  }
  getBody() {
    return import_ts_dedent30.dedent`
      ${this.data.id}
      Type: ${this.data.dataType}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent30.dedent`
        Sets a global value that is shared across all graphs and subgraphs. The id of the global value and the value itself are configured in this node.
      `,
      infoBoxTitle: "Set Global Node",
      contextMenuTitle: "Set Global",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    const rawValue = inputs["value"];
    if (!rawValue) {
      return {};
    }
    const id = this.data.useIdInput ? coerceType(inputs["id"], "string") : this.data.id;
    if (!id) {
      throw new Error("Missing variable ID");
    }
    let previousValue = context.getGlobal(this.data.id);
    if (!previousValue && isArrayDataType(this.data.dataType)) {
      previousValue = { type: this.data.dataType, value: [] };
    } else if (!previousValue && isScalarDataType(this.data.dataType)) {
      previousValue = { type: this.data.dataType, value: scalarDefaults[this.data.dataType] };
    }
    const value = unwrapDataValue(rawValue);
    context.setGlobal(id, value);
    return {
      ["saved-value"]: value,
      ["previous-value"]: previousValue,
      ["variable_id_out"]: { type: "string", value: id }
    };
  }
};
var setGlobalNode = nodeDefinition(SetGlobalNodeImpl, "Set Global");

// src/model/nodes/GetGlobalNode.ts
var import_non_secure32 = require("nanoid/non-secure");
var import_ts_dedent31 = require("ts-dedent");
var GetGlobalNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "getGlobal",
      title: "Get Global",
      id: (0, import_non_secure32.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        id: "variable-name",
        dataType: "string",
        onDemand: true,
        useIdInput: false,
        wait: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    if (this.data.useIdInput) {
      return [
        {
          id: "id",
          title: "Variable ID",
          dataType: this.data.dataType
        }
      ];
    }
    return [];
  }
  getOutputDefinitions() {
    const { onDemand, dataType } = this.chartNode.data;
    return [
      {
        id: "value",
        title: "Value",
        dataType: onDemand ? `fn<${dataType}>` : dataType
      },
      {
        id: "variable_id_out",
        title: "Variable ID",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "Variable ID",
        dataKey: "id",
        useInputToggleDataKey: "useIdInput"
      },
      {
        type: "dataTypeSelector",
        label: "Data Type",
        dataKey: "dataType"
      },
      {
        type: "toggle",
        label: "On Demand",
        dataKey: "onDemand"
      },
      {
        type: "toggle",
        label: "Wait",
        dataKey: "wait"
      }
    ];
  }
  getBody() {
    return import_ts_dedent31.dedent`
      ${this.data.useIdInput ? "(ID from input)" : this.data.id}
      Type: ${this.data.dataType}
      ${this.data.wait ? "Waits for available data" : ""}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent31.dedent`
        Retrieves a global value that is shared across all graphs and subgraphs. The id of the global value is configured in this node.
      `,
      infoBoxTitle: "Get Global Node",
      contextMenuTitle: "Get Global",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    if (this.data.onDemand) {
      if (this.data.wait) {
        throw new Error("Cannot use onDemand and wait together");
      }
      return {
        ["value"]: {
          type: `fn<${this.data.dataType}>`,
          value: () => {
            const id2 = this.data.useIdInput ? coerceType(inputs["id"], "string") : this.data.id;
            const value2 = context.getGlobal(id2);
            if (value2) {
              return value2.value;
            }
            if (isArrayDataType(this.data.dataType)) {
              return [];
            }
            return scalarDefaults[this.data.dataType];
          }
        }
      };
    }
    const id = this.data.useIdInput ? coerceType(inputs["id"], "string") : this.data.id;
    let value = this.data.wait ? await context.waitForGlobal(id) : context.getGlobal(id);
    if (!value && isArrayDataType(this.data.dataType)) {
      value = { type: this.data.dataType, value: [] };
    }
    if (!value && isScalarDataType(this.data.dataType)) {
      value = { type: this.data.dataType, value: scalarDefaults[this.data.dataType] };
    }
    return {
      ["value"]: value,
      ["variable_id_out"]: { type: "string", value: id }
    };
  }
};
var getGlobalNode = nodeDefinition(GetGlobalNodeImpl, "Get Global");

// src/model/nodes/WaitForEventNode.ts
var import_non_secure33 = require("nanoid/non-secure");
var import_ts_dedent32 = require("ts-dedent");
var WaitForEventNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure33.nanoid)(),
      type: "waitForEvent",
      title: "Wait For Event",
      visualData: { x: 0, y: 0, width: 150 },
      data: {
        eventName: "continue",
        useEventNameInput: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.useEventNameInput) {
      inputDefinitions.push({
        id: "eventName",
        title: "Event Name",
        dataType: "string"
      });
    }
    inputDefinitions.push({
      id: "inputData",
      title: "Data",
      dataType: "any"
    });
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "outputData",
        title: "Data",
        dataType: "any"
      },
      {
        id: "eventData",
        title: "Event Data",
        dataType: "any"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "Event Name",
        dataKey: "eventName",
        useInputToggleDataKey: "useEventNameInput"
      }
    ];
  }
  getBody() {
    return this.data.useEventNameInput ? "(Using Input)" : this.data.eventName;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent32.dedent`
        Waits for a specific event to be raised by a 'Raise Event' node or the host project. The event name can be configured.
      `,
      infoBoxTitle: "Wait For Event Node",
      contextMenuTitle: "Wait For Event",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    const eventName = this.chartNode.data.useEventNameInput ? coerceType(inputs["eventName"], "string") : this.chartNode.data.eventName;
    const eventData = await context.waitEvent(eventName);
    return {
      ["outputData"]: inputs["inputData"],
      ["eventData"]: eventData
    };
  }
};
var waitForEventNode = nodeDefinition(WaitForEventNodeImpl, "Wait For Event");

// src/model/nodes/GptFunctionNode.ts
var import_non_secure34 = require("nanoid/non-secure");
var import_ts_dedent33 = require("ts-dedent");
var GptFunctionNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "gptFunction",
      title: "GPT Function",
      id: (0, import_non_secure34.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        name: "newFunction",
        description: "No description provided",
        schema: import_ts_dedent33.dedent`
          {
            "type": "object",
            "properties": {}
          }`
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    let inputs = [];
    if (this.data.useNameInput) {
      inputs.push({
        id: "name",
        title: "Name",
        dataType: "string",
        description: "The name of the function that GPT will see as available to call"
      });
    }
    if (this.data.useDescriptionInput) {
      inputs.push({
        id: "description",
        title: "Description",
        dataType: "string",
        description: "The description of the function that GPT will see as available to call"
      });
    }
    if (this.data.useSchemaInput) {
      inputs.push({
        id: "schema",
        title: "Schema",
        dataType: "object",
        description: "The schema of the function that GPT will see as available to call"
      });
    }
    const inputNames = this.data.useSchemaInput ? [] : [...new Set(this.data.schema.match(/\{\{([^}]+)\}\}/g))];
    inputs = [
      ...inputs,
      ...(inputNames == null ? void 0 : inputNames.map((inputName) => {
        const name = inputName.slice(2, -2);
        return {
          // id and title should not have the {{ and }}
          id: `input-${name}`,
          title: name,
          dataType: "string",
          description: `An interpolated value in the schema named '${name}'`
        };
      })) ?? []
    ];
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "function",
        title: "Function",
        dataType: "gpt-function",
        description: "The GPT function that can be called by the LLM."
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "Name",
        dataKey: "name",
        useInputToggleDataKey: "useNameInput"
      },
      {
        type: "toggle",
        label: "Strict",
        dataKey: "strict",
        helperMessage: "Sets the strict parameter, which determines if OpenAI Structured Outputs are used."
      },
      {
        type: "code",
        label: "Description",
        dataKey: "description",
        useInputToggleDataKey: "useDescriptionInput",
        language: "markdown",
        height: 100
      },
      {
        type: "custom",
        customEditorId: "GptFunctionNodeJsonSchemaAiAssist",
        label: "AI Assist"
      },
      {
        type: "code",
        label: "Schema",
        dataKey: "schema",
        language: "json",
        useInputToggleDataKey: "useSchemaInput"
      }
    ];
  }
  getBody() {
    return `!markdown_${this.data.name}_: ${this.data.description}`;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent33.dedent`
        Defines a GPT function, which is a method that the LLM can call in its responses.
      `,
      infoBoxTitle: "GPT Function Node",
      contextMenuTitle: "GPT Function",
      group: ["AI"]
    };
  }
  async process(inputs) {
    const name = getInputOrData(this.data, inputs, "name");
    const description = getInputOrData(this.data, inputs, "description");
    let schema;
    if (this.data.useSchemaInput) {
      schema = coerceType(inputs["schema"], "object");
    } else {
      const inputMap = keys(inputs).filter((key) => key.startsWith("input")).reduce(
        (acc, key) => {
          const stringValue = coerceTypeOptional(inputs[key], "string") ?? "";
          const interpolationKey = key.slice("input-".length);
          acc[interpolationKey] = stringValue;
          return acc;
        },
        {}
      );
      const interpolated = interpolate(this.data.schema, inputMap);
      schema = JSON.parse(interpolated);
    }
    return {
      ["function"]: {
        type: "gpt-function",
        value: {
          name,
          description,
          parameters: schema,
          strict: this.data.strict ?? false
        }
      }
    };
  }
};
var gptFunctionNode = nodeDefinition(GptFunctionNodeImpl, "GPT Function");

// src/model/nodes/ToYamlNode.ts
var import_non_secure35 = require("nanoid/non-secure");
var import_yaml2 = __toESM(require("yaml"), 1);
var import_ts_dedent34 = require("ts-dedent");
var ToYamlNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "toYaml",
      title: "To YAML",
      id: (0, import_non_secure35.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 175
      },
      data: {}
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "object",
        title: "Object",
        dataType: "object",
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "yaml",
        title: "YAML",
        dataType: "string"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent34.dedent`
        Turns the input object into YAML text.
      `,
      infoBoxTitle: "To YAML Node",
      contextMenuTitle: "To YAML",
      group: ["Text"]
    };
  }
  async process(inputs) {
    const object = coerceType(inputs["object"], "object");
    const toYaml = import_yaml2.default.stringify(object, null, {
      indent: 2,
      aliasDuplicateObjects: false
    });
    return {
      ["yaml"]: {
        type: "string",
        value: toYaml
      }
    };
  }
};
var toYamlNode = nodeDefinition(ToYamlNodeImpl, "To YAML");

// src/model/nodes/GetEmbeddingNode.ts
var import_non_secure36 = require("nanoid/non-secure");
var import_ts_dedent35 = require("ts-dedent");

// src/integrations/integrations.ts
var registeredIntegrations = {
  vectorDatabase: /* @__PURE__ */ new Map(),
  llmProvider: /* @__PURE__ */ new Map(),
  embeddingGenerator: /* @__PURE__ */ new Map()
};
function registerIntegration(type, integrationKey, factory) {
  registeredIntegrations[type].set(integrationKey, factory);
}
function getIntegration(type, integrationKey, context) {
  const factory = registeredIntegrations[type].get(integrationKey);
  if (!factory) {
    throw new Error(`Integration ${integrationKey} not found`);
  }
  return factory(context);
}

// src/model/nodes/GetEmbeddingNode.ts
var GetEmbeddingNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure36.nanoid)(),
      type: "getEmbedding",
      title: "Get Embedding",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        integration: "openai",
        useIntegrationInput: false,
        model: void 0,
        dimensions: void 0
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    inputDefinitions.push({
      id: "input",
      title: "Input",
      dataType: "string",
      required: true
    });
    if (this.data.useIntegrationInput) {
      inputDefinitions.push({
        id: "integration",
        title: "Integration",
        dataType: "string",
        required: true
      });
    }
    if (this.data.useModelInput) {
      inputDefinitions.push({
        id: "model",
        title: "Model",
        dataType: "string",
        required: false
      });
    }
    if (this.data.useDimensionsInput) {
      inputDefinitions.push({
        id: "dimensions",
        title: "Dimensions",
        dataType: "number",
        required: false
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    const outputs = [
      {
        id: "embedding",
        title: "Embedding",
        dataType: "vector"
      }
    ];
    return outputs;
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Integration",
        dataKey: "integration",
        options: [{ label: "OpenAI", value: "openai" }],
        useInputToggleDataKey: "useIntegrationInput"
      },
      {
        type: "string",
        label: "Model",
        dataKey: "model",
        useInputToggleDataKey: "useModelInput"
      },
      {
        type: "number",
        label: "Dimensions",
        dataKey: "dimensions",
        useInputToggleDataKey: "useDimensionsInput"
      }
    ];
  }
  getBody() {
    return `Using ${this.data.useIntegrationInput ? "(input)" : this.data.integration}`;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent35.dedent`
        Gets a OpenAI vector embedding for the input text provided.

        Can be used with the Vector Store and Vector KNN nodes.
      `,
      infoBoxTitle: "Get Embedding Node",
      contextMenuTitle: "Get Embedding",
      group: ["AI"]
    };
  }
  async process(inputs, context) {
    const input = coerceType(inputs["input"], "string");
    const integrationName = this.data.useIntegrationInput ? coerceType(inputs["integration"], "string") : this.data.integration;
    const model = this.data.useModelInput ? coerceType(inputs["model"], "string") : this.data.model;
    const dimensions = this.data.useDimensionsInput ? coerceType(inputs["dimensions"], "number") : this.data.dimensions;
    const embeddingGenerator = getIntegration("embeddingGenerator", integrationName, context);
    const embedding = await embeddingGenerator.generateEmbedding(input, {
      model,
      dimensions
    });
    return {
      ["embedding"]: {
        type: "vector",
        value: embedding
      }
    };
  }
};
var getEmbeddingNode = nodeDefinition(GetEmbeddingNodeImpl, "Get Embedding");

// src/model/nodes/VectorStoreNode.ts
var import_non_secure37 = require("nanoid/non-secure");
var import_ts_dedent36 = require("ts-dedent");
var VectorStoreNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure37.nanoid)(),
      type: "vectorStore",
      title: "Vector Store",
      visualData: { x: 0, y: 0, width: 200 },
      data: {
        integration: "pinecone",
        collectionId: ""
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    inputDefinitions.push({
      id: "vector",
      title: "Vector",
      dataType: "vector",
      required: true
    });
    if (this.data.useCollectionIdInput) {
      inputDefinitions.push({
        id: "collectionId",
        title: "Collection ID",
        dataType: "string",
        required: true
      });
    }
    inputDefinitions.push({
      id: "data",
      title: "Data",
      dataType: "any",
      required: true
    });
    if (this.data.useIntegrationInput) {
      inputDefinitions.push({
        id: "integration",
        title: "Integration",
        dataType: "string",
        required: true
      });
    }
    inputDefinitions.push({
      id: "id",
      title: "ID",
      dataType: "string",
      required: false
    });
    return inputDefinitions;
  }
  getOutputDefinitions() {
    const outputs = [
      {
        id: "complete",
        title: "Complete",
        dataType: "boolean"
      }
    ];
    return outputs;
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Integration",
        dataKey: "integration",
        options: [{ label: "Pinecone", value: "pinecone" }],
        useInputToggleDataKey: "useIntegrationInput"
      },
      {
        type: "string",
        label: "Collection ID",
        dataKey: "collectionId",
        useInputToggleDataKey: "useCollectionIdInput"
      }
    ];
  }
  getBody() {
    return import_ts_dedent36.dedent`
      Integration: ${this.data.useIntegrationInput ? "(using input)" : this.data.integration}
      Collection Id: ${this.data.useCollectionIdInput ? "(using input)" : this.data.collectionId}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent36.dedent`
        Takes in a vector, as well as data to store with the vector. This data is stored in the configured vector DB integration for later retrieval.
      `,
      infoBoxTitle: "Vector Store Node",
      contextMenuTitle: "Vector Store",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    var _a, _b;
    const integration = getInputOrData(this.data, inputs, "integration");
    const vectorDb = getIntegration("vectorDatabase", integration, context);
    const indexUrl = getInputOrData(this.data, inputs, "collectionId");
    if (((_a = inputs["vector"]) == null ? void 0 : _a.type) !== "vector") {
      throw new Error(`Expected vector input, got ${(_b = inputs["vector"]) == null ? void 0 : _b.type}`);
    }
    await vectorDb.store(
      { type: "string", value: indexUrl },
      inputs["vector"],
      inputs["data"],
      {
        id: coerceTypeOptional(inputs["id"], "string")
      }
    );
    return {
      ["complete"]: {
        type: "boolean",
        value: true
      }
    };
  }
};
var vectorStoreNode = nodeDefinition(VectorStoreNodeImpl, "Vector Store");

// src/model/nodes/VectorNearestNeighborsNode.ts
var import_non_secure38 = require("nanoid/non-secure");
var import_ts_dedent37 = require("ts-dedent");
var VectorNearestNeighborsNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure38.nanoid)(),
      type: "vectorNearestNeighbors",
      title: "Vector KNN",
      visualData: { x: 0, y: 0, width: 200 },
      data: {
        k: 10,
        integration: "pinecone",
        collectionId: ""
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    inputDefinitions.push({
      id: "vector",
      title: "Vector",
      dataType: "vector",
      required: true
    });
    if (this.data.useIntegrationInput) {
      inputDefinitions.push({
        id: "integration",
        title: "Integration",
        dataType: "string",
        required: true
      });
    }
    if (this.data.useCollectionIdInput) {
      inputDefinitions.push({
        id: "collectionId",
        title: "Collection ID",
        dataType: "string",
        required: true
      });
    }
    if (this.data.useKInput) {
      inputDefinitions.push({
        id: "k",
        title: "K",
        dataType: "number",
        required: true
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    const outputs = [
      {
        id: "results",
        title: "Results",
        dataType: "any[]"
      }
    ];
    return outputs;
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Integration",
        dataKey: "integration",
        options: [{ label: "Pinecone", value: "pinecone" }],
        useInputToggleDataKey: "useIntegrationInput"
      },
      {
        type: "number",
        label: "K",
        dataKey: "k",
        min: 1,
        max: 100,
        step: 1,
        defaultValue: 10,
        useInputToggleDataKey: "useKInput"
      },
      {
        type: "string",
        label: "Collection ID",
        dataKey: "collectionId",
        useInputToggleDataKey: "useCollectionIdInput"
      }
    ];
  }
  getBody() {
    return import_ts_dedent37.dedent`
      Integration: ${this.data.useIntegrationInput ? "(using input)" : this.data.integration}
      K: ${this.data.useKInput ? "(using input)" : this.data.k}
      Collection Id: ${this.data.useCollectionIdInput ? "(using input)" : this.data.collectionId}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent37.dedent`
        Performs a k-nearest neighbors search on the vectors stored in the configured vector DB integration. Takes in a vector and returns the k closest vectors and their corresponding data.
      `,
      infoBoxTitle: "Vector KNN Node",
      contextMenuTitle: "Vector KNN",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    var _a, _b;
    const integration = getInputOrData(this.data, inputs, "integration");
    const vectorDb = getIntegration("vectorDatabase", integration, context);
    const indexUrl = getInputOrData(this.data, inputs, "collectionId");
    const k = getInputOrData(this.data, inputs, "k", "number");
    if (((_a = inputs["vector"]) == null ? void 0 : _a.type) !== "vector") {
      throw new Error(`Expected vector input, got ${(_b = inputs["vector"]) == null ? void 0 : _b.type}`);
    }
    const results = await vectorDb.nearestNeighbors(
      { type: "string", value: indexUrl },
      inputs["vector"],
      k
    );
    return {
      ["results"]: results
    };
  }
};
var vectorNearestNeighborsNode = nodeDefinition(VectorNearestNeighborsNodeImpl, "Vector KNN");

// src/model/nodes/HashNode.ts
var import_non_secure39 = require("nanoid/non-secure");
var crypto = __toESM(require("crypto-js"), 1);
var import_ts_pattern6 = require("ts-pattern");
var import_ts_dedent38 = require("ts-dedent");
var { SHA256, SHA512, MD5, SHA1 } = crypto;
var HashNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "hash",
      title: "Hash",
      id: (0, import_non_secure39.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        algorithm: "sha256"
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "input",
        title: "Input",
        dataType: "string",
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "hash",
        title: "Hash",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Algorithm",
        dataKey: "algorithm",
        options: [
          { value: "md5", label: "MD5" },
          { value: "sha1", label: "SHA1" },
          { value: "sha256", label: "SHA256" },
          { value: "sha512", label: "SHA512" }
        ]
      }
    ];
  }
  getBody() {
    return algorithmDisplayName[this.data.algorithm];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent38.dedent`
        Computes a hash of the input value using the configured hash function.
      `,
      infoBoxTitle: "Hash Node",
      contextMenuTitle: "Hash",
      group: ["Data"]
    };
  }
  async process(inputs) {
    const inputText = coerceType(inputs["input"], "string");
    const hash = (0, import_ts_pattern6.match)(this.data.algorithm).with("md5", () => MD5(inputText).toString()).with("sha1", () => SHA1(inputText).toString()).with("sha256", () => SHA256(inputText).toString()).with("sha512", () => SHA512(inputText).toString()).exhaustive();
    return {
      ["hash"]: {
        type: "string",
        value: hash
      }
    };
  }
};
var algorithmDisplayName = {
  md5: "MD5",
  sha1: "SHA-1",
  sha256: "SHA-256",
  sha512: "SHA-512"
};
var hashNode = nodeDefinition(HashNodeImpl, "Hash");

// src/model/nodes/AbortGraphNode.ts
var import_non_secure40 = require("nanoid/non-secure");
var import_ts_dedent39 = require("ts-dedent");
var AbortGraphNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "abortGraph",
      title: "Abort Graph",
      id: (0, import_non_secure40.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        successfully: true,
        errorMessage: ""
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "data",
        title: "Data or Error",
        dataType: "any",
        description: "The message to abort the graph with."
      }
    ];
    if (this.data.useSuccessfullyInput) {
      inputs.push({
        id: "successfully",
        title: "Successfully",
        dataType: "boolean",
        description: "Whether to successfully abort the graph (early-exit), or error abort the graph."
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [];
  }
  getEditors() {
    return [
      {
        type: "toggle",
        label: "Successfully Abort",
        dataKey: "successfully",
        useInputToggleDataKey: "useSuccessfullyInput"
      },
      {
        type: "string",
        label: "Error Message (if not successfully aborting)",
        dataKey: "errorMessage"
      }
    ];
  }
  getBody() {
    return import_ts_dedent39.dedent`
      ${this.data.useSuccessfullyInput ? "Success depends on input" : this.data.successfully ? "Successfully Abort" : this.data.errorMessage ? `Error Abort: ${this.data.errorMessage}` : "Error Abort"}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent39.dedent`
        Aborts the execution of the entire graph immediately.

        Can either "successfully" abort the graph (early-exit), or "error" abort the graph.
      `,
      infoBoxTitle: "Abort Graph Node",
      contextMenuTitle: "Abort Graph",
      group: ["Logic"]
    };
  }
  async process(inputs, context) {
    var _a;
    const successfully = this.data.useSuccessfullyInput ? coerceTypeOptional(inputs["successfully"], "boolean") ?? this.data.successfully : this.data.successfully;
    if (successfully) {
      context.abortGraph();
    } else {
      const errorMessage = ((_a = coerceTypeOptional(inputs["data"], "string")) == null ? void 0 : _a.trim()) || this.data.errorMessage || "Graph aborted with error";
      context.abortGraph(errorMessage);
    }
    return {};
  }
};
var abortGraphNode = nodeDefinition(AbortGraphNodeImpl, "Abort Graph");

// src/model/nodes/RaceInputsNode.ts
var import_non_secure41 = require("nanoid/non-secure");
var import_ts_dedent40 = require("ts-dedent");
var RaceInputsNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "raceInputs",
      title: "Race Inputs",
      id: (0, import_non_secure41.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 300
      },
      data: {}
    };
    return chartNode;
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const inputConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("input")
    );
    let maxInputNumber = 0;
    for (const connection of inputConnections) {
      const messageNumber = parseInt(connection.inputId.replace("input", ""), 10);
      if (messageNumber > maxInputNumber) {
        maxInputNumber = messageNumber;
      }
    }
    return maxInputNumber + 1;
  }
  getInputDefinitions(connections) {
    const inputs = [];
    const inputCount = this.#getInputPortCount(connections);
    for (let i = 1; i <= inputCount; i++) {
      inputs.push({
        dataType: "any",
        id: `input${i}`,
        title: `Input ${i}`
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "result",
        title: "Result",
        dataType: "any"
      }
    ];
  }
  getEditors() {
    return [];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent40.dedent`
        Takes in multiple inputs and outputs the value of the first one to finish. The other inputs are cancelled.
      `,
      infoBoxTitle: "Race Inputs Node",
      contextMenuTitle: "Race Inputs",
      group: ["Logic"]
    };
  }
  async process(inputs, context) {
    const value = Object.entries(inputs).find(
      ([key, value2]) => key.startsWith("input") && value2 !== void 0 && value2.type !== "control-flow-excluded"
    );
    if (!value) {
      return {
        ["result"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    return {
      ["result"]: value[1]
    };
  }
};
var raceInputsNode = nodeDefinition(RaceInputsNodeImpl, "Race Inputs");

// src/model/nodes/ToJsonNode.ts
var import_non_secure42 = require("nanoid/non-secure");
var import_ts_dedent41 = require("ts-dedent");
var ToJsonNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "toJson",
      title: "To JSON",
      id: (0, import_non_secure42.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 175
      },
      data: {
        indented: true
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "data",
        title: "Data",
        dataType: "any",
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "json",
        title: "JSON",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "toggle",
        label: "Indented",
        dataKey: "indented"
      }
    ];
  }
  getBody() {
    return this.data.indented ? "Indented" : "Not indented";
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent41.dedent`
        Turns the input value into its JSON equivalent (stringifies the value).
      `,
      infoBoxTitle: "To JSON Node",
      contextMenuTitle: "To JSON",
      group: ["Text"]
    };
  }
  async process(inputs) {
    const data = coerceType(inputs["data"], "any");
    const toJson = this.data.indented ? JSON.stringify(data, null, 2) : JSON.stringify(data);
    return {
      ["json"]: {
        type: "string",
        value: toJson
      }
    };
  }
};
var toJsonNode = nodeDefinition(ToJsonNodeImpl, "To JSON");

// src/model/nodes/JoinNode.ts
var import_non_secure43 = require("nanoid/non-secure");
var import_ts_dedent42 = require("ts-dedent");
var JoinNodeImpl = class extends NodeImpl {
  static create = () => {
    const chartNode = {
      type: "join",
      title: "Join",
      id: (0, import_non_secure43.nanoid)(),
      data: {
        flatten: true,
        joinString: "\n"
      },
      visualData: {
        x: 0,
        y: 0,
        width: 150
      }
    };
    return chartNode;
  };
  getInputDefinitions(connections) {
    const inputs = [];
    const inputCount = this.#getInputPortCount(connections);
    if (this.data.useJoinStringInput) {
      inputs.push({
        dataType: "string",
        id: "joinString",
        title: "Join String"
      });
    }
    for (let i = 1; i <= inputCount; i++) {
      inputs.push({
        dataType: "string",
        id: `input${i}`,
        title: `Input ${i}`
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "string",
        id: "output",
        title: "Joined"
      }
    ];
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const inputConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("input")
    );
    let maxInputNumber = 0;
    for (const connection of inputConnections) {
      const messageNumber = parseInt(connection.inputId.replace("input", ""), 10);
      if (messageNumber > maxInputNumber) {
        maxInputNumber = messageNumber;
      }
    }
    return maxInputNumber + 1;
  }
  getEditors() {
    return [
      {
        type: "toggle",
        label: "Flatten",
        dataKey: "flatten"
      },
      {
        type: "code",
        label: "Join String",
        dataKey: "joinString",
        useInputToggleDataKey: "useJoinStringInput",
        language: "plaintext"
      }
    ];
  }
  getBody() {
    return this.data.useJoinStringInput ? "(Join value is input)" : this.data.joinString === "\n" ? "(New line)" : this.data.joinString === "	" ? "(Tab)" : this.data.joinString === " " ? "(Space)" : this.data.joinString;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent42.dedent`
        Takes an array of strings, and joins them using the configured delimiter.

        Defaults to a newline.
      `,
      infoBoxTitle: "Join Node",
      contextMenuTitle: "Join",
      group: ["Text"]
    };
  }
  async process(inputs) {
    const joinString = this.data.useJoinStringInput ? coerceTypeOptional(inputs["joinString"], "string") ?? this.data.joinString : this.data.joinString;
    const normalizedJoinString = handleEscapeCharacters(joinString);
    const inputKeys = Object.keys(inputs).filter((key) => key.startsWith("input"));
    const inputValueStrings = [];
    for (let i = 1; i <= inputKeys.length; i++) {
      const inputValue = inputs[`input${i}`];
      if (isArrayDataValue(inputValue) && this.data.flatten) {
        for (const value of inputValue.value) {
          inputValueStrings.push(coerceType(inferType(value), "string"));
        }
      } else if (inputValue) {
        inputValueStrings.push(coerceType(inputValue, "string"));
      }
    }
    const outputValue = inputValueStrings.join(normalizedJoinString);
    return {
      ["output"]: {
        type: "string",
        value: outputValue
      }
    };
  }
};
var joinNode = nodeDefinition(JoinNodeImpl, "Coalesce");

// src/model/nodes/FilterNode.ts
var import_non_secure44 = require("nanoid/non-secure");
var import_lodash_es9 = require("lodash");
var import_ts_dedent43 = require("ts-dedent");
var FilterNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "filter",
      title: "Filter",
      id: (0, import_non_secure44.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 175
      },
      data: {}
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "array",
        title: "Array",
        dataType: "any[]",
        required: true
      },
      {
        id: "include",
        title: "Include",
        dataType: "boolean[]",
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "filtered",
        title: "Filtered",
        dataType: "any[]"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent43.dedent`
        Takes in both an array of values, and an array of booleans of the same length, and filters the array where the corresponding boolean is true.
      `,
      infoBoxTitle: "Filter Node",
      contextMenuTitle: "Filter",
      group: ["Lists"]
    };
  }
  async process(inputs) {
    var _a;
    const array = coerceType(inputs["array"], "any[]");
    const include = coerceType(inputs["include"], "boolean[]");
    const zipped = (0, import_lodash_es9.zip)(array, include);
    const filtered = zipped.filter(([_, include2]) => include2).map(([value, _]) => value);
    return {
      ["filtered"]: {
        type: ((_a = inputs["array"]) == null ? void 0 : _a.type) ?? "any",
        value: filtered
      }
    };
  }
};
var filterNode = nodeDefinition(FilterNodeImpl, "Filter");

// src/model/nodes/ObjectNode.ts
var import_non_secure45 = require("nanoid/non-secure");
var import_ts_dedent44 = require("ts-dedent");
var DEFAULT_JSON_TEMPLATE = `{
  "key": "{{input}}"
}`;
var ObjectNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "object",
      title: "Object",
      id: (0, import_non_secure45.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        jsonTemplate: DEFAULT_JSON_TEMPLATE
      }
    };
    return chartNode;
  }
  getInputDefinitions(connections) {
    const inputNames = [...new Set(this.chartNode.data.jsonTemplate.match(/\{\{([^}]+)\}\}/g))];
    return (inputNames == null ? void 0 : inputNames.map((inputName) => {
      return {
        // id and title should not have the {{ and }}
        id: inputName.slice(2, -2),
        title: inputName.slice(2, -2),
        dataType: "any",
        required: false
      };
    })) ?? [];
  }
  getOutputDefinitions() {
    return [
      {
        dataType: ["object", "object[]"],
        id: "output",
        title: "Output"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "custom",
        customEditorId: "ObjectNodeAiAssist",
        label: "AI Assist"
      },
      {
        type: "code",
        label: "JSON Template",
        dataKey: "jsonTemplate",
        language: "json",
        theme: "prompt-interpolation"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent44.dedent`
        Creates an object from input values and a JSON template, escaping the input values and inserting them into the template.

        Use double-quotes around the input values to escape them. String values are automatically escaped.

        Useful for creating objects from multiple inputs.
      `,
      infoBoxTitle: "Object Node",
      contextMenuTitle: "Object",
      group: ["Objects"]
    };
  }
  interpolate(baseString, values3) {
    return baseString.replace(/("?)\{\{([^}]+)\}\}("?)/g, (_m, openQuote, key, _closeQuote) => {
      const isQuoted = Boolean(openQuote);
      const value = values3[key];
      if (value == null) {
        return "null";
      }
      if (isQuoted && typeof value === "string") {
        return JSON.stringify(value);
      }
      if (isQuoted) {
        return JSON.stringify(JSON.stringify(value));
      }
      return JSON.stringify(value);
    });
  }
  async process(inputs) {
    const inputMap = Object.keys(inputs).reduce(
      (acc, key) => {
        var _a;
        acc[key] = (_a = inputs[key]) == null ? void 0 : _a.value;
        return acc;
      },
      {}
    );
    const outputValue = JSON.parse(this.interpolate(this.chartNode.data.jsonTemplate, inputMap));
    if (Array.isArray(outputValue)) {
      return {
        output: {
          type: "object[]",
          value: outputValue
        }
      };
    }
    return {
      output: {
        type: "object",
        value: outputValue
      }
    };
  }
};
var objectNode = nodeDefinition(ObjectNodeImpl, "Object");

// src/model/nodes/BooleanNode.ts
var import_non_secure46 = require("nanoid/non-secure");
var import_ts_dedent45 = require("ts-dedent");
var BooleanNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "boolean",
      title: "Bool",
      id: (0, import_non_secure46.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 130
      },
      data: {
        value: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return this.data.useValueInput ? [
      {
        dataType: "any",
        id: "input",
        title: "Input"
      }
    ] : [];
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "boolean",
        id: "value",
        title: "Value"
      }
    ];
  }
  getEditors() {
    return [{ type: "toggle", label: "Value", dataKey: "value", useInputToggleDataKey: "useValueInput" }];
  }
  getBody() {
    return this.data.useValueInput ? `(Input to bool)` : (this.data.value ?? false).toString();
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent45.dedent`
        Outputs a boolean constant, or converts an input value into a boolean.
      `,
      infoBoxTitle: "Bool Node",
      contextMenuTitle: "Bool",
      group: ["Data"]
    };
  }
  async process(inputs) {
    const value = this.data.useValueInput ? coerceTypeOptional(inputs["input"], "boolean") ?? this.data.value ?? false : this.data.value ?? false;
    return {
      ["value"]: {
        type: "boolean",
        value
      }
    };
  }
};
var booleanNode = nodeDefinition(BooleanNodeImpl, "Boolean");

// src/model/nodes/CompareNode.ts
var import_non_secure47 = require("nanoid/non-secure");
var import_lodash_es10 = require("lodash");
var import_ts_pattern7 = require("ts-pattern");
var import_ts_dedent46 = require("ts-dedent");
var CompareNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "compare",
      title: "Compare",
      id: (0, import_non_secure47.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 160
      },
      data: {
        comparisonFunction: "=="
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        dataType: "any",
        id: "a",
        title: "A"
      },
      {
        dataType: "any",
        id: "b",
        title: "B"
      }
    ];
    if (this.data.useComparisonFunctionInput) {
      inputs.push({
        dataType: "string",
        id: "comparisonFunction",
        title: "Comparison Function"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "boolean",
        id: "output",
        title: "Output"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Comparison Function",
        dataKey: "comparisonFunction",
        options: [
          { label: "==", value: "==" },
          { label: "!=", value: "!=" },
          { label: "<", value: "<" },
          { label: "<=", value: "<=" },
          { label: ">", value: ">" },
          { label: ">=", value: ">=" },
          { label: "and", value: "and" },
          { label: "or", value: "or" },
          { label: "xor", value: "xor" },
          { label: "nand", value: "nand" },
          { label: "nor", value: "nor" },
          { label: "xnor", value: "xnor" }
        ],
        useInputToggleDataKey: "useComparisonFunctionInput"
      }
    ];
  }
  getBody() {
    return this.data.useComparisonFunctionInput ? "A (Comparison Function) B" : `A ${this.data.comparisonFunction} B`;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent46.dedent`
        Compares two values using the configured operator and outputs the result.

        If the data types of the values do not match, then the B value is converted to the type of the A value.
      `,
      infoBoxTitle: "Compare Node",
      contextMenuTitle: "Compare",
      group: ["Logic"]
    };
  }
  async process(inputs) {
    const comparisonFunction = this.data.useComparisonFunctionInput ? coerceType(inputs["comparisonFunction"], "string") : this.data.comparisonFunction;
    const inputA = inputs["a"];
    const inputB = inputs["b"];
    if (!inputA) {
      return {
        ["output"]: {
          type: "boolean",
          value: (0, import_ts_pattern7.match)(comparisonFunction).with("==", () => !inputB).with("!=", () => !!inputB).otherwise(() => false)
        }
      };
    }
    const value1 = inputA.value;
    const value2 = (inputB == null ? void 0 : inputB.type) !== inputA.type ? coerceTypeOptional(inputB, inputA.type) : inputB.value;
    return {
      ["output"]: {
        type: "boolean",
        value: (0, import_ts_pattern7.match)(comparisonFunction).with("==", () => (0, import_lodash_es10.isEqual)(value1, value2)).with("!=", () => !(0, import_lodash_es10.isEqual)(value1, value2)).with("<", () => value1 < value2).with(">", () => value1 > value2).with("<=", () => value1 <= value2).with(">=", () => value1 >= value2).with("and", () => !!(value1 && value2)).with("or", () => !!(value1 || value2)).with("xor", () => !!(value1 ? !value2 : value2)).with("nand", () => !(value1 && value2)).with("nor", () => !(value1 || value2)).with("xnor", () => !(value1 ? !value2 : value2)).exhaustive()
      }
    };
  }
};
var compareNode = nodeDefinition(CompareNodeImpl, "Compare");

// src/model/nodes/EvaluateNode.ts
var import_non_secure48 = require("nanoid/non-secure");
var import_ts_pattern8 = require("ts-pattern");
var import_ts_dedent47 = require("ts-dedent");
var unaryOperation = ["abs", "negate"];
var isUnaryOp = (operation) => unaryOperation.includes(operation);
var EvaluateNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "evaluate",
      title: "Evaluate",
      id: (0, import_non_secure48.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 175
      },
      data: {
        operation: "+"
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        dataType: "number",
        id: "a",
        title: "A"
      }
    ];
    const isUnary = !this.data.useOperationInput && isUnaryOp(this.data.operation);
    if (!isUnary) {
      inputs.push({
        dataType: "number",
        id: "b",
        title: "B"
      });
    }
    if (this.data.useOperationInput) {
      inputs.push({
        dataType: "string",
        id: "operation",
        title: "Operation"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "number",
        id: "output",
        title: "Output"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Operation",
        dataKey: "operation",
        options: [
          { label: "+", value: "+" },
          { label: "-", value: "-" },
          { label: "*", value: "*" },
          { label: "/", value: "/" },
          { label: "^", value: "^" },
          { label: "%", value: "%" },
          { label: "abs", value: "abs" },
          { label: "negate", value: "negate" }
        ],
        useInputToggleDataKey: "useOperationInput"
      }
    ];
  }
  getBody() {
    const isUnary = !this.data.useOperationInput && isUnaryOp(this.data.operation);
    if (isUnary) {
      return (0, import_ts_pattern8.match)(this.data.operation).with("abs", () => "abs(A)").with("negate", () => "-A").exhaustive();
    }
    if (this.data.operation === "^") {
      return "!markdownA<sup>B</sup>";
    }
    return this.data.useOperationInput ? "A (Operation) B" : `A ${this.data.operation} B`;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent47.dedent`
        Evaluates the configured mathematical operation on the input values and outputs the result.

        For more complex operations, you should use the \`Code\` node.
      `,
      infoBoxTitle: "Evaluate Node",
      contextMenuTitle: "Evaluate",
      group: ["Numbers"]
    };
  }
  async process(inputs) {
    const operation = this.data.useOperationInput ? coerceType(inputs["operation"], "string") : this.data.operation;
    const inputA = coerceTypeOptional(inputs["a"], "number");
    const inputB = coerceTypeOptional(inputs["b"], "number");
    if (isUnaryOp(operation) && inputA) {
      return {
        ["output"]: {
          type: "number",
          value: (0, import_ts_pattern8.match)(operation).with("abs", () => Math.abs(inputA)).with("negate", () => -inputA).exhaustive()
        }
      };
    }
    if (inputA == null || inputB == null) {
      throw new Error("Missing input");
    }
    return {
      ["output"]: {
        type: "number",
        value: (0, import_ts_pattern8.match)(operation).with("+", () => inputA + inputB).with("-", () => inputA - inputB).with("*", () => inputA * inputB).with("/", () => inputA / inputB).with("^", () => Math.pow(inputA, inputB)).with("%", () => inputA % inputB).exhaustive()
      }
    };
  }
};
var evaluateNode = nodeDefinition(EvaluateNodeImpl, "Evaluate");

// src/model/nodes/NumberNode.ts
var import_non_secure49 = require("nanoid/non-secure");
var import_ts_dedent48 = require("ts-dedent");
var NumberNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "number",
      title: "Number",
      id: (0, import_non_secure49.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        value: 0,
        round: false,
        roundTo: 0
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return this.data.useValueInput ? [
      {
        dataType: "any",
        id: "input",
        title: "Input"
      }
    ] : [];
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "number",
        id: "value",
        title: "Value"
      }
    ];
  }
  getEditors() {
    return [
      { type: "number", label: "Value", dataKey: "value", useInputToggleDataKey: "useValueInput" },
      { type: "toggle", label: "Round", dataKey: "round" },
      { type: "number", label: "Round To", dataKey: "roundTo" }
    ];
  }
  getBody() {
    return this.data.useValueInput ? `(Input to number)` : (this.data.value ?? 0).toLocaleString();
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent48.dedent`
        Outputs a number constant, or converts an input value into a number.

        Can be configured to round the number to a certain number of decimal places.
      `,
      infoBoxTitle: "Number Node",
      contextMenuTitle: "Number",
      group: ["Numbers"]
    };
  }
  async process(inputs) {
    let value = this.data.useValueInput ? coerceTypeOptional(inputs["input"], "number") ?? this.data.value ?? 0 : this.data.value ?? 0;
    const { roundTo = 0, round = false } = this.data;
    if (round) {
      value = Math.round(value * Math.pow(10, roundTo)) / Math.pow(10, roundTo);
    }
    return {
      ["value"]: {
        type: "number",
        value
      }
    };
  }
};
var numberNode = nodeDefinition(NumberNodeImpl, "Number");

// src/model/nodes/RandomNumberNode.ts
var import_non_secure50 = require("nanoid/non-secure");
var import_ts_dedent49 = require("ts-dedent");
var RandomNumberNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "randomNumber",
      title: "RNG",
      id: (0, import_non_secure50.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 150
      },
      data: {
        min: 0,
        max: 1,
        integers: false,
        maxInclusive: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [];
    if (this.data.useMinInput) {
      inputs.push({
        dataType: "number",
        id: "min",
        title: "Min"
      });
    }
    if (this.data.useMaxInput) {
      inputs.push({
        dataType: "number",
        id: "max",
        title: "Max"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "number",
        id: "value",
        title: "Value"
      }
    ];
  }
  getEditors() {
    return [
      { type: "number", label: "Min", dataKey: "min", useInputToggleDataKey: "useMinInput" },
      { type: "number", label: "Max", dataKey: "max", useInputToggleDataKey: "useMaxInput" },
      { type: "toggle", label: "Integers", dataKey: "integers" },
      { type: "toggle", label: "Max Inclusive", dataKey: "maxInclusive" }
    ];
  }
  getBody() {
    return import_ts_dedent49.dedent`
      Min: ${this.data.useMinInput ? "(Input)" : this.data.min ?? 0}
      Max: ${this.data.useMaxInput ? "(Input)" : this.data.max ?? 1}
      ${this.data.integers ? "Integers" : "Floats"}
      ${this.data.maxInclusive ? "Max Inclusive" : "Max Exclusive"}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent49.dedent`
        Outputs a random number between the configured min and max values.

        Can be configured to output only integers, and whether the max value is inclusive or exclusive.
      `,
      infoBoxTitle: "RNG Node",
      contextMenuTitle: "RNG",
      group: ["Numbers"]
    };
  }
  async process(inputs) {
    const min = this.data.useMinInput ? coerceTypeOptional(inputs["min"], "number") ?? this.data.min ?? 0 : this.data.min ?? 0;
    let max2 = this.data.useMaxInput ? coerceTypeOptional(inputs["max"], "number") ?? this.data.max ?? 1 : this.data.max ?? 1;
    if (this.data.integers && this.data.maxInclusive) {
      max2 += 1;
    }
    let value = Math.random() * (max2 - min) + min;
    if (this.data.integers) {
      value = Math.floor(value);
    }
    return {
      ["value"]: {
        type: "number",
        value
      }
    };
  }
};
var randomNumberNode = nodeDefinition(RandomNumberNodeImpl, "Random Number");

// src/model/nodes/ShuffleNode.ts
var import_non_secure51 = require("nanoid/non-secure");
var import_lodash_es11 = require("lodash");
var import_ts_dedent50 = require("ts-dedent");
var ShuffleNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "shuffle",
      title: "Shuffle",
      id: (0, import_non_secure51.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 175
      },
      data: {}
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        dataType: "any[]",
        id: "array",
        title: "Array"
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "any[]",
        id: "shuffled",
        title: "Shuffled"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent50.dedent`
        Shuffles the input array. Outputs the shuffled array.
      `,
      infoBoxTitle: "Shuffle Node",
      contextMenuTitle: "Shuffle",
      group: ["Lists"]
    };
  }
  async process(inputs) {
    var _a;
    const input = inputs["array"];
    const items = input ? isArrayDataValue(input) ? input.value : [input.value] : [];
    const shuffled = (0, import_lodash_es11.shuffle)(items);
    return {
      ["shuffled"]: {
        type: ((_a = inputs["array"]) == null ? void 0 : _a.type) ?? "any[]",
        value: shuffled
      }
    };
  }
};
var shuffleNode = nodeDefinition(ShuffleNodeImpl, "Shuffle");

// src/model/nodes/CommentNode.ts
var import_non_secure52 = require("nanoid/non-secure");
var import_ts_dedent51 = require("ts-dedent");
var CommentNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "comment",
      title: "Comment",
      id: (0, import_non_secure52.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 600
      },
      data: {
        text: "",
        height: 600,
        color: "rgba(255,255,255,1)",
        backgroundColor: "rgba(0,0,0,0.05)"
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [];
  }
  getOutputDefinitions() {
    return [];
  }
  getEditors() {
    return [
      {
        type: "color",
        label: "Color",
        dataKey: "color"
      },
      {
        type: "color",
        label: "Background Color",
        dataKey: "backgroundColor"
      },
      {
        type: "code",
        label: "Text",
        dataKey: "text",
        language: "markdown",
        theme: "vs-dark"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent51.dedent`
        A comment node is a node that does nothing. It is useful for adding notes to a graph.
      `,
      infoBoxTitle: "Comment Node",
      contextMenuTitle: "Comment",
      group: ["Advanced"]
    };
  }
  async process() {
    return {};
  }
};
var commentNode = nodeDefinition(CommentNodeImpl, "Comment");

// src/model/nodes/ImageNode.ts
var import_non_secure53 = require("nanoid/non-secure");
var ImageNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure53.nanoid)(),
      type: "image",
      title: "Image",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        useDataInput: false,
        mediaType: "image/png",
        useMediaTypeInput: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.useDataInput) {
      inputDefinitions.push({
        id: "data",
        title: "Data",
        dataType: "binary",
        coerced: false
      });
    }
    if (this.chartNode.data.useMediaTypeInput) {
      inputDefinitions.push({
        id: "mediaType",
        title: "Media Type",
        dataType: "string"
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "image",
        title: "Image",
        dataType: "image"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Media Type",
        dataKey: "mediaType",
        options: [
          { value: "image/png", label: "PNG" },
          { value: "image/jpeg", label: "JPEG" },
          { value: "image/gif", label: "GIF" }
        ],
        useInputToggleDataKey: "useMediaTypeInput"
      },
      {
        type: "imageBrowser",
        label: "Image",
        dataKey: "data",
        useInputToggleDataKey: "useDataInput",
        mediaTypeDataKey: "mediaType"
      }
    ];
  }
  static getUIData() {
    return {
      contextMenuTitle: "Image",
      group: "Data",
      infoBoxTitle: "Image Node",
      infoBoxBody: "Defines a static image for use with other nodes. Can convert a binary type into an image type."
    };
  }
  async process(inputData, context) {
    var _a, _b;
    let data;
    if (this.chartNode.data.useDataInput) {
      data = expectType(inputData["data"], "binary");
    } else {
      const dataRef = (_a = this.data.data) == null ? void 0 : _a.refId;
      if (!dataRef) {
        throw new Error("No data ref");
      }
      const encodedData = (_b = context.project.data) == null ? void 0 : _b[dataRef];
      if (!encodedData) {
        throw new Error(`No data at ref ${dataRef}`);
      }
      data = base64ToUint8Array(encodedData);
    }
    const mediaType = this.chartNode.data.useMediaTypeInput ? expectType(inputData["mediaType"], "string") : this.chartNode.data.mediaType;
    return {
      ["image"]: {
        type: "image",
        value: { mediaType, data }
      }
    };
  }
};
var imageNode = nodeDefinition(ImageNodeImpl, "Image");

// src/model/nodes/AudioNode.ts
var import_non_secure54 = require("nanoid/non-secure");
var AudioNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure54.nanoid)(),
      type: "audio",
      title: "Audio",
      visualData: { x: 0, y: 0, width: 300 },
      data: {
        useDataInput: false,
        useMediaTypeInput: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.useDataInput) {
      inputDefinitions.push({
        id: "data",
        title: "Data",
        dataType: "string",
        coerced: false
      });
    }
    if (this.chartNode.data.useMediaTypeInput) {
      inputDefinitions.push({
        id: "mediaType",
        title: "Media Type",
        dataType: "string",
        coerced: false
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "data",
        title: "Audio Data",
        dataType: "audio"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "fileBrowser",
        label: "Audio File",
        dataKey: "data",
        mediaTypeDataKey: "mediaType",
        useInputToggleDataKey: "useDataInput",
        accept: "audio/*"
      },
      {
        type: "string",
        label: "Media Type",
        dataKey: "mediaType",
        useInputToggleDataKey: "useMediaTypeInput"
      }
    ];
  }
  static getUIData() {
    return {
      contextMenuTitle: "Audio",
      group: "Data",
      infoBoxTitle: "Audio Node",
      infoBoxBody: "Defines an audio sample for use with other nodes. Can convert a binary type into an audio type."
    };
  }
  async process(inputData, context) {
    var _a, _b;
    let data;
    const mediaType = getInputOrData(this.data, inputData, "mediaType", "string") || "audio/wav";
    if (this.chartNode.data.useDataInput) {
      data = expectType(inputData["data"], "binary");
    } else {
      const dataRef = (_a = this.data.data) == null ? void 0 : _a.refId;
      if (!dataRef) {
        throw new Error("No data ref");
      }
      const encodedData = (_b = context.project.data) == null ? void 0 : _b[dataRef];
      if (!encodedData) {
        throw new Error(`No data at ref ${dataRef}`);
      }
      data = base64ToUint8Array(encodedData);
    }
    return {
      ["data"]: {
        type: "audio",
        value: { data, mediaType }
      }
    };
  }
};
var audioNode = nodeDefinition(AudioNodeImpl, "Audio");

// src/model/nodes/HttpCallNode.ts
var import_non_secure55 = require("nanoid/non-secure");
var HttpCallNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "httpCall",
      title: "Http Call",
      id: (0, import_non_secure55.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        method: "GET",
        url: "",
        headers: "",
        body: "",
        errorOnNon200: true
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [];
    if (this.data.useMethodInput) {
      inputs.push({
        dataType: "string",
        id: "method",
        title: "Method"
      });
    }
    if (this.data.useUrlInput) {
      inputs.push({
        dataType: "string",
        id: "url",
        title: "URL"
      });
    }
    if (this.data.useHeadersInput) {
      inputs.push({
        dataType: "object",
        id: "headers",
        title: "Headers"
      });
    }
    if (this.data.useBodyInput) {
      inputs.push({
        dataType: "string",
        id: "req_body",
        title: "Body"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    const outputDefinitions = [];
    if (this.data.isBinaryOutput) {
      outputDefinitions.push({
        dataType: "binary",
        id: "binary",
        title: "Binary"
      });
    } else {
      outputDefinitions.push(
        {
          dataType: "string",
          id: "res_body",
          title: "Body"
        },
        {
          dataType: "object",
          id: "json",
          title: "JSON"
        }
      );
    }
    outputDefinitions.push(
      {
        dataType: "number",
        id: "statusCode",
        title: "Status Code"
      },
      {
        dataType: "object",
        id: "res_headers",
        title: "Headers"
      }
    );
    return outputDefinitions;
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Method",
        dataKey: "method",
        useInputToggleDataKey: "useMethodInput",
        options: [
          { label: "GET", value: "GET" },
          { label: "POST", value: "POST" },
          { label: "PUT", value: "PUT" },
          { label: "DELETE", value: "DELETE" }
        ]
      },
      {
        type: "string",
        label: "URL",
        dataKey: "url",
        useInputToggleDataKey: "useUrlInput"
      },
      {
        type: "code",
        label: "Headers",
        dataKey: "headers",
        useInputToggleDataKey: "useHeadersInput",
        language: "json"
      },
      {
        type: "code",
        label: "Body",
        dataKey: "body",
        useInputToggleDataKey: "useBodyInput",
        language: "json"
      },
      {
        type: "toggle",
        label: "Binary Output",
        dataKey: "isBinaryOutput",
        helperMessage: "Toggle on if the response is expected to be binary data"
      },
      {
        type: "toggle",
        label: "Error on non-200 status code",
        dataKey: "errorOnNon200"
      }
    ];
  }
  getBody() {
    return import_ts_dedent.dedent`
      ${this.data.useMethodInput ? "(Method Using Input)" : this.data.method} ${this.data.useUrlInput ? "(URL Using Input)" : this.data.url} ${this.data.useHeadersInput ? "\nHeaders: (Using Input)" : this.data.headers.trim() ? `
Headers: ${this.data.headers}` : ""}${this.data.useBodyInput ? "\nBody: (Using Input)" : this.data.body.trim() ? `
Body: ${this.data.body}` : ""}${this.data.errorOnNon200 ? "\nError on non-200" : ""}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Makes an HTTP call to the specified URL with the given method, headers, and body.
      `,
      infoBoxTitle: "HTTP Call Node",
      contextMenuTitle: "HTTP Call",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    var _a;
    const method = getInputOrData(this.data, inputs, "method", "string");
    const url = getInputOrData(this.data, inputs, "url", "string");
    try {
      new URL(url);
    } catch (err) {
      throw new Error(`Invalid URL: ${url}`);
    }
    let headers;
    if (this.data.useHeadersInput) {
      const headersInput = inputs["headers"];
      if ((headersInput == null ? void 0 : headersInput.type) === "string") {
        headers = JSON.parse(headersInput.value);
      } else if ((headersInput == null ? void 0 : headersInput.type) === "object") {
        headers = headersInput.value;
      } else {
        headers = coerceType(headersInput, "object");
      }
    } else if (this.data.headers.trim()) {
      headers = JSON.parse(this.data.headers);
    }
    let body;
    if (this.data.useBodyInput) {
      const bodyInput = inputs["req_body"];
      if ((bodyInput == null ? void 0 : bodyInput.type) === "string") {
        body = bodyInput.value;
      } else if ((bodyInput == null ? void 0 : bodyInput.type) === "object") {
        body = JSON.stringify(bodyInput.value);
      } else {
        body = coerceType(bodyInput, "string");
      }
    } else {
      body = this.data.body || void 0;
    }
    try {
      const response = await fetch(url, {
        method,
        headers,
        body,
        signal: context.signal,
        mode: "cors"
      });
      const output = {
        ["statusCode"]: {
          type: "number",
          value: response.status
        },
        ["res_headers"]: {
          type: "object",
          value: Object.fromEntries(response.headers.entries())
        }
      };
      if (this.data.isBinaryOutput) {
        const responseBlob = await response.blob();
        output["binary"] = {
          type: "binary",
          value: new Uint8Array(await responseBlob.arrayBuffer())
        };
      } else {
        const responseText = await response.text();
        output["res_body"] = {
          type: "string",
          value: responseText
        };
        if ((_a = response.headers.get("content-type")) == null ? void 0 : _a.includes("application/json")) {
          const jsonData = JSON.parse(responseText);
          output["json"] = {
            type: "object",
            value: jsonData
          };
        } else {
          output["json"] = {
            type: "control-flow-excluded",
            value: void 0
          };
        }
      }
      return output;
    } catch (err) {
      const { message } = getError(err);
      if (message.includes("Load failed") || message.includes("Failed to fetch")) {
        if (context.executor === "browser") {
          throw new Error(
            "Failed to make HTTP call. You may be running into CORS problems. Try using the Node executor in the top-right menu."
          );
        }
      }
      throw err;
    }
  }
};
var httpCallNode = nodeDefinition(HttpCallNodeImpl, "Http Call");

// src/model/nodes/DelayNode.ts
var import_non_secure56 = require("nanoid/non-secure");
var import_ts_dedent52 = require("ts-dedent");
var DelayNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "delay",
      title: "Delay",
      id: (0, import_non_secure56.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 175
      },
      data: {
        delay: 0
      }
    };
    return chartNode;
  }
  getInputDefinitions(connections) {
    const inputs = [];
    const inputCount = this.#getInputPortCount(connections);
    if (this.data.useDelayInput) {
      inputs.push({
        dataType: "number",
        id: "delay",
        title: "Delay (ms)"
      });
    }
    for (let i = 1; i <= inputCount; i++) {
      inputs.push({
        dataType: "any",
        id: `input${i}`,
        title: `Input ${i}`
      });
    }
    return inputs;
  }
  getOutputDefinitions(connections) {
    const outputs = [];
    const inputCount = this.#getInputPortCount(connections);
    for (let i = 1; i <= inputCount - 1; i++) {
      outputs.push({
        dataType: "any",
        id: `output${i}`,
        title: `Output ${i}`
      });
    }
    return outputs;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent52.dedent`
        Delays the execution and then passes the input value to the output without any modifications.
      `,
      infoBoxTitle: "Delay Node",
      contextMenuTitle: "Delay",
      group: ["Logic"]
    };
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const inputConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("input")
    );
    let maxInputNumber = 0;
    for (const connection of inputConnections) {
      const messageNumber = parseInt(connection.inputId.replace("input", ""), 10);
      if (messageNumber > maxInputNumber) {
        maxInputNumber = messageNumber;
      }
    }
    return maxInputNumber + 1;
  }
  getEditors() {
    return [
      {
        type: "number",
        label: "Delay (ms)",
        dataKey: "delay",
        useInputToggleDataKey: "useDelayInput",
        defaultValue: 0
      }
    ];
  }
  getBody() {
    return `Delay ${this.data.useDelayInput ? "(Input ms)" : `${this.chartNode.data.delay}ms`}`;
  }
  async process(inputData) {
    const delayAmount = getInputOrData(this.data, inputData, "delay", "number");
    await new Promise((resolve) => setTimeout(resolve, delayAmount));
    const inputCount = Object.keys(inputData).filter((key) => key.startsWith("input")).length;
    const outputs = {};
    for (let i = 1; i <= inputCount; i++) {
      const input = inputData[`input${i}`];
      outputs[`output${i}`] = input;
    }
    return outputs;
  }
};
var delayNode = nodeDefinition(DelayNodeImpl, "Delay");

// src/model/nodes/AppendToDatasetNode.ts
var import_non_secure57 = require("nanoid/non-secure");
var import_ts_dedent53 = require("ts-dedent");
var AppendToDatasetNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure57.nanoid)(),
      type: "appendToDataset",
      title: "Append to Dataset",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        datasetId: ""
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    inputDefinitions.push({
      id: "data",
      dataType: "string[]",
      title: "Data",
      description: "The data to append to the dataset. May be a string or array of strings. If an array, each element will be a column in the dataset."
    });
    inputDefinitions.push({
      id: "id",
      dataType: "string",
      title: "ID",
      description: "The ID of the row to append. If not provided, a random ID will be generated. If an existing ID is provided, the row will be overwritten."
    });
    inputDefinitions.push({
      id: "embedding",
      dataType: "vector",
      title: "Embedding",
      description: "The vector embedding to store with the row."
    });
    if (this.data.useDatasetIdInput) {
      inputDefinitions.push({
        id: "datasetId",
        title: "Dataset ID",
        dataType: "string",
        description: "The ID of the dataset to append to."
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "dataset",
        title: "Dataset",
        dataType: "object"
        // technically string[][]...
      },
      {
        id: "id_out",
        title: "ID",
        dataType: "string"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent53.dedent`
        Appends a row of data to the specified dataset.
      `,
      infoBoxTitle: "Append to Dataset Node",
      contextMenuTitle: "Append to Dataset",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [
      {
        type: "datasetSelector",
        label: "Dataset",
        dataKey: "datasetId",
        useInputToggleDataKey: "useDatasetIdInput"
      }
    ];
  }
  async process(inputs, context) {
    const { datasetProvider } = context;
    if (datasetProvider == null) {
      throw new Error("datasetProvider is required");
    }
    const datasetId = getInputOrData(this.data, inputs, "datasetId", "string");
    const dataId = coerceTypeOptional(inputs["id"], "string") || newId();
    const embedding = coerceTypeOptional(inputs["embedding"], "vector");
    const dataInput = inputs["data"];
    if (!dataInput) {
      throw new Error("data input is required");
    }
    const data = arrayizeDataValue(unwrapDataValue(dataInput));
    const stringData = data.map((d) => coerceType(d, "string"));
    const newData = {
      id: dataId,
      data: stringData,
      embedding
    };
    await datasetProvider.putDatasetRow(datasetId, newData);
    return {
      ["dataset"]: {
        type: "object",
        value: newData
      },
      ["id_out"]: {
        type: "string",
        value: datasetId
      }
    };
  }
};
var appendToDatasetNode = nodeDefinition(AppendToDatasetNodeImpl, "Append To Dataset");

// src/model/nodes/CreateDatasetNode.ts
var CreateDatasetNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: newId(),
      type: "createDataset",
      title: "Create Dataset",
      visualData: { x: 0, y: 0, width: 250 },
      data: {}
    };
  }
  getInputDefinitions() {
    return [
      {
        id: "datasetId",
        title: "Dataset ID",
        dataType: "string"
      },
      {
        id: "datasetName",
        title: "Dataset Name",
        dataType: "string"
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "datasetId_out",
        title: "Dataset ID",
        dataType: "string"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Creates a new dataset with the provided ID and name. If the dataset already exists, it does nothing.
      `,
      infoBoxTitle: "Create Dataset Node",
      contextMenuTitle: "Create Dataset",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    const { datasetProvider } = context;
    if (datasetProvider == null) {
      throw new Error("datasetProvider is required");
    }
    const datasetId = coerceTypeOptional(inputs["datasetId"], "string") || newId();
    const datasetName = coerceTypeOptional(inputs["datasetName"], "string") || datasetId;
    const existingDataset = await datasetProvider.getDatasetMetadata(datasetId);
    if (!existingDataset) {
      await datasetProvider.putDatasetMetadata({
        id: datasetId,
        name: datasetName,
        description: "",
        projectId: context.project.metadata.id
      });
    }
    return {
      ["datasetId_out"]: {
        type: "string",
        value: datasetId || datasetName
      }
    };
  }
};
var createDatasetNode = nodeDefinition(CreateDatasetNodeImpl, "Create Dataset");

// src/model/nodes/LoadDatasetNode.ts
var LoadDatasetNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: newId(),
      type: "loadDataset",
      title: "Load Dataset",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        datasetId: ""
      }
    };
  }
  getInputDefinitions() {
    const inputs = [];
    if (this.data.useDatasetIdInput) {
      inputs.push({
        id: "datasetId",
        title: "Dataset ID",
        dataType: "string"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "dataset",
        title: "Dataset",
        dataType: "object[]"
      },
      {
        id: "datasetId_out",
        title: "Dataset ID",
        dataType: "string"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Loads a dataset with the provided ID. If the dataset does not exist, it throws an error.
      `,
      infoBoxTitle: "Load Dataset Node",
      contextMenuTitle: "Load Dataset",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [
      {
        type: "datasetSelector",
        label: "Dataset",
        dataKey: "datasetId",
        useInputToggleDataKey: "useDatasetIdInput"
      }
    ];
  }
  async process(inputs, context) {
    const { datasetProvider } = context;
    if (datasetProvider == null) {
      throw new Error("datasetProvider is required");
    }
    const datasetId = coerceTypeOptional(inputs["datasetId"], "string") || this.data.datasetId;
    const dataset = await datasetProvider.getDatasetData(datasetId);
    if (!dataset) {
      throw new Error(`Dataset with ID ${datasetId} does not exist`);
    }
    return {
      ["dataset"]: {
        type: "object[]",
        value: dataset.rows
      },
      ["datasetId_out"]: {
        type: "string",
        value: datasetId
      }
    };
  }
};
var loadDatasetNode = nodeDefinition(LoadDatasetNodeImpl, "Load Dataset");

// src/model/nodes/GetAllDatasetsNode.ts
var GetAllDatasetsNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: newId(),
      type: "getAllDatasets",
      title: "Get All Datasets",
      visualData: { x: 0, y: 0, width: 250 },
      data: {}
    };
  }
  getInputDefinitions() {
    return [];
  }
  getOutputDefinitions() {
    return [
      {
        id: "datasets",
        title: "Datasets",
        dataType: "object[]"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Retrieves all datasets. If no datasets exist, it returns an empty array.
      `,
      infoBoxTitle: "Get All Datasets Node",
      contextMenuTitle: "Get All Datasets",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [];
  }
  async process(inputs, context) {
    const { datasetProvider } = context;
    if (datasetProvider == null) {
      throw new Error("datasetProvider is required");
    }
    const datasets = await datasetProvider.getDatasetsForProject(context.project.metadata.id);
    return {
      ["datasets"]: {
        type: "object[]",
        value: datasets
      }
    };
  }
};
var getAllDatasetsNode = nodeDefinition(GetAllDatasetsNodeImpl, "Get All Datasets");

// src/model/nodes/SplitNode.ts
var SplitNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: newId(),
      type: "split",
      title: "Split Text",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        delimiter: ",",
        regex: false
      }
    };
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "string",
        title: "String",
        dataType: "string"
      }
    ];
    if (this.data.useDelimiterInput) {
      inputs.push({
        id: "delimiter",
        title: "Delimiter",
        dataType: "string"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "splitString",
        title: "Split",
        dataType: "string[]"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Splits a string by the provided delimiter.
      `,
      infoBoxTitle: "Split Text Node",
      contextMenuTitle: "Split Text",
      group: ["Text"]
    };
  }
  getEditors() {
    return [
      {
        type: "toggle",
        label: "Regex",
        dataKey: "regex"
      },
      {
        type: "code",
        label: "Delimiter",
        language: "plaintext",
        dataKey: "delimiter",
        useInputToggleDataKey: "useDelimiterInput"
      }
    ];
  }
  getBody() {
    if (this.data.useDelimiterInput) {
      return "(Delimiter from input)";
    }
    const normalized = handleEscapeCharacters(this.data.delimiter);
    if (normalized === "\n") {
      return "(New line)";
    }
    if (normalized === "\r\n") {
      return "(New line (windows))";
    }
    if (normalized === "	") {
      return "(Tab)";
    }
    if (normalized === " ") {
      return "(Space)";
    }
    return normalized;
  }
  async process(inputs, context) {
    const delimiter = getInputOrData(this.data, inputs, "delimiter");
    const normalizedDelimiter = this.data.regex ? new RegExp(delimiter) : handleEscapeCharacters(delimiter);
    const stringToSplit = coerceType(inputs["string"], "string");
    const splitString = stringToSplit.split(normalizedDelimiter);
    return {
      ["splitString"]: {
        type: "string[]",
        value: splitString
      }
    };
  }
};
var splitNode = nodeDefinition(SplitNodeImpl, "Split String");

// src/model/nodes/DatasetNearestNeigborsNode.ts
var DatasetNearestNeighborsNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: newId(),
      type: "datasetNearestNeighbors",
      title: "KNN Dataset",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        datasetId: "",
        k: 5
      }
    };
  }
  getInputDefinitions() {
    const inputs = [
      {
        id: "embedding",
        title: "Embedding",
        dataType: "object"
      }
    ];
    if (this.data.useDatasetIdInput) {
      inputs.push({
        id: "datasetId",
        title: "Dataset ID",
        dataType: "string"
      });
    }
    if (this.data.useKInput) {
      inputs.push({
        id: "k",
        title: "K",
        dataType: "number"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "nearestNeighbors",
        title: "Nearest Neighbors",
        dataType: "object[]"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Finds the k nearest neighbors in the dataset with the provided ID, given an embedding.
      `,
      infoBoxTitle: "KNN Dataset Node",
      contextMenuTitle: "KNN Dataset",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [
      {
        type: "datasetSelector",
        label: "Dataset",
        dataKey: "datasetId",
        useInputToggleDataKey: "useDatasetIdInput"
      },
      {
        type: "number",
        label: "K",
        dataKey: "k",
        useInputToggleDataKey: "useKInput"
      }
    ];
  }
  async process(inputs, context) {
    const { datasetProvider } = context;
    if (datasetProvider == null) {
      throw new Error("datasetProvider is required");
    }
    const datasetId = getInputOrData(this.data, inputs, "datasetId");
    const k = getInputOrData(this.data, inputs, "k", "number");
    const embedding = coerceType(inputs["embedding"], "vector");
    const nearestNeighbors = await datasetProvider.knnDatasetRows(datasetId, k, embedding);
    return {
      ["nearestNeighbors"]: {
        type: "object[]",
        value: nearestNeighbors.map((neighbor) => ({
          id: neighbor.id,
          distance: neighbor.distance,
          data: neighbor.data
        }))
      }
    };
  }
};
var datasetNearestNeighborsNode = nodeDefinition(DatasetNearestNeighborsNodeImpl, "Dataset Nearest Neighbors");

// src/model/nodes/GetDatasetRowNode.ts
var GetDatasetRowNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: newId(),
      type: "getDatasetRow",
      title: "Get Dataset Row",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        datasetId: "",
        rowId: ""
      }
    };
  }
  getInputDefinitions() {
    const inputs = [];
    if (this.data.useRowIdInput) {
      inputs.push({
        id: "rowId",
        title: "Row ID",
        dataType: "string"
      });
    }
    if (this.data.useDatasetIdInput) {
      inputs.push({
        id: "datasetId",
        title: "Dataset ID",
        dataType: "string"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "row",
        title: "Row",
        dataType: "object"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Gets a row from a dataset with the provided ID. If the dataset or row does not exist, it throws an error.
      `,
      infoBoxTitle: "Get Dataset Row Node",
      contextMenuTitle: "Get Dataset Row",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [
      {
        type: "datasetSelector",
        label: "Dataset",
        dataKey: "datasetId",
        useInputToggleDataKey: "useDatasetIdInput"
      },
      {
        type: "string",
        label: "Row ID",
        dataKey: "rowId",
        useInputToggleDataKey: "useRowIdInput"
      }
    ];
  }
  async process(inputs, context) {
    const { datasetProvider } = context;
    if (datasetProvider == null) {
      throw new Error("datasetProvider is required");
    }
    const datasetId = getInputOrData(this.data, inputs, "datasetId", "string");
    const rowId = getInputOrData(this.data, inputs, "rowId", "string");
    const dataset = await datasetProvider.getDatasetData(datasetId);
    if (!dataset) {
      throw new Error(`Dataset with ID ${datasetId} does not exist`);
    }
    const row = dataset.rows.find((r) => r.id === rowId);
    if (!row) {
      return {
        ["row"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    return {
      ["row"]: {
        type: "object",
        value: row
      }
    };
  }
};
var getDatasetRowNode = nodeDefinition(GetDatasetRowNodeImpl, "Get Dataset Row");

// src/model/nodes/SliceNode.ts
var import_non_secure58 = require("nanoid/non-secure");
var import_ts_dedent54 = require("ts-dedent");
var SliceNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "slice",
      title: "Slice",
      id: (0, import_non_secure58.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        start: 0,
        count: void 0
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [
      {
        dataType: "any[]",
        id: "input",
        title: "Input"
      }
    ];
    if (this.data.useStartInput) {
      inputs.push({
        dataType: "number",
        id: "start",
        title: "Start"
      });
    }
    if (this.data.useCountInput) {
      inputs.push({
        dataType: "number",
        id: "count",
        title: "Count"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "any[]",
        id: "output",
        title: "Output"
      }
    ];
  }
  getEditors() {
    return [
      { type: "number", label: "Start", dataKey: "start", useInputToggleDataKey: "useStartInput", allowEmpty: true },
      { type: "number", label: "Count", dataKey: "count", useInputToggleDataKey: "useCountInput", allowEmpty: true }
    ];
  }
  getBody() {
    return import_ts_dedent54.dedent`
      Start: ${this.data.useStartInput ? "(Using Input)" : this.data.start == null ? "0" : this.data.start}
      Count: ${this.data.useCountInput ? "(Using Input)" : this.data.count == null ? "All" : this.data.count}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent54.dedent`
        Slices an array from the start index for the count number of elements.

        Useful for extracting a portion of an array.
      `,
      infoBoxTitle: "Slice Node",
      contextMenuTitle: "Slice",
      group: ["Lists"]
    };
  }
  async process(inputs) {
    const inputArray = coerceType(inputs["input"], "any[]");
    const start = getInputOrData(this.data, inputs, "start", "number") ?? 0;
    const count = getInputOrData(this.data, inputs, "count", "number") ?? inputArray.length;
    const outputArray = inputArray.slice(start, start + count);
    return {
      ["output"]: {
        type: "any[]",
        value: outputArray
      }
    };
  }
};
var sliceNode = nodeDefinition(SliceNodeImpl, "Slice");

// src/model/nodes/ExtractMarkdownCodeBlocksNode.ts
var import_non_secure59 = require("nanoid/non-secure");
var import_ts_dedent55 = require("ts-dedent");
var ExtractMarkdownCodeBlocksNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "extractMarkdownCodeBlocks",
      title: "Extract Markdown Code Blocks",
      id: (0, import_non_secure59.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {}
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "input",
        title: "Input",
        dataType: "string",
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "firstBlock",
        title: "First Block",
        dataType: "string"
      },
      {
        id: "allBlocks",
        title: "All Blocks",
        dataType: "string[]"
      },
      {
        id: "languages",
        title: "Languages",
        dataType: "string[]"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent55.dedent`
        Extracts the code blocks in the input Markdown text.

        Outputs the first matched block, all matched blocks, and the languages specified for the blocks.
      `,
      infoBoxTitle: "Extract Markdown Code Blocks Node",
      contextMenuTitle: "Extract Markdown Code Blocks",
      group: ["Text"]
    };
  }
  async process(inputs) {
    const inputString = expectType(inputs["input"], "string");
    const regex = /```(\w*)\n([\s\S]*?)```/g;
    let match15;
    let firstBlock;
    const allBlocks = [];
    const languages = [];
    while ((match15 = regex.exec(inputString)) !== null) {
      const language = match15[1];
      const block = match15[2];
      if (!firstBlock) {
        firstBlock = block;
      }
      allBlocks.push(block);
      languages.push(language);
    }
    return {
      ["firstBlock"]: firstBlock == null ? {
        type: "control-flow-excluded",
        value: void 0
      } : {
        type: "string",
        value: firstBlock
      },
      ["allBlocks"]: {
        type: "string[]",
        value: allBlocks
      },
      ["languages"]: {
        type: "string[]",
        value: languages
      }
    };
  }
};
var extractMarkdownCodeBlocksNode = nodeDefinition(
  ExtractMarkdownCodeBlocksNodeImpl,
  "Extract Markdown Code Blocks"
);

// src/model/nodes/AssembleMessageNode.ts
var import_non_secure60 = require("nanoid/non-secure");
var import_lodash_es12 = require("lodash");
var import_ts_pattern9 = require("ts-pattern");
var messageTypeToTitle = {
  assistant: "Assistant",
  function: "Function Tool Call",
  system: "System",
  user: "User"
};
var AssembleMessageNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "assembleMessage",
      title: "Assemble Message",
      id: (0, import_non_secure60.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        type: "user",
        useTypeInput: false,
        toolCallId: "",
        useToolCallIdInput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions(connections) {
    const inputs = [];
    const messageCount = this.#getInputPortCount(connections);
    if (this.data.useTypeInput) {
      inputs.push({
        dataType: "string",
        id: "type",
        title: "Type",
        description: "The type of message to assemble."
      });
    }
    if (this.data.useToolCallIdInput) {
      inputs.push({
        dataType: "string",
        id: "toolCallId",
        title: "Tool Call ID",
        description: "The ID of the tool call to associate with the message."
      });
    }
    for (let i = 1; i <= messageCount; i++) {
      inputs.push({
        dataType: ["string", "image", "string[]", "image[]", "object", "object[]", "document", "document[]"],
        id: `part${i}`,
        title: `Part ${i}`,
        description: "A part of the message to assemble."
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "chat-message",
        id: "message",
        title: "Message",
        description: "The assembled message."
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Type",
        dataKey: "type",
        options: [
          { value: "system", label: "System" },
          { value: "user", label: "User" },
          { value: "assistant", label: "Assistant" },
          { value: "function", label: "Function" }
        ],
        defaultValue: "user",
        useInputToggleDataKey: "useTypeInput"
      },
      {
        type: "string",
        label: "Tool Call ID",
        dataKey: "toolCallId",
        useInputToggleDataKey: "useToolCallIdInput",
        hideIf: (data) => data.type !== "function"
      }
    ];
  }
  #getInputPortCount(connections) {
    const inputNodeId = this.chartNode.id;
    const messageConnections = connections.filter(
      (connection) => connection.inputNodeId === inputNodeId && connection.inputId.startsWith("part")
    );
    let maxMessageNumber = 0;
    for (const connection of messageConnections) {
      const messageNumber = parseInt(connection.inputId.replace("part", ""));
      if (messageNumber > maxMessageNumber) {
        maxMessageNumber = messageNumber;
      }
    }
    return maxMessageNumber + 1;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Assembles a single chat message from multiple parts. This is similar to a Prompt node, but works with multimodal
        models, as you can include text, images, and documents in the message.
      `,
      infoBoxTitle: "Assemble Message Node",
      contextMenuTitle: "Assemble Message",
      group: "AI"
    };
  }
  getBody(_context) {
    return import_ts_dedent.dedent`
      ${this.data.useTypeInput ? "(Type From Input)" : messageTypeToTitle[this.data.type]}
      ${this.data.useTypeInput || this.data.type === "function" ? `Tool Call ID: ${this.data.useToolCallIdInput ? "(From Input)" : this.data.toolCallId}` : ``}
    `;
  }
  async process(inputs) {
    const output = {};
    const type = getInputOrData(this.data, inputs, "type");
    const outMessage = (0, import_ts_pattern9.match)(type).with(
      "system",
      (type2) => ({
        type: type2,
        message: []
      })
    ).with(
      "user",
      (type2) => ({
        type: type2,
        message: []
      })
    ).with(
      "assistant",
      (type2) => ({
        type: type2,
        message: [],
        function_call: void 0,
        // Not supported yet in Assemble Message node
        function_calls: void 0
        // Not supported yet in Assemble Message node
      })
    ).with(
      "function",
      (type2) => ({
        type: type2,
        message: [],
        name: getInputOrData(this.data, inputs, "toolCallId")
      })
    ).otherwise(() => {
      throw new Error(`Invalid type: ${type}`);
    });
    const inputParts = (0, import_lodash_es12.orderBy)(
      Object.entries(inputs).filter(([key]) => key.startsWith("part")),
      ([key]) => key,
      "asc"
    );
    for (const [, inputPart] of inputParts) {
      if (!inputPart || inputPart.type === "control-flow-excluded" || !inputPart.value) {
        continue;
      }
      const inPart = arrayizeDataValue(unwrapDataValue(inputPart));
      for (const message of inPart) {
        if (message.type === "string") {
          outMessage.message.push(message.value);
        } else if (message.type === "image") {
          outMessage.message.push({
            type: "image",
            data: message.value.data,
            mediaType: message.value.mediaType
          });
        } else if (message.type === "object") {
          if (message.value && "type" in message.value && message.value.type === "url_reference" && typeof message.value.url === "string") {
            outMessage.message.push({
              type: "url",
              url: message.value.url
            });
          }
        } else if (message.type === "document") {
          outMessage.message.push({
            type: "document",
            data: message.value.data,
            mediaType: message.value.mediaType,
            context: message.value.context,
            title: message.value.title,
            enableCitations: message.value.enableCitations
          });
        } else {
          const coerced = coerceTypeOptional(message, "string");
          if (coerced) {
            outMessage.message.push(coerced);
          }
        }
      }
    }
    output["message"] = {
      type: "chat-message",
      value: outMessage
    };
    return output;
  }
};
var assembleMessageNode = nodeDefinition(AssembleMessageNodeImpl, "Assemble Prompt");

// src/model/nodes/URLReferenceNode.ts
var import_non_secure61 = require("nanoid/non-secure");
var UrlReferenceNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "urlReference",
      title: "URL Reference",
      id: (0, import_non_secure61.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 225
      },
      data: {
        url: ""
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [];
    if (this.data.useUrlInput) {
      inputs.push({
        dataType: "string",
        id: "url",
        title: "URL",
        description: "The value to convert into a URL reference.",
        coerced: true
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "object",
        id: "urlReference",
        title: "URL Reference",
        description: "A reference to a URL."
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "URL",
        dataKey: "url",
        useInputToggleDataKey: "useUrlInput"
      }
    ];
  }
  static getUIData() {
    return {
      contextMenuTitle: "URL Reference",
      group: "Data",
      infoBoxTitle: "URL Reference Node",
      infoBoxBody: "Defines a reference to a URL, or converts a string into a URL reference. Used with the Assemble Message node to define URLs for attachments/images."
    };
  }
  getBody() {
    return this.data.useUrlInput ? "(URL Using Input)" : this.data.url;
  }
  async process(inputs) {
    const url = getInputOrData(this.data, inputs, "url", "string");
    return {
      ["urlReference"]: {
        type: "object",
        value: { type: "url_reference", url }
      }
    };
  }
};
var urlReferenceNode = nodeDefinition(UrlReferenceNodeImpl, "URL Reference");

// src/model/nodes/DestructureNode.ts
var import_non_secure62 = require("nanoid/non-secure");
var import_jsonpath_plus3 = require("jsonpath-plus");
var import_ts_dedent56 = require("ts-dedent");
var DestructureNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "destructure",
      title: "Destructure",
      id: (0, import_non_secure62.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        paths: ["$.value"]
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "object",
        title: "Object",
        dataType: "object",
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return this.chartNode.data.paths.map((path, index) => ({
      id: `match_${index}`,
      title: path,
      dataType: "any"
    }));
  }
  getEditors() {
    return [
      {
        type: "stringList",
        label: "Paths",
        dataKey: "paths",
        helperMessage: "One or more JSONPath expressions. Each expression will correspond to an output port of the node."
      }
    ];
  }
  getBody() {
    return "";
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent56.dedent`
        Destructures the input value by extracting values at the specified paths. The paths use JSONPath notation to navigate through the value.
      `,
      infoBoxTitle: "Destructure Node",
      contextMenuTitle: "Destructure",
      group: ["Objects"]
    };
  }
  async process(inputs) {
    const inputObject = coerceTypeOptional(inputs["object"], "object");
    const output = {};
    this.data.paths.forEach((path, index) => {
      let match15;
      try {
        match15 = (0, import_jsonpath_plus3.JSONPath)({ json: inputObject ?? null, path: path.trim(), wrap: false });
      } catch (err) {
        match15 = void 0;
      }
      output[`match_${index}`] = {
        type: "any",
        value: match15
      };
    });
    return output;
  }
};
var destructureNode = nodeDefinition(DestructureNodeImpl, "Destructure");

// src/model/nodes/ReplaceDatasetNode.ts
var import_non_secure63 = require("nanoid/non-secure");
var import_ts_dedent57 = require("ts-dedent");
var ReplaceDatasetNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure63.nanoid)(),
      type: "replaceDataset",
      title: "Replace Dataset",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        datasetId: ""
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    inputDefinitions.push({
      id: "data",
      dataType: "object[]",
      title: "Data",
      description: "The new data of the dataset. If empty, the dataset will be cleared. May be an array of array of strings, or an array of DatasetRow objects with { id, data } properties. If a string[][], IDs will be generated."
    });
    if (this.data.useDatasetIdInput) {
      inputDefinitions.push({
        id: "datasetId",
        title: "Dataset ID",
        dataType: "string",
        description: "The ID of the dataset to replace."
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "dataset",
        title: "Dataset",
        dataType: "object[]",
        description: "The new data of the dataset. An array of DatasetRow objects with { id, data } properties."
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent57.dedent`
        Replaces the data in a dataset with the given data. If no data is given, the dataset will be cleared instead.
      `,
      infoBoxTitle: "Replace Dataset Node",
      contextMenuTitle: "Replace Dataset",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [
      {
        type: "datasetSelector",
        label: "Dataset",
        dataKey: "datasetId",
        useInputToggleDataKey: "useDatasetIdInput"
      }
    ];
  }
  async process(inputs, context) {
    const { datasetProvider } = context;
    if (datasetProvider == null) {
      throw new Error("datasetProvider is required");
    }
    const datasetId = getInputOrData(this.data, inputs, "datasetId", "string");
    const dataInput = inputs["data"];
    if (!dataInput) {
      await datasetProvider.putDatasetData(datasetId, { id: datasetId, rows: [] });
      return {
        ["dataset"]: {
          type: "object[]",
          value: []
        }
      };
    }
    let dataArrays = unwrapDataValue(dataInput).value;
    if (!Array.isArray(dataArrays)) {
      throw new Error("Data input must be either an array of rows, or an array of columns for a single row.");
    }
    const isDatasetRow = (row) => {
      return typeof row === "object" && row != null && "id" in row && "data" in row;
    };
    const firstElem = dataArrays[0];
    if (!Array.isArray(firstElem) && !isDatasetRow(firstElem)) {
      dataArrays = [dataArrays];
    }
    const rows = dataArrays.map((row) => {
      if (Array.isArray(row)) {
        return {
          id: newId(),
          data: row.map((value) => coerceType(inferType(value), "string"))
        };
      }
      if ("id" in row && "data" in row) {
        return row;
      }
      throw new Error("Data input must be an array of strings or DatasetRows");
    });
    await datasetProvider.putDatasetData(datasetId, {
      id: datasetId,
      rows
    });
    return {
      ["dataset"]: {
        type: "object[]",
        value: rows
      }
    };
  }
};
var replaceDatasetNode = nodeDefinition(ReplaceDatasetNodeImpl, "Replace Dataset");

// src/model/nodes/ListGraphsNode.ts
var ListGraphsNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: newId(),
      type: "listGraphs",
      title: "List Graphs",
      visualData: { x: 0, y: 0, width: 250 },
      data: {}
    };
  }
  getInputDefinitions() {
    return [];
  }
  getOutputDefinitions() {
    return [
      {
        id: "graphs",
        title: "Graphs",
        dataType: "graph-reference[]"
      },
      {
        id: "graph-names",
        title: "Graph Names",
        dataType: "string[]"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent.dedent`
        Lists all graphs in the project.
      `,
      infoBoxTitle: "List Graphs Node",
      contextMenuTitle: "List Graphs",
      group: ["Input/Output"]
    };
  }
  getEditors() {
    return [];
  }
  async process(_inputs, context) {
    const graphs = Object.values(context.project.graphs);
    return {
      ["graphs"]: {
        type: "graph-reference[]",
        value: graphs.map((graph) => ({
          graphId: graph.metadata.id ?? "",
          graphName: graph.metadata.name ?? ""
        }))
      },
      ["graph-names"]: {
        type: "string[]",
        value: graphs.map((graph) => graph.metadata.name ?? "")
      }
    };
  }
};
var listGraphsNode = nodeDefinition(ListGraphsNodeImpl, "List Graphs");

// src/model/nodes/GraphReferenceNode.ts
var import_non_secure64 = require("nanoid/non-secure");
var import_ts_dedent58 = require("ts-dedent");
var GraphReferenceNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "graphReference",
      title: "Graph Reference",
      id: (0, import_non_secure64.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 275
      },
      data: {
        graphId: "",
        useGraphIdOrNameInput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [];
    if (this.data.useGraphIdOrNameInput) {
      inputs.push({
        id: "graph-name-or-id",
        dataType: "string",
        title: "Graph Name Or ID",
        description: "The name or ID of the graph to get a reference to.",
        required: true
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "graph",
        dataType: "graph-reference",
        title: "Graph",
        description: "A reference to the graph."
      }
    ];
  }
  getEditors() {
    const definitions = [
      {
        type: "graphSelector",
        label: "Graph",
        dataKey: "graphId",
        useInputToggleDataKey: "useGraphIdOrNameInput"
      }
    ];
    return definitions;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent58.dedent`
        Gets a reference to another graph, that can be used to pass around graphs to call using a Call Graph node.
      `,
      infoBoxTitle: "Graph Reference Node",
      contextMenuTitle: "Graph Reference",
      group: ["Advanced"]
    };
  }
  getBody(context) {
    if (this.data.useGraphIdOrNameInput) {
      return "(Graph from input)";
    }
    const graph = context.project.graphs[this.data.graphId];
    if (!graph) {
      return "(Graph not found)";
    }
    return graph.metadata.name ?? "(Unnamed Graph)";
  }
  async process(inputs, context) {
    if (this.data.useGraphIdOrNameInput) {
      const graphIdOrName = coerceType(inputs["graph-name-or-id"], "string");
      let graph2 = context.project.graphs[graphIdOrName];
      if (!graph2) {
        graph2 = Object.values(context.project.graphs).find((graph3) => graph3.metadata.name === graphIdOrName);
      }
      if (!graph2) {
        return {
          ["graph"]: {
            type: "control-flow-excluded",
            value: void 0
          }
        };
      }
      return {
        ["graph"]: {
          type: "graph-reference",
          value: {
            graphId: graph2.metadata.id ?? "",
            graphName: graph2.metadata.name ?? ""
          }
        }
      };
    }
    const graph = context.project.graphs[this.data.graphId];
    if (!graph) {
      return {
        ["graph"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    return {
      ["graph"]: {
        type: "graph-reference",
        value: {
          graphId: graph.metadata.id ?? "",
          graphName: graph.metadata.name ?? ""
        }
      }
    };
  }
};
var graphReferenceNode = nodeDefinition(GraphReferenceNodeImpl, "Graph Reference");

// src/model/nodes/CallGraphNode.ts
var import_non_secure65 = require("nanoid/non-secure");
var import_ts_dedent59 = require("ts-dedent");

// src/api/looseDataValue.ts
var import_lodash_es13 = require("lodash");
function looseDataValuesToDataValues(values3) {
  return (0, import_lodash_es13.mapValues)(values3, (val) => looseDataValueToDataValue(val));
}
function looseDataValueToDataValue(value) {
  if (typeof value === "string") {
    return { type: "string", value };
  }
  if (typeof value === "number") {
    return { type: "number", value };
  }
  if (typeof value === "boolean") {
    return { type: "boolean", value };
  }
  return value;
}

// src/model/nodes/CallGraphNode.ts
var CallGraphNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "callGraph",
      title: "Call Graph",
      id: (0, import_non_secure65.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        useErrorOutput: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [];
    inputs.push({
      id: "graph",
      dataType: "graph-reference",
      title: "Graph",
      description: "The reference to the graph to call.",
      required: true
    });
    inputs.push({
      id: "inputs",
      dataType: "object",
      title: "Inputs",
      description: "The inputs to pass to the graph. Should be an object where the keys are the input names and the values are the input values."
    });
    return inputs;
  }
  getOutputDefinitions() {
    const outputs = [
      {
        id: "outputs",
        dataType: "object",
        title: "Outputs",
        description: "The outputs of the graph."
      }
    ];
    if (this.data.useErrorOutput) {
      outputs.push({
        id: "error",
        dataType: "string",
        title: "Error",
        description: "The error message if the graph call failed."
      });
    }
    return outputs;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent59.dedent`
        Calls another graph and passes inputs to it. Use in combination with the Graph Reference node to call dynamic graphs.
      `,
      infoBoxTitle: "Call Graph Node",
      contextMenuTitle: "Call Graph",
      group: ["Advanced"]
    };
  }
  async process(inputs, context) {
    const graphRef = coerceTypeOptional(inputs["graph"], "graph-reference");
    const graphInputs = coerceTypeOptional(inputs["inputs"], "object");
    if (!graphRef) {
      return {
        ["outputs"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    const graph = context.project.graphs[graphRef.graphId];
    if (!graph) {
      return {
        ["outputs"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    const subGraphProcessor = context.createSubProcessor(graphRef.graphId, { signal: context.signal });
    const outputs = {};
    try {
      const startTime = Date.now();
      const inputData = looseDataValuesToDataValues(graphInputs);
      const graphOutputs = await subGraphProcessor.processGraph(context, inputData, context.contextValues);
      const duration = Date.now() - startTime;
      outputs["outputs"] = {
        type: "object",
        value: graphOutputs
      };
      if (this.data.useErrorOutput) {
        outputs["error"] = {
          type: "control-flow-excluded",
          value: void 0
        };
      }
      if (outputs["duration"] == null) {
        outputs["duration"] = {
          type: "number",
          value: duration
        };
      }
      return outputs;
    } catch (err) {
      if (!this.data.useErrorOutput) {
        throw err;
      }
      outputs["outputs"] = {
        type: "control-flow-excluded",
        value: void 0
      };
      outputs["error"] = {
        type: "string",
        value: getError(err).message
      };
      return outputs;
    }
  }
};
var callGraphNode = nodeDefinition(CallGraphNodeImpl, "Call Graph");

// src/model/nodes/DelegateFunctionCallNode.ts
var import_nanoid = require("nanoid");
var import_ts_dedent60 = require("ts-dedent");
var DelegateFunctionCallNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "delegateFunctionCall",
      title: "Delegate Function Call",
      id: (0, import_nanoid.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 325
      },
      data: {
        handlers: [],
        unknownHandler: void 0
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [];
    inputs.push({
      id: "function-call",
      dataType: "object",
      title: "Function Call",
      coerced: true,
      required: true,
      description: "The function call to delegate to a subgraph."
    });
    return inputs;
  }
  getOutputDefinitions() {
    const outputs = [];
    outputs.push({
      id: "output",
      dataType: "string",
      title: "Output",
      description: "The output of the function call."
    });
    outputs.push({
      id: "message",
      dataType: "object",
      title: "Message Output",
      description: "Maps the output for use directly with an Assemble Prompt node and GPT."
    });
    return outputs;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent60.dedent`
        Handles a function call by delegating it to a different subgraph depending on the function call.
      `,
      infoBoxTitle: "Delegate Function Call Node",
      contextMenuTitle: "Delegate Function Call",
      group: ["Advanced"]
    };
  }
  getEditors() {
    return [
      {
        type: "custom",
        customEditorId: "ToolCallHandlers",
        label: "Handlers",
        dataKey: "handlers"
      },
      {
        type: "graphSelector",
        dataKey: "unknownHandler",
        label: "Unknown Handler",
        helperMessage: "The subgraph to delegate to if the function call does not match any handlers."
      }
    ];
  }
  getBody(context) {
    if (this.data.handlers.length === 0) {
      return "No handlers defined";
    }
    const lines = ["Handlers:"];
    this.data.handlers.forEach(({ key, value }) => {
      var _a;
      const subgraphName = ((_a = context.project.graphs[value]) == null ? void 0 : _a.metadata.name) ?? "Unknown Subgraph";
      lines.push(`    ${key || "(MISSING!)"} -> ${subgraphName}`);
    });
    return lines.join("\n");
  }
  async process(inputs, context) {
    const functionCall = coerceType(
      inputs["function-call"],
      "object"
    );
    let handler = this.data.handlers.find((handler2) => handler2.key === functionCall.name);
    if (!handler) {
      if (this.data.unknownHandler) {
        handler = { key: void 0, value: this.data.unknownHandler };
      } else {
        throw new Error(`No handler found for function call: ${functionCall.name}`);
      }
    }
    const subgraphInputs = {
      _function_name: {
        type: "string",
        value: functionCall.name
      },
      _arguments: {
        type: "object",
        value: functionCall.arguments
      }
    };
    for (const [argName, argument] of Object.entries(functionCall.arguments)) {
      subgraphInputs[argName] = {
        type: "any",
        value: argument
      };
    }
    const handlerGraphId = handler.value;
    const subprocessor = context.createSubProcessor(handlerGraphId, { signal: context.signal });
    const outputs = await subprocessor.processGraph(context, subgraphInputs, context.contextValues);
    const outputString = coerceTypeOptional(outputs.output, "string") ?? "";
    return {
      ["output"]: {
        type: "string",
        value: outputString
      },
      ["message"]: {
        type: "chat-message",
        value: {
          type: "function",
          message: outputString,
          name: functionCall.id ?? ""
        }
      }
    };
  }
};
var delegateFunctionCallNode = nodeDefinition(DelegateFunctionCallNodeImpl, "Delegate Function Call");

// src/model/nodes/PlayAudioNode.ts
var import_non_secure66 = require("nanoid/non-secure");
var PlayAudioNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure66.nanoid)(),
      type: "playAudio",
      title: "Play Audio",
      visualData: { x: 0, y: 0, width: 200 },
      data: {}
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    inputDefinitions.push({
      id: "data",
      title: "Data",
      dataType: "audio",
      coerced: false
    });
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "data",
        title: "Audio Data",
        dataType: "audio"
      }
    ];
  }
  getEditors() {
    return [];
  }
  static getUIData() {
    return {
      contextMenuTitle: "Play Audio",
      group: "Input/Output",
      infoBoxTitle: "Play Audio Node",
      infoBoxBody: "Plays audio data to the speakers."
    };
  }
  async process(inputData, context) {
    if (!context.audioProvider) {
      throw new Error("Playing audio is not supported in this context");
    }
    const data = expectType(inputData["data"], "audio");
    await context.audioProvider.playAudio({ type: "audio", value: data }, context.signal);
    return {
      ["data"]: {
        type: "audio",
        value: data
      }
    };
  }
};
var playAudioNode = nodeDefinition(PlayAudioNodeImpl, "Play Audio");

// src/model/nodes/DocumentNode.ts
var import_non_secure67 = require("nanoid/non-secure");
var DocumentNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure67.nanoid)(),
      type: "document",
      title: "Document",
      visualData: { x: 0, y: 0, width: 300 },
      data: {
        useDataInput: false,
        useMediaTypeInput: false,
        title: "",
        useTitleInput: false,
        context: "",
        useContextInput: false,
        enableCitations: false,
        useEnableCitationsInput: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.useDataInput) {
      inputDefinitions.push({
        id: "data",
        title: "Data",
        dataType: ["string", "binary"],
        coerced: false,
        description: "The document data. Either string or binary data loaded from a file."
      });
    }
    if (this.chartNode.data.useMediaTypeInput) {
      inputDefinitions.push({
        id: "mediaType",
        title: "Media Type",
        dataType: "string",
        coerced: false,
        description: "The media type of the document, such as text/plain or application/pdf."
      });
    }
    if (this.data.useTitleInput) {
      inputDefinitions.push({
        id: "title",
        title: "Title",
        dataType: "string",
        coerced: true,
        description: "The title of the document."
      });
    }
    if (this.data.useContextInput) {
      inputDefinitions.push({
        id: "context",
        title: "Context",
        dataType: "string",
        coerced: true,
        description: "The context of the document."
      });
    }
    if (this.data.useEnableCitationsInput) {
      inputDefinitions.push({
        id: "enableCitations",
        title: "Enable Citations",
        dataType: "boolean",
        coerced: true,
        description: "Whether to enable citations for the document."
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "data",
        title: "Document Data",
        dataType: "document"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "fileBrowser",
        label: "Document File",
        dataKey: "data",
        mediaTypeDataKey: "mediaType",
        useInputToggleDataKey: "useDataInput",
        accept: "*/*"
      },
      {
        type: "string",
        label: "Media Type",
        dataKey: "mediaType",
        useInputToggleDataKey: "useMediaTypeInput"
      },
      {
        type: "string",
        label: "Title",
        dataKey: "title",
        useInputToggleDataKey: "useTitleInput"
      },
      {
        type: "string",
        label: "Context",
        dataKey: "context",
        useInputToggleDataKey: "useContextInput"
      },
      {
        type: "toggle",
        label: "Enable Citations",
        dataKey: "enableCitations",
        useInputToggleDataKey: "useEnableCitationsInput"
      }
    ];
  }
  static getUIData() {
    return {
      contextMenuTitle: "Document",
      group: "Data",
      infoBoxTitle: "Document Node",
      infoBoxBody: "Defines a document for use with other nodes such as Assemble Message. Can accept text and PDF files."
    };
  }
  getBody(_context) {
    const parts = [
      this.data.useDataInput ? "(Data from input)" : "(Data stored in node)",
      this.data.useMediaTypeInput ? "(Media type from input)" : this.data.mediaType ? `(${this.data.mediaType.trim()})` : void 0,
      this.data.useTitleInput ? "(Title from input)" : this.data.title ? `Title: ${this.data.title}` : void 0,
      this.data.useContextInput ? "(Context from input)" : this.data.context ? `Context: ${this.data.context}` : void 0
    ].filter((x) => x != null);
    return import_ts_dedent.dedent`
      ${parts.join("\n")}
    `;
  }
  async process(inputData, context) {
    var _a, _b;
    let data;
    const mediaType = getInputOrData(this.data, inputData, "mediaType", "string") || "text/plain";
    const title = getInputOrData(this.data, inputData, "title");
    const contextInput = getInputOrData(this.data, inputData, "context");
    const enableCitations = getInputOrData(this.data, inputData, "enableCitations", "boolean");
    if (this.chartNode.data.useDataInput) {
      data = expectType(inputData["data"], "binary");
    } else {
      const dataRef = (_a = this.data.data) == null ? void 0 : _a.refId;
      if (!dataRef) {
        throw new Error("No data ref");
      }
      const encodedData = (_b = context.project.data) == null ? void 0 : _b[dataRef];
      if (!encodedData) {
        throw new Error(`No data at ref ${dataRef}`);
      }
      data = base64ToUint8Array(encodedData);
    }
    return {
      ["data"]: {
        type: "document",
        value: {
          data,
          mediaType,
          title,
          context: contextInput,
          enableCitations
        }
      }
    };
  }
};
var documentNode = nodeDefinition(DocumentNodeImpl, "Document");

// src/model/nodes/ChatLoopNode.ts
var import_non_secure68 = require("nanoid/non-secure");
var import_ts_dedent61 = require("ts-dedent");
var ChatLoopNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "chatLoop",
      title: "Chat Loop",
      id: (0, import_non_secure68.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        ...ChatNodeBase.defaultData(),
        userPrompt: "Your response:",
        renderingFormat: "markdown"
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return ChatNodeBase.getInputDefinitions(this.data);
  }
  getOutputDefinitions() {
    return [
      {
        dataType: "string[]",
        id: "conversation",
        title: "Full Conversation"
      },
      {
        dataType: "string",
        id: "lastMessage",
        title: "Last Message"
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent61.dedent`
        Creates an interactive chat loop with an AI model. The node will:
        1. Send the initial prompt to the AI
        2. Show the AI's response and prompt for user input
        3. Send the user's input back to the AI
        4. Repeat steps 2-3 until the user ends the conversation

        The conversation history is maintained and sent with each new message.
      `,
      contextMenuTitle: "Chat Loop",
      infoBoxTitle: "Chat Loop Node",
      group: ["Convenience"]
    };
  }
  getEditors() {
    return [
      ...ChatNodeBase.getEditors(),
      {
        type: "code",
        label: "User Prompt",
        dataKey: "userPrompt",
        language: "plain-text"
      },
      {
        type: "group",
        label: "Rendering",
        editors: [
          {
            type: "dropdown",
            dataKey: "renderingFormat",
            label: "Format",
            options: [
              { label: "Text", value: "text" },
              { label: "Markdown", value: "markdown" }
            ],
            defaultValue: "markdown"
          }
        ]
      }
    ];
  }
  getBody() {
    return ChatNodeBase.getBody(this.data);
  }
  async process(inputs, context) {
    var _a;
    const conversation = [];
    let continueChat = true;
    conversation.push(...coerceType(inputs["prompt"], "chat-message[]"));
    const initialResponse = await ChatNodeBase.process(this.data, this.chartNode, inputs, context);
    const firstMessage = coerceType(initialResponse["response"], "string");
    conversation.push({
      type: "assistant",
      message: firstMessage,
      function_calls: void 0,
      function_call: void 0
    });
    let messageToUser = firstMessage;
    while (continueChat) {
      const userResponse = await context.requestUserInput([messageToUser], this.data.renderingFormat ?? "text");
      if (!userResponse || userResponse.value.length === 0 || ((_a = userResponse.value[0]) == null ? void 0 : _a.length) === 0) {
        continueChat = false;
        break;
      }
      conversation.push({
        type: "user",
        message: userResponse.value[0]
      });
      const chatInputs = {
        ...inputs,
        prompt: {
          type: "chat-message[]",
          value: conversation
        }
      };
      const aiResponse = await ChatNodeBase.process(this.data, this.chartNode, chatInputs, context);
      const aiMessage = coerceType(aiResponse["response"], "string");
      conversation.push({
        type: "assistant",
        message: aiMessage,
        function_calls: void 0,
        function_call: void 0
      });
      messageToUser = aiMessage;
    }
    return {
      ["conversation"]: {
        type: "chat-message[]",
        value: conversation
      },
      ["lastMessage"]: {
        type: "chat-message",
        value: conversation.at(-1)
      }
    };
  }
};
var chatLoopNode = nodeDefinition(ChatLoopNodeImpl, "Chat Loop");

// src/model/nodes/ReadAllFilesNode.ts
var import_non_secure69 = require("nanoid/non-secure");
var import_ts_dedent62 = require("ts-dedent");
var ReadAllFilesNodeImpl = class extends NodeImpl {
  static create() {
    return {
      id: (0, import_non_secure69.nanoid)(),
      type: "readAllFiles",
      title: "Read All Files",
      visualData: { x: 0, y: 0, width: 250 },
      data: {
        path: "",
        usePathInput: false,
        recursive: false,
        useRecursiveInput: false,
        filterGlobs: [],
        useFilterGlobsInput: false,
        ignores: [],
        useIgnoresInput: false,
        asBinary: false,
        errorOnMissingFile: false
      }
    };
  }
  getInputDefinitions() {
    const inputDefinitions = [];
    if (this.chartNode.data.usePathInput) {
      inputDefinitions.push({
        id: "path",
        title: "Path",
        dataType: "string",
        required: true,
        coerced: false
      });
    }
    if (this.chartNode.data.useRecursiveInput) {
      inputDefinitions.push({
        id: "recursive",
        title: "Recursive",
        dataType: "boolean",
        required: true,
        coerced: false
      });
    }
    if (this.chartNode.data.useFilterGlobsInput) {
      inputDefinitions.push({
        id: "filterGlobs",
        title: "Filter Globs",
        dataType: "string[]",
        required: true,
        coerced: false
      });
    }
    if (this.chartNode.data.useIgnoresInput) {
      inputDefinitions.push({
        id: "ignores",
        title: "Ignores",
        dataType: "string[]",
        required: true,
        coerced: false
      });
    }
    return inputDefinitions;
  }
  getOutputDefinitions() {
    return [
      {
        id: "files",
        title: "Files",
        dataType: "object[]"
      },
      {
        id: "rootPath",
        title: "Root Path",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "directoryBrowser",
        label: "Path",
        dataKey: "path",
        useInputToggleDataKey: "usePathInput"
      },
      {
        type: "toggle",
        label: "Recursive",
        dataKey: "recursive",
        useInputToggleDataKey: "useRecursiveInput"
      },
      {
        type: "stringList",
        label: "Filter Globs",
        dataKey: "filterGlobs",
        useInputToggleDataKey: "useFilterGlobsInput"
      },
      {
        type: "stringList",
        label: "Ignores",
        dataKey: "ignores",
        useInputToggleDataKey: "useIgnoresInput"
      },
      {
        type: "toggle",
        label: "Read as Binary",
        dataKey: "asBinary"
      },
      {
        type: "toggle",
        label: "Error on Missing File",
        dataKey: "errorOnMissingFile"
      }
    ];
  }
  getBody() {
    return import_ts_dedent62.dedent`
      ${this.data.asBinary ? "Read as Binary" : "Read as Text"}
      Path: ${this.data.usePathInput ? "(Input)" : this.data.path}
      Recursive: ${this.data.useRecursiveInput ? "(Input)" : this.data.recursive}
      Filters: ${this.data.useFilterGlobsInput ? "(Input)" : this.data.filterGlobs.length > 0 ? this.data.filterGlobs.join(", ") : "None"}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent62.dedent`
        Reads all files in the specified directory and outputs an array of objects containing each file's path and contents.
        Each object has a 'path' (string) and 'content' (string or binary) property.
      `,
      infoBoxTitle: "Read All Files Node",
      contextMenuTitle: "Read All Files",
      group: ["Input/Output"]
    };
  }
  async process(inputs, context) {
    const { nativeApi } = context;
    if (nativeApi == null) {
      throw new Error("This node requires a native API to run.");
    }
    const path = getInputOrData(this.chartNode.data, inputs, "path");
    const recursive = getInputOrData(this.data, inputs, "recursive", "boolean");
    const filterGlobs = getInputOrData(this.data, inputs, "filterGlobs", "string[]");
    const ignores = getInputOrData(this.data, inputs, "ignores", "string[]");
    try {
      const filePaths = await nativeApi.readdir(path, void 0, {
        recursive,
        includeDirectories: false,
        // We only want files since we're reading contents
        filterGlobs,
        relative: true,
        // Always use relative paths in output
        ignores
      });
      const filePromises = filePaths.map(async (filePath) => {
        try {
          if (this.data.asBinary) {
            const content = await nativeApi.readBinaryFile(`${path}/${filePath}`);
            const buffer = await content.arrayBuffer();
            return {
              path: filePath,
              content: await uint8ArrayToBase64(new Uint8Array(buffer)) ?? ""
            };
          } else {
            const content = await nativeApi.readTextFile(`${path}/${filePath}`, void 0);
            return {
              path: filePath,
              content
            };
          }
        } catch (err) {
          if (this.chartNode.data.errorOnMissingFile) {
            throw err;
          }
          return {
            path: filePath,
            content: this.data.asBinary ? new Uint8Array() : ""
          };
        }
      });
      const files = await Promise.all(filePromises);
      return {
        ["files"]: { type: "object[]", value: files },
        ["rootPath"]: { type: "string", value: path }
      };
    } catch (err) {
      if (this.chartNode.data.errorOnMissingFile) {
        throw err;
      }
      return {
        ["files"]: { type: "object[]", value: [] },
        ["rootPath"]: { type: "string", value: path }
      };
    }
  }
};
var readAllFilesNode = nodeDefinition(ReadAllFilesNodeImpl, "Read All Files");

// src/model/nodes/ToMarkdownTableNode.ts
var import_non_secure70 = require("nanoid/non-secure");
var import_ts_dedent63 = require("ts-dedent");
var ToMarkdownTableNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "toMarkdownTable",
      title: "To Markdown Table",
      id: (0, import_non_secure70.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        includeHeaders: true,
        alignPipes: false
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "data",
        title: "Data Array",
        dataType: "any",
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "markdown",
        title: "Markdown Table",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "toggle",
        label: "Include Headers",
        dataKey: "includeHeaders"
      },
      {
        type: "toggle",
        label: "Align Pipes",
        dataKey: "alignPipes"
      }
    ];
  }
  getBody() {
    const parts = [];
    if (this.data.includeHeaders)
      parts.push("With Header Row");
    if (this.data.alignPipes)
      parts.push("Pipes Aligned");
    return parts.length > 0 ? parts.join(", ") : void 0;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent63.dedent`
        Converts an array of objects into a markdown table format.
        Input should be an array of objects with consistent keys.
      `,
      infoBoxTitle: "To Markdown Table Node",
      contextMenuTitle: "To Markdown Table",
      group: ["Text"]
    };
  }
  async process(inputs) {
    const data = coerceType(inputs["data"], "object[]");
    const keys2 = data.length === 0 ? [] : Object.keys(data[0]);
    const { toMarkdown } = await import("mdast-util-to-markdown");
    const { gfmTableToMarkdown } = await import("mdast-util-gfm-table");
    const markdownTable = toMarkdown(
      {
        type: "table",
        children: [
          ...this.data.includeHeaders ? [
            {
              type: "tableRow",
              children: keys2.map((key) => ({
                type: "tableCell",
                children: [{ type: "text", value: key }]
              }))
            }
          ] : [],
          ...data.map((row) => ({
            type: "tableRow",
            children: keys2.map((key) => ({
              type: "tableCell",
              children: [{ type: "text", value: `${row[key]}` }]
            }))
          }))
        ]
      },
      {
        extensions: [gfmTableToMarkdown({ tablePipeAlign: this.data.alignPipes })]
      }
    );
    return {
      ["markdown"]: {
        type: "string",
        value: markdownTable
      }
    };
  }
};
var toMarkdownTableNode = nodeDefinition(ToMarkdownTableNodeImpl, "To Markdown Table");

// src/model/nodes/CronNode.ts
var import_nanoid2 = require("nanoid");
var import_ts_dedent64 = require("ts-dedent");
var cronParser = __toESM(require("cron-parser"), 1);
var CronNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "cron",
      title: "Cron",
      id: (0, import_nanoid2.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        targetGraph: void 0,
        scheduleType: "interval",
        schedule: "5 minutes",
        executeImmediately: true
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    const inputs = [];
    inputs.push({
      id: "trigger",
      title: "Trigger",
      dataType: "boolean",
      description: "Starts the scheduled job when true."
    });
    if (this.data.useTargetGraphInput) {
      inputs.push({
        id: "targetGraph",
        title: "Target Graph",
        dataType: "string",
        description: "The subgraph to execute on schedule"
      });
    }
    return inputs;
  }
  getOutputDefinitions() {
    return [
      {
        id: "output",
        title: "Last Output",
        dataType: "any",
        description: "The last output from the subgraph execution."
      },
      {
        id: "iteration",
        title: "Iteration",
        dataType: "number",
        description: "The current iteration number."
      },
      {
        id: "completed",
        title: "Completed",
        dataType: "boolean",
        description: "True when the job has completed."
      },
      {
        id: "nextRun",
        title: "Next Run",
        dataType: "string",
        description: "The scheduled time for the next execution."
      }
    ];
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent64.dedent`
        Executes a subgraph on a schedule. Supports:
        - Natural language (e.g., "every 5 minutes", "daily at 3pm")
        - Cron expressions (e.g., "0 * * * *")
        - Simple intervals (e.g., "5 minutes", "1 hour")
      `,
      infoBoxTitle: "Cron Node",
      contextMenuTitle: "Cron",
      group: ["Advanced"]
    };
  }
  getEditors() {
    return [
      {
        type: "toggle",
        dataKey: "executeImmediately",
        label: "Execute Immediately",
        helperMessage: "Starts the job immediately when the node is run, in addition to the schedule"
      },
      {
        type: "graphSelector",
        dataKey: "targetGraph",
        useInputToggleDataKey: "useTargetGraphInput",
        label: "Target Graph",
        helperMessage: "The subgraph to execute on schedule"
      },
      {
        type: "dropdown",
        dataKey: "scheduleType",
        label: "Schedule Type",
        options: [
          { label: "Cron Expression", value: "cron" },
          { label: "Simple Interval", value: "interval" }
        ],
        helperMessage: "How to specify the schedule"
      },
      {
        type: "string",
        dataKey: "schedule",
        label: "Schedule",
        helperMessage: import_ts_dedent64.dedent`
          Examples:
          Cron: "*/5 * * * *", "0 15 * * *"
          Interval: "5 minutes", "1 hour", "7 days"
        `
      }
    ];
  }
  parseSchedule() {
    const { scheduleType, schedule } = this.data;
    if (scheduleType === "cron") {
      return { type: "cron", expression: schedule };
    }
    const match15 = schedule.match(/^(\d+)\s*(second|seconds|minute|minutes|hour|hours|day|days|week|weeks)$/i);
    if (!match15) {
      throw new Error('Invalid interval format. Expected: "number unit" (e.g., "5 minutes")');
    }
    const value = parseInt(match15[1], 10);
    let unit = match15[2].toLowerCase();
    if (unit.endsWith("s")) {
      unit = unit;
    } else {
      unit = `${unit}s`;
    }
    return { type: "interval", value, unit };
  }
  getNextRunTime(schedule) {
    const now = /* @__PURE__ */ new Date();
    if (schedule.type === "interval") {
      const { value, unit } = schedule;
      const next = new Date(now);
      switch (unit) {
        case "seconds":
          next.setSeconds(now.getSeconds() + value);
          break;
        case "minutes":
          next.setMinutes(now.getMinutes() + value);
          break;
        case "hours":
          next.setHours(now.getHours() + value);
          break;
        case "days":
          next.setDate(now.getDate() + value);
          break;
        case "weeks":
          next.setDate(now.getDate() + value * 7);
          break;
      }
      return next;
    }
    if (schedule.type === "cron") {
      const cron = cronParser.parseExpression(schedule.expression, { currentDate: now });
      const next = cron.next().toDate();
      return next;
    }
    throw new Error("Invalid schedule type");
  }
  getBody(context) {
    var _a, _b;
    if (!this.data.targetGraph && !this.data.useTargetGraphInput) {
      return "No target graph selected";
    }
    const graphName = this.data.useTargetGraphInput ? "graph from input" : ((_b = (_a = context.project.graphs[this.data.targetGraph]) == null ? void 0 : _a.metadata) == null ? void 0 : _b.name) ?? "Unknown Graph";
    return `Executes ${graphName}
${this.data.schedule}`;
  }
  async process(inputs, context) {
    if (inputs["trigger"] !== void 0) {
      const trigger = coerceTypeOptional(inputs["trigger"], "boolean");
      if (!trigger) {
        return {
          ["completed"]: { type: "boolean", value: false },
          ["iteration"]: { type: "number", value: 0 }
        };
      }
    }
    if (!this.data.targetGraph) {
      throw new Error("No target graph selected");
    }
    let iteration = 0;
    const schedule = this.parseSchedule();
    let lastOutputs = {};
    let didExecuteFirstTime = !this.data.executeImmediately;
    while (!context.signal.aborted) {
      const nextRun = didExecuteFirstTime ? this.getNextRunTime(schedule) : /* @__PURE__ */ new Date();
      const delay = nextRun.getTime() - Date.now();
      didExecuteFirstTime = true;
      const outputs = {
        ["output"]: lastOutputs ? { type: "object", value: lastOutputs } : {
          type: "any",
          value: null
        },
        ["iteration"]: { type: "number", value: iteration },
        ["completed"]: { type: "boolean", value: false },
        ["nextRun"]: { type: "string", value: nextRun.toISOString() }
      };
      if (delay > 0) {
        await new Promise((resolve) => {
          context.signal.addEventListener("abort", resolve, { once: true });
          setTimeout(resolve, delay);
        });
      }
      if (context.signal.aborted) {
        throw new Error("Aborted");
      }
      iteration++;
      const subprocessor = context.createSubProcessor(this.data.targetGraph, { signal: context.signal });
      lastOutputs = await subprocessor.processGraph(
        context,
        lastOutputs,
        context.contextValues
      );
      const breakSignal = coerceTypeOptional(lastOutputs["break"], "boolean");
      if (breakSignal === true) {
        return {
          ...outputs,
          ["completed"]: { type: "boolean", value: true }
        };
      }
    }
    return {
      ["output"]: lastOutputs ? { type: "object", value: lastOutputs } : { type: "any", value: null },
      ["iteration"]: { type: "number", value: iteration },
      ["completed"]: { type: "boolean", value: true },
      ["nextRun"]: { type: "string", value: (/* @__PURE__ */ new Date()).toISOString() }
    };
  }
};
var cronNode = nodeDefinition(CronNodeImpl, "Cron");

// src/model/nodes/ToTreeNode.ts
var import_non_secure71 = require("nanoid/non-secure");
var import_ts_dedent65 = require("ts-dedent");
var import_lodash_es14 = require("lodash");
var ToTreeNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "toTree",
      title: "To Tree",
      id: (0, import_non_secure71.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 300
      },
      data: {
        format: "{{path}}",
        childrenProperty: "children",
        useSortAlphabetically: true
      }
    };
    return chartNode;
  }
  getInputDefinitions() {
    return [
      {
        id: "objects",
        title: "Objects",
        dataType: ["object[]", "object"],
        required: true
      }
    ];
  }
  getOutputDefinitions() {
    return [
      {
        id: "tree",
        title: "Tree",
        dataType: "string"
      }
    ];
  }
  getEditors() {
    return [
      {
        type: "string",
        label: "Children Property",
        dataKey: "childrenProperty"
      },
      {
        type: "code",
        label: "Format",
        dataKey: "format",
        language: "prompt-interpolation-markdown",
        theme: "prompt-interpolation"
      },
      {
        type: "toggle",
        label: "Sort Alphabetically",
        dataKey: "useSortAlphabetically"
      }
    ];
  }
  getBody() {
    return import_ts_dedent65.dedent`
      Format: ${this.data.format}
      Children: ${this.data.childrenProperty}
      Sort: ${this.data.useSortAlphabetically ? "Yes" : "No"}
    `;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent65.dedent`
        Converts an array of objects into a tree structure and renders it as text.

        The format field supports interpolation using {{property}} syntax to determine
        how each node is displayed.

        Use the children property to specify which field contains child nodes.
      `,
      infoBoxTitle: "To Tree Node",
      contextMenuTitle: "To Tree",
      group: ["Text"]
    };
  }
  buildTree(objects, parentPath = "", level = 0, isLast = true) {
    if (!Array.isArray(objects) || objects.length === 0)
      return "";
    let result = "";
    const sortedObjects = this.data.useSortAlphabetically ? (0, import_lodash_es14.sortBy)(objects, (obj) => String((0, import_lodash_es14.get)(obj, "path", ""))) : objects;
    sortedObjects.forEach((obj, index) => {
      const isLastItem = index === sortedObjects.length - 1;
      const prefix = level === 0 ? "" : isLast ? "\u2514\u2500\u2500 " : "\u251C\u2500\u2500 ";
      const indent = level === 0 ? "" : "    ".repeat(level - 1) + (isLast ? "    " : "\u2502   ");
      const matches = extractInterpolationVariables(this.data.format);
      const interpolationVars = matches.reduce(
        (acc, match15) => {
          const key = match15;
          acc[key] = String((0, import_lodash_es14.get)(obj, key, ""));
          return acc;
        },
        {}
      );
      const formattedNode = interpolate(this.data.format, interpolationVars);
      result += indent + prefix + formattedNode + "\n";
      const children = (0, import_lodash_es14.get)(obj, this.data.childrenProperty);
      if (Array.isArray(children) && children.length > 0) {
        const newPath = parentPath ? `${parentPath}/${formattedNode}` : formattedNode;
        result += this.buildTree(children, newPath, level + 1, isLastItem);
      }
    });
    return result;
  }
  async process(inputs) {
    const objects = coerceTypeOptional(inputs["objects"], "object[]") ?? [];
    const treeOutput = this.buildTree(objects);
    return {
      ["tree"]: {
        type: "string",
        value: treeOutput
      }
    };
  }
};
var toTreeNode = nodeDefinition(ToTreeNodeImpl, "To Tree");

// src/model/nodes/LoopUntilNode.ts
var import_non_secure72 = require("nanoid/non-secure");
var import_ts_dedent66 = require("ts-dedent");
var LoopUntilNodeImpl = class extends NodeImpl {
  static create() {
    const chartNode = {
      type: "loopUntil",
      title: "Loop Until",
      id: (0, import_non_secure72.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 200
      },
      data: {
        targetGraph: void 0,
        conditionType: "allOutputsSet"
      }
    };
    return chartNode;
  }
  getInputDefinitions(_connections, _nodes, project) {
    const inputs = [];
    const graph = project.graphs[this.data.targetGraph ?? ""];
    if (graph) {
      const inputNodes = graph.nodes.filter((node) => node.type === "graphInput");
      const inputIds = [...new Set(inputNodes.map((node) => node.data.id))].sort();
      inputIds.forEach((id) => {
        const inputNode = inputNodes.find((node) => node.data.id === id);
        inputs.push({
          id,
          title: id,
          dataType: inputNode.data.dataType
        });
      });
    }
    return inputs;
  }
  getOutputDefinitions(_connections, _nodes, project) {
    const outputs = [];
    const graph = project.graphs[this.data.targetGraph ?? ""];
    if (graph) {
      const outputNodes = graph.nodes.filter((node) => node.type === "graphOutput");
      const outputIds = [...new Set(outputNodes.map((node) => node.data.id))].sort();
      outputIds.forEach((id) => {
        const outputNode = outputNodes.find((node) => node.data.id === id);
        outputs.push({
          id,
          title: id,
          dataType: outputNode.data.dataType
        });
      });
    }
    outputs.push(
      {
        id: "iteration",
        title: "Iterations",
        dataType: "number",
        description: "The number of iterations completed."
      },
      {
        id: "completed",
        title: "Completed",
        dataType: "boolean",
        description: "True when the loop has completed."
      }
    );
    return outputs;
  }
  getEditors(context) {
    const definitions = [
      {
        type: "graphSelector",
        label: "Target Graph",
        dataKey: "targetGraph"
      },
      {
        type: "dropdown",
        dataKey: "conditionType",
        label: "Stop Condition",
        options: [
          { label: "All Outputs Set", value: "allOutputsSet" },
          { label: "Input Equals Value", value: "inputEqual" }
        ],
        helperMessage: "The condition that will stop the loop"
      },
      {
        type: "number",
        dataKey: "maxIterations",
        label: "Max Iterations",
        helperMessage: "Maximum number of iterations (optional, leave empty for unlimited)",
        allowEmpty: true
      }
    ];
    if (this.data.conditionType === "inputEqual") {
      definitions.push(
        {
          type: "string",
          dataKey: "inputToCheck",
          label: "Input to Check",
          helperMessage: "The name of the input to compare"
        },
        {
          type: "string",
          dataKey: "targetValue",
          label: "Target Value",
          helperMessage: "The value to compare against"
        }
      );
    }
    if (this.data.targetGraph) {
      const graph = context.project.graphs[this.data.targetGraph];
      if (graph) {
        const inputNodes = graph.nodes.filter((node) => node.type === "graphInput");
        const inputIds = [...new Set(inputNodes.map((node) => node.data.id))].sort();
        for (const inputId of inputIds) {
          const inputNode = inputNodes.find((node) => node.data.id === inputId);
          definitions.push({
            type: "dynamic",
            dataKey: "inputData",
            dynamicDataKey: inputNode.data.id,
            dataType: inputNode.data.dataType,
            label: inputNode.data.id,
            editor: inputNode.data.editor ?? "auto"
          });
        }
      }
    }
    return definitions;
  }
  static getUIData() {
    return {
      infoBoxBody: import_ts_dedent66.dedent`
        Executes a subgraph in a loop until a condition is met. Each iteration's outputs become
        the inputs for the next iteration. Supports different stopping conditions and optional
        maximum iterations.
      `,
      infoBoxTitle: "Loop Until Node",
      contextMenuTitle: "Loop Until",
      group: ["Logic"]
    };
  }
  getBody(context) {
    var _a, _b;
    if (!this.data.targetGraph) {
      return "No target graph selected";
    }
    const graphName = ((_b = (_a = context.project.graphs[this.data.targetGraph]) == null ? void 0 : _a.metadata) == null ? void 0 : _b.name) ?? "Unknown Graph";
    const condition = this.data.conditionType === "allOutputsSet" ? "all outputs are set" : `${this.data.inputToCheck} equals ${this.data.targetValue}`;
    const maxIterations = this.data.maxIterations ? `
Max iterations: ${this.data.maxIterations}` : "";
    return `Executes ${graphName}
until ${condition}${maxIterations}`;
  }
  checkCondition(outputs) {
    var _a;
    if (this.data.conditionType === "allOutputsSet") {
      const anyInputIsExcluded = Object.values(outputs).filter((o) => o != null).some((output) => output.type === "control-flow-excluded");
      return !anyInputIsExcluded;
    } else if (this.data.conditionType === "inputEqual" && this.data.inputToCheck && this.data.targetValue) {
      const inputValue = outputs[this.data.inputToCheck];
      return ((_a = inputValue == null ? void 0 : inputValue.value) == null ? void 0 : _a.toString()) === this.data.targetValue;
    }
    return false;
  }
  async process(inputs, context) {
    var _a;
    if (!this.data.targetGraph) {
      throw new Error("No target graph selected");
    }
    let iteration = 0;
    let currentInputs = { ...inputs };
    if (this.data.inputData) {
      Object.entries(this.data.inputData).forEach(([key, value]) => {
        if (currentInputs[key] === void 0) {
          currentInputs[key] = value;
        }
      });
    }
    let lastOutputs = {};
    while (!context.signal.aborted) {
      if (this.data.maxIterations && iteration >= this.data.maxIterations) {
        break;
      }
      const subprocessor = context.createSubProcessor(this.data.targetGraph, { signal: context.signal });
      lastOutputs = await subprocessor.processGraph(
        context,
        currentInputs,
        context.contextValues
      );
      iteration++;
      if (this.checkCondition(lastOutputs)) {
        break;
      }
      (_a = context.onPartialOutputs) == null ? void 0 : _a.call(context, lastOutputs);
      currentInputs = lastOutputs;
    }
    return {
      ...lastOutputs,
      ["iteration"]: { type: "number", value: iteration },
      ["completed"]: { type: "boolean", value: true }
    };
  }
};
var loopUntilNode = nodeDefinition(LoopUntilNodeImpl, "Loop Until");

// src/model/Nodes.ts
var registerBuiltInNodes = (registry) => {
  return registry.register(toYamlNode).register(userInputNode).register(textNode).register(chatNode).register(promptNode).register(extractRegexNode).register(codeNode).register(matchNode).register(ifNode).register(readDirectoryNode).register(readFileNode).register(ifElseNode).register(chunkNode).register(graphInputNode).register(graphOutputNode).register(subGraphNode).register(arrayNode).register(extractJsonNode).register(assemblePromptNode).register(loopControllerNode).register(trimChatMessagesNode).register(extractYamlNode).register(externalCallNode).register(extractObjectPathNode).register(raiseEventNode).register(contextNode).register(coalesceNode).register(passthroughNode).register(popNode).register(setGlobalNode).register(getGlobalNode).register(waitForEventNode).register(gptFunctionNode).register(getEmbeddingNode).register(vectorStoreNode).register(vectorNearestNeighborsNode).register(hashNode).register(abortGraphNode).register(raceInputsNode).register(toJsonNode).register(joinNode).register(filterNode).register(objectNode).register(booleanNode).register(compareNode).register(evaluateNode).register(numberNode).register(randomNumberNode).register(shuffleNode).register(commentNode).register(imageNode).register(audioNode).register(httpCallNode).register(delayNode).register(appendToDatasetNode).register(createDatasetNode).register(loadDatasetNode).register(getAllDatasetsNode).register(splitNode).register(datasetNearestNeighborsNode).register(getDatasetRowNode).register(sliceNode).register(extractMarkdownCodeBlocksNode).register(assembleMessageNode).register(urlReferenceNode).register(destructureNode).register(replaceDatasetNode).register(listGraphsNode).register(graphReferenceNode).register(callGraphNode).register(delegateFunctionCallNode).register(playAudioNode).register(documentNode).register(chatLoopNode).register(readAllFilesNode).register(toMarkdownTableNode).register(cronNode).register(toTreeNode).register(loopUntilNode);
};
var globalRivetNodeRegistry = registerBuiltInNodes(new NodeRegistration());
function resetGlobalRivetNodeRegistry() {
  globalRivetNodeRegistry = registerBuiltInNodes(new NodeRegistration());
}

// src/integrations/GptTokenizerTokenizer.ts
var import_emittery = __toESM(require("emittery-0-13"), 1);
var GptTokenizerTokenizer = class {
  emitter = new import_emittery.default();
  on(event, listener) {
    this.emitter.on(event, listener);
  }
  async getTokenCountForString(input, _info) {
    const { encode } = await import("gpt-tokenizer");
    return encode(input).length;
  }
  async getTokenCountForMessages(messages, functions, _info) {
    try {
      const openaiMessages = await Promise.all(
        messages.map((message) => chatMessageToOpenAIChatCompletionMessage(message))
      );
      const validMessages = openaiMessages.filter((message) => message.role !== "tool").map((message) => {
        if (Array.isArray(message.content)) {
          const textContent = message.content.filter((c) => c.type === "text").map((c) => c.text).join("");
          return { ...message, content: textContent };
        }
        return message;
      });
      const { encode, encodeChat } = await import("gpt-tokenizer");
      const encodedChat = encodeChat(validMessages, "gpt-3.5-turbo");
      const encodedFunctions = functions && functions.length > 0 ? encode(this.convertGptFunctionsToPromptString(functions)) : [];
      return encodedChat.length + encodedFunctions.length;
    } catch (err) {
      this.emitter.emit("error", getError(err));
      return 0;
    }
  }
  /**
   * Converts GPT Functions to approximate TypeScript-style string.
   * Per thread: https://community.openai.com/t/how-to-calculate-the-tokens-when-using-function-call/266573/24
   * We should consider using a different library, eg. https://github.com/hmarr/openai-chat-tokens
   * @param functions
   */
  convertGptFunctionsToPromptString(functions) {
    return `
# Tools

## functions

namespace functions {
${functions.map(
      (fn) => {
        var _a;
        return `
// ${fn.description}
type ${fn.name} = (_: {
${Object.entries(((_a = fn.parameters) == null ? void 0 : _a.properties) ?? {}).map(([parameterName, value]) => `// ${value == null ? void 0 : value.description}
${parameterName}?: ${value == null ? void 0 : value.type}`).join("\n")}
})
`;
      }
    ).join("")}
} // namespace functions
`;
  }
};

// src/model/GraphProcessor.ts
var PQueue = import_p_queue.default;
if (typeof PQueue !== "function") {
  PQueue = import_p_queue.default.default;
}
var GraphProcessor = class _GraphProcessor {
  // Per-instance state
  #graph;
  #project;
  #nodesById;
  #nodeInstances;
  #connections;
  #definitions;
  #emitter = new import_emittery2.default();
  #running = false;
  #isSubProcessor = false;
  #scc;
  #nodesNotInCycle;
  #externalFunctions = {};
  slowMode = false;
  #isPaused = false;
  #parent;
  #registry;
  id = (0, import_non_secure73.nanoid)();
  #includeTrace = true;
  executor;
  /** If set, specifies the node(s) that the graph will run TO, instead of the nodes without any dependents. */
  runToNodeIds;
  /** If set, specifies the node that the graph will run FROM, instead of the start nodes. Requires preloading data. */
  runFromNodeId;
  /** The node that is executing this graph, almost always a subgraph node. Undefined for root. */
  #executor;
  /** The interval between nodeFinish events when playing back a recording. I.e. how fast the playback is. */
  recordingPlaybackChatLatency = 1e3;
  warnOnInvalidGraph = false;
  // Per-process state
  #erroredNodes = void 0;
  #remainingNodes = void 0;
  #visitedNodes = void 0;
  #currentlyProcessing = void 0;
  #context = void 0;
  #nodeResults = void 0;
  #abortController = void 0;
  #processingQueue = void 0;
  #graphInputs = void 0;
  #graphOutputs = void 0;
  #executionCache = void 0;
  #queuedNodes = void 0;
  #loopControllersSeen = void 0;
  #subprocessors = void 0;
  #contextValues = void 0;
  #globals = void 0;
  #attachedNodeData = void 0;
  #aborted = false;
  #abortSuccessfully = false;
  #abortError = void 0;
  #totalCost = 0;
  #ignoreNodes = void 0;
  #hasPreloadedData = false;
  #nodeAbortControllers = /* @__PURE__ */ new Map();
  /** User input nodes that are pending user input. */
  #pendingUserInputs = void 0;
  get isRunning() {
    return this.#running;
  }
  constructor(project, graphId, registry, includeTrace) {
    var _a, _b;
    this.#project = project;
    const graph = graphId ? project.graphs[graphId] : project.metadata.mainGraphId ? project.graphs[project.metadata.mainGraphId] : void 0;
    if (!graph) {
      throw new Error(`Graph ${graphId} not found in project`);
    }
    this.#graph = graph;
    this.#includeTrace = includeTrace;
    this.#nodeInstances = {};
    this.#connections = {};
    this.#nodesById = {};
    this.#registry = registry ?? globalRivetNodeRegistry;
    this.#emitter.bindMethods(this, ["on", "off", "once", "onAny", "offAny"]);
    for (const node of this.#graph.nodes) {
      this.#nodeInstances[node.id] = this.#registry.createDynamicImpl(node);
      this.#nodesById[node.id] = node;
    }
    for (const conn of this.#graph.connections) {
      if (!this.#nodesById[conn.inputNodeId] || !this.#nodesById[conn.outputNodeId]) {
        if (this.warnOnInvalidGraph) {
          if (!this.#nodesById[conn.inputNodeId]) {
            console.warn(
              `Missing node ${conn.inputNodeId} in graph ${graphId} (connection from ${(_a = this.#nodesById[conn.outputNodeId]) == null ? void 0 : _a.title})`
            );
          } else {
            console.warn(
              `Missing node ${conn.outputNodeId} in graph ${graphId} (connection to ${(_b = this.#nodesById[conn.inputNodeId]) == null ? void 0 : _b.title}) `
            );
          }
        }
        continue;
      }
      this.#connections[conn.inputNodeId] ??= [];
      this.#connections[conn.outputNodeId] ??= [];
      this.#connections[conn.inputNodeId].push(conn);
      this.#connections[conn.outputNodeId].push(conn);
    }
    this.#definitions = {};
    for (const node of this.#graph.nodes) {
      const connectionsForNode = this.#connections[node.id] ?? [];
      const inputDefs = this.#nodeInstances[node.id].getInputDefinitionsIncludingBuiltIn(
        connectionsForNode,
        this.#nodesById,
        this.#project
      );
      const outputDefs = this.#nodeInstances[node.id].getOutputDefinitions(
        connectionsForNode,
        this.#nodesById,
        this.#project
      );
      this.#definitions[node.id] = { inputs: inputDefs, outputs: outputDefs };
      const invalidConnections = connectionsForNode.filter((connection) => {
        if (connection.inputNodeId === node.id) {
          const inputDef = inputDefs.find((def) => def.id === connection.inputId);
          if (!inputDef) {
            if (this.warnOnInvalidGraph) {
              const nodeFrom = this.#nodesById[connection.outputNodeId];
              console.warn(
                `[Warn] Invalid connection going from "${nodeFrom == null ? void 0 : nodeFrom.title}".${connection.outputId} to "${node.title}".${connection.inputId}`
              );
            }
            return true;
          }
        } else {
          const outputDef = outputDefs.find((def) => def.id === connection.outputId);
          if (!outputDef) {
            if (this.warnOnInvalidGraph) {
              const nodeTo = this.#nodesById[connection.inputNodeId];
              console.warn(
                `[Warn] Invalid connection going from "${node.title}".${connection.outputId} to "${nodeTo == null ? void 0 : nodeTo.title}".${connection.inputId}`
              );
            }
            return true;
          }
        }
        return false;
      });
      for (const connections of values(this.#connections)) {
        for (const invalidConnection of invalidConnections) {
          const index = connections.indexOf(invalidConnection);
          if (index !== -1) {
            connections.splice(index, 1);
          }
        }
      }
    }
    this.#scc = this.#tarjanSCC();
    this.#nodesNotInCycle = this.#scc.filter((cycle) => cycle.length === 1).flat();
    this.setExternalFunction("echo", async (value) => ({ type: "any", value }));
    this.#emitter.on("globalSet", ({ id, value }) => {
      this.#emitter.emit(`globalSet:${id}`, value);
    });
  }
  #emitTraceEvent(eventData) {
    if (this.#includeTrace) {
      this.#emitter.emit("trace", eventData);
    }
  }
  on = void 0;
  off = void 0;
  once = void 0;
  onAny = void 0;
  offAny = void 0;
  #onUserEventHandlers = /* @__PURE__ */ new Map();
  onUserEvent(onEvent, listener) {
    const handler = (event, value) => {
      if (event === `userEvent:${onEvent}`) {
        listener(value);
      }
    };
    this.#onUserEventHandlers.set(listener, handler);
    this.#emitter.onAny(handler);
  }
  offUserEvent(listener) {
    const internalHandler = this.#onUserEventHandlers.get(listener);
    this.#emitter.offAny(internalHandler);
  }
  userInput(nodeId, values3) {
    const pending = this.#pendingUserInputs[nodeId];
    if (pending) {
      pending.resolve(values3);
      delete this.#pendingUserInputs[nodeId];
    }
    for (const processor of this.#subprocessors) {
      processor.userInput(nodeId, values3);
    }
  }
  setExternalFunction(name, fn) {
    this.#externalFunctions[name] = fn;
  }
  async abort(successful = false, error) {
    if (!this.#running || this.#aborted) {
      return Promise.resolve();
    }
    this.#abortController.abort();
    this.#abortSuccessfully = successful;
    this.#abortError = error;
    this.#emitter.emit("graphAbort", { successful, error, graph: this.#graph });
    if (!this.#isSubProcessor) {
      this.#emitter.emit("abort", { successful, error });
    }
    await this.#processingQueue.onIdle();
  }
  pause() {
    if (this.#isPaused === false) {
      this.#isPaused = true;
      this.#emitter.emit("pause", void 0);
    }
  }
  resume() {
    if (this.#isPaused) {
      this.#isPaused = false;
      this.#emitter.emit("resume", void 0);
    }
  }
  setSlowMode(slowMode) {
    this.slowMode = slowMode;
  }
  async #waitUntilUnpaused() {
    if (!this.#isPaused) {
      return;
    }
    await this.#emitter.once("resume");
  }
  async *events() {
    for await (const [event, data] of this.#emitter.anyEvent()) {
      yield { type: event, ...data };
      if (event === "finish") {
        break;
      }
    }
  }
  preloadNodeData(nodeId, data) {
    this.#nodeResults ??= /* @__PURE__ */ new Map();
    this.#visitedNodes ??= /* @__PURE__ */ new Set();
    for (const value of Object.values(data)) {
      if (!value || !("type" in value) || !value.type) {
        throw new Error(`Invalid data value for node ${nodeId}, must be a DataValue`);
      }
    }
    this.#nodeResults.set(nodeId, data);
    this.#visitedNodes.add(nodeId);
    this.#hasPreloadedData = true;
  }
  /** Gets all node IDs that a given node ID depends on being complete before the given node ID can start. */
  getDependencyNodesDeep(nodeId) {
    const node = this.#nodesById[nodeId];
    if (!node) {
      return [];
    }
    const connections = this.#connections[nodeId];
    if (!connections) {
      return [];
    }
    const dependencyNodes = connections.map((conn) => {
      if (conn.inputNodeId === nodeId) {
        return this.getDependencyNodesDeep(conn.outputNodeId);
      }
      return [];
    }).flat();
    return [.../* @__PURE__ */ new Set([nodeId, ...dependencyNodes])];
  }
  async replayRecording(recorder) {
    const { events } = recorder;
    this.#initProcessState();
    try {
      const nodesByIdAllGraphs = {};
      for (const graph of Object.values(this.#project.graphs)) {
        for (const node of graph.nodes) {
          nodesByIdAllGraphs[node.id] = node;
        }
      }
      const getGraph = (graphId) => {
        const graph = this.#project.graphs[graphId];
        if (!graph) {
          throw new Error(`Mismatch between project and recording: graph ${graphId} not found in project`);
        }
        return graph;
      };
      const getNode = (nodeId) => {
        const node = nodesByIdAllGraphs[nodeId];
        if (!node) {
          throw new Error(`Mismatch between project and recording: node ${nodeId} not found in any graph in project`);
        }
        return node;
      };
      for (const event of events) {
        if (this.#aborted) {
          break;
        }
        await this.#waitUntilUnpaused();
        await (0, import_ts_pattern10.match)(event).with({ type: "start" }, ({ data }) => {
          this.#emitter.emit("start", {
            project: this.#project,
            contextValues: data.contextValues,
            inputs: data.inputs,
            startGraph: getGraph(data.startGraph)
          });
          this.#contextValues = data.contextValues;
          this.#graphInputs = data.inputs;
        }).with({ type: "abort" }, ({ data }) => {
          this.#emitter.emit("abort", data);
        }).with({ type: "pause" }, () => {
        }).with({ type: "resume" }, () => {
        }).with({ type: "done" }, ({ data }) => {
          this.#emitter.emit("done", data);
          this.#graphOutputs = data.results;
          this.#running = false;
        }).with({ type: "error" }, ({ data }) => {
          this.#emitter.emit("error", data);
        }).with({ type: "globalSet" }, ({ data }) => {
          this.#emitter.emit("globalSet", data);
        }).with({ type: "trace" }, ({ data }) => {
          this.#emitter.emit("trace", data);
        }).with({ type: "graphStart" }, ({ data }) => {
          this.#emitter.emit("graphStart", {
            graph: getGraph(data.graphId),
            inputs: data.inputs
          });
        }).with({ type: "graphFinish" }, ({ data }) => {
          this.#emitter.emit("graphFinish", {
            graph: getGraph(data.graphId),
            outputs: data.outputs
          });
        }).with({ type: "graphError" }, ({ data }) => {
          this.#emitter.emit("graphError", {
            graph: getGraph(data.graphId),
            error: data.error
          });
        }).with({ type: "graphAbort" }, ({ data }) => {
          this.#emitter.emit("graphAbort", {
            graph: getGraph(data.graphId),
            error: data.error,
            successful: data.successful
          });
        }).with({ type: "nodeStart" }, async ({ data }) => {
          const node = getNode(data.nodeId);
          this.#emitter.emit("nodeStart", {
            node: getNode(data.nodeId),
            inputs: data.inputs,
            processId: data.processId
          });
          if (node.type === "chat") {
            await new Promise((resolve) => setTimeout(resolve, this.recordingPlaybackChatLatency));
          }
        }).with({ type: "nodeFinish" }, ({ data }) => {
          const node = getNode(data.nodeId);
          this.#emitter.emit("nodeFinish", {
            node,
            outputs: data.outputs,
            processId: data.processId
          });
          this.#nodeResults.set(data.nodeId, data.outputs);
          this.#visitedNodes.add(data.nodeId);
        }).with({ type: "nodeError" }, ({ data }) => {
          this.#emitter.emit("nodeError", {
            node: getNode(data.nodeId),
            error: data.error,
            processId: data.processId
          });
          this.#erroredNodes.set(data.nodeId, data.error);
          this.#visitedNodes.add(data.nodeId);
        }).with({ type: "nodeExcluded" }, ({ data }) => {
          this.#emitter.emit("nodeExcluded", {
            node: getNode(data.nodeId),
            processId: data.processId,
            inputs: data.inputs,
            outputs: data.outputs,
            reason: data.reason
          });
          this.#visitedNodes.add(data.nodeId);
        }).with({ type: "nodeOutputsCleared" }, () => {
        }).with({ type: "partialOutput" }, () => {
        }).with({ type: "userInput" }, ({ data }) => {
          this.#emitter.emit("userInput", {
            callback: void 0,
            inputStrings: data.inputStrings,
            inputs: data.inputs,
            node: getNode(data.nodeId),
            processId: data.processId,
            renderingType: data.renderingType
          });
        }).with({ type: import_ts_pattern10.P.string.startsWith("globalSet:") }, ({ type, data }) => {
          this.#emitter.emit(type, data);
        }).with({ type: import_ts_pattern10.P.string.startsWith("userEvent:") }, ({ type, data }) => {
          this.#emitter.emit(type, data);
        }).with({ type: "newAbortController" }, () => {
        }).with({ type: "finish" }, () => {
          this.#emitter.emit("finish", void 0);
        }).with(import_ts_pattern10.P.nullish, () => {
        }).exhaustive();
      }
    } catch (err) {
      this.#emitter.emit("error", { error: getError(err) });
    } finally {
      this.#running = false;
    }
    return this.#graphOutputs;
  }
  #initProcessState() {
    this.#running = true;
    if (!this.#hasPreloadedData) {
      this.#nodeResults = /* @__PURE__ */ new Map();
      this.#visitedNodes = /* @__PURE__ */ new Set();
    }
    this.#erroredNodes = /* @__PURE__ */ new Map();
    this.#currentlyProcessing = /* @__PURE__ */ new Set();
    this.#remainingNodes = new Set(this.#graph.nodes.map((n) => n.id));
    this.#pendingUserInputs = {};
    this.#processingQueue = new PQueue({ concurrency: Infinity });
    this.#graphOutputs = {};
    this.#executionCache ??= /* @__PURE__ */ new Map();
    this.#queuedNodes = /* @__PURE__ */ new Set();
    this.#loopControllersSeen = /* @__PURE__ */ new Set();
    this.#subprocessors = /* @__PURE__ */ new Set();
    this.#attachedNodeData = /* @__PURE__ */ new Map();
    this.#globals ??= /* @__PURE__ */ new Map();
    this.#ignoreNodes = /* @__PURE__ */ new Set();
    this.#abortController = this.#newAbortController();
    this.#abortController.signal.addEventListener("abort", () => {
      this.#aborted = true;
    });
    this.#aborted = false;
    this.#abortError = void 0;
    this.#abortSuccessfully = false;
    this.#nodeAbortControllers = /* @__PURE__ */ new Map();
  }
  /** Main function for running a graph. Runs a graph and returns the outputs from the output nodes of the graph. */
  async processGraph(context, inputs = {}, contextValues = {}) {
    try {
      if (this.#running) {
        throw new Error("Cannot process graph while already processing");
      }
      this.#initProcessState();
      this.#context = context;
      this.#graphInputs = inputs;
      this.#contextValues ??= contextValues;
      if (this.#context.tokenizer) {
        this.#context.tokenizer.on("error", (error) => {
          this.#emitter.emit("error", { error });
        });
      }
      if (!this.#isSubProcessor) {
        await this.#emitter.emit("start", {
          contextValues: this.#contextValues,
          inputs: this.#graphInputs,
          project: this.#project,
          startGraph: this.#graph
        });
      }
      await this.#emitter.emit("graphStart", { graph: this.#graph, inputs: this.#graphInputs });
      if (this.#hasPreloadedData) {
        for (const node of this.#graph.nodes) {
          if (this.#nodeResults.has(node.id)) {
            this.#emitTraceEvent(`Node ${node.title} has preloaded data`);
            await this.#emitter.emit("nodeStart", {
              node,
              inputs: {},
              processId: "preload"
            });
            await this.#emitter.emit("nodeFinish", {
              node,
              outputs: this.#nodeResults.get(node.id),
              processId: "preload"
            });
          }
        }
      }
      const startNodes = this.runToNodeIds ? this.#graph.nodes.filter((node) => {
        var _a;
        return (_a = this.runToNodeIds) == null ? void 0 : _a.includes(node.id);
      }) : this.#graph.nodes.filter((node) => this.#outputNodesFrom(node).nodes.length === 0);
      await this.#waitUntilUnpaused();
      for (const startNode of startNodes) {
        this.#processingQueue.add(async () => {
          await this.#fetchNodeDataAndProcessNode(startNode);
        });
      }
      await this.#processingQueue.onIdle();
      if (this.runToNodeIds) {
        for (const node of this.#graph.nodes) {
          if (this.#queuedNodes.has(node.id) === false) {
            this.#ignoreNodes.add(node.id);
          }
        }
      }
      const erroredNodes = [...this.#erroredNodes.entries()].filter(([nodeId]) => {
        const erroredNodeAttachedData = this.#getAttachedDataTo(nodeId);
        return erroredNodeAttachedData.races == null || erroredNodeAttachedData.races.completed === false;
      });
      if (erroredNodes.length && !this.#abortSuccessfully) {
        const error = this.#abortError ?? Error(
          `Graph ${this.#graph.metadata.name} (${this.#graph.metadata.id}) failed to process due to errors in nodes: ${erroredNodes.map(([nodeId, error2]) => `${this.#nodesById[nodeId].title} (${nodeId}): ${error2}`).join(", ")}`
        );
        await this.#emitter.emit("graphError", { graph: this.#graph, error });
        if (!this.#isSubProcessor) {
          await this.#emitter.emit("error", { error });
        }
        throw error;
      }
      if (this.#graphOutputs["cost"] == null) {
        this.#graphOutputs["cost"] = {
          type: "number",
          value: this.#totalCost
        };
      }
      const outputValues = this.#graphOutputs;
      this.#running = false;
      await this.#emitter.emit("graphFinish", { graph: this.#graph, outputs: outputValues });
      if (!this.#isSubProcessor) {
        await this.#emitter.emit("done", { results: outputValues });
        await this.#emitter.emit("finish", void 0);
      }
      return outputValues;
    } finally {
      this.#running = false;
      if (!this.#isSubProcessor) {
        await this.#emitter.emit("finish", void 0);
      }
    }
  }
  async #fetchNodeDataAndProcessNode(node) {
    var _a;
    if (this.#currentlyProcessing.has(node.id) || this.#queuedNodes.has(node.id)) {
      return;
    }
    if (this.#nodeResults.has(node.id) || this.#erroredNodes.has(node.id)) {
      return;
    }
    const inputNodes = this.#inputNodesTo(node);
    for (const inputNode of inputNodes) {
      if (this.#erroredNodes.has(inputNode.id)) {
        return;
      }
    }
    const connections = this.#connections[node.id] ?? [];
    const inputsReady = this.#definitions[node.id].inputs.every((input) => {
      const connectionToInput = connections == null ? void 0 : connections.find((conn) => conn.inputId === input.id && conn.inputNodeId === node.id);
      return connectionToInput || !input.required;
    });
    if (!inputsReady) {
      return;
    }
    this.#emitTraceEvent(`Node ${node.title} has required inputs nodes: ${inputNodes.map((n) => n.title).join(", ")}`);
    const attachedData = this.#getAttachedDataTo(node);
    if (node.type === "raceInputs" || attachedData.races) {
      for (const inputNode of inputNodes) {
        const inputNodeAttachedData = this.#getAttachedDataTo(inputNode);
        const raceIds = /* @__PURE__ */ new Set([...((_a = attachedData.races) == null ? void 0 : _a.raceIds) ?? []]);
        if (node.type === "raceInputs") {
          raceIds.add(`race-${node.id}`);
        }
        inputNodeAttachedData.races = {
          propagate: false,
          raceIds: [...raceIds],
          completed: false
        };
      }
    }
    this.#queuedNodes.add(node.id);
    this.#processingQueue.addAll(
      inputNodes.map((inputNode) => {
        return async () => {
          this.#emitTraceEvent(`Fetching required data for node ${inputNode.title} (${inputNode.id})`);
          await this.#fetchNodeDataAndProcessNode(inputNode);
        };
      })
    );
    await this.#processNodeIfAllInputsAvailable(node);
  }
  /** If all inputs are present, all conditions met, processes the node. */
  async #processNodeIfAllInputsAvailable(node) {
    var _a, _b, _c;
    const builtInNode = node;
    if (this.#ignoreNodes.has(node.id)) {
      this.#emitTraceEvent(`Node ${node.title} is ignored`);
      return;
    }
    if (this.runToNodeIds) {
      const dependencyNodes = this.getDependencyNodesDeep(node.id);
      if (this.runToNodeIds.some((runTo) => runTo !== node.id && dependencyNodes.includes(runTo))) {
        this.#emitTraceEvent(`Node ${node.title} is excluded due to runToNodeIds`);
        return;
      }
    }
    if (this.#currentlyProcessing.has(node.id)) {
      this.#emitTraceEvent(`Node ${node.title} is already being processed`);
      return;
    }
    if (this.#visitedNodes.has(node.id) && node.type !== "loopController") {
      this.#emitTraceEvent(`Node ${node.title} has already been processed`);
      return;
    }
    if (this.#erroredNodes.has(node.id)) {
      this.#emitTraceEvent(`Node ${node.title} has already errored`);
      return;
    }
    const inputNodes = this.#inputNodesTo(node);
    for (const inputNode of inputNodes) {
      if (this.#erroredNodes.has(inputNode.id)) {
        this.#emitTraceEvent(`Node ${node.title} has errored input node ${inputNode.title}`);
        return;
      }
    }
    const connections = this.#connections[node.id] ?? [];
    const inputsReady = this.#definitions[node.id].inputs.every((input) => {
      const connectionToInput = connections == null ? void 0 : connections.find((conn) => conn.inputId === input.id && conn.inputNodeId === node.id);
      return connectionToInput || !input.required;
    });
    if (!inputsReady) {
      this.#emitTraceEvent(
        `Node ${node.title} has required inputs nodes: ${inputNodes.map((n) => n.title).join(", ")}`
      );
      return;
    }
    const inputValues = this.#getInputValuesForNode(node);
    if (this.#excludedDueToControlFlow(node, inputValues, (0, import_non_secure73.nanoid)(), "loop-not-broken")) {
      this.#emitTraceEvent(`Node ${node.title} is excluded due to control flow`);
      return;
    }
    let waitingForInputNode = false;
    const anyInputIsValid = Object.values(inputValues).some(
      (value) => value && value.type.includes("control-flow-excluded") === false
    );
    for (const inputNode of inputNodes) {
      if (node.type === "loopController" && !this.#loopControllersSeen.has(node.id) && this.#nodesAreInSameCycle(node.id, inputNode.id)) {
        continue;
      }
      if (node.type === "raceInputs" && this.#visitedNodes.has(inputNode.id) && anyInputIsValid) {
        waitingForInputNode = false;
        break;
      }
      if (waitingForInputNode === false && this.#visitedNodes.has(inputNode.id) === false) {
        waitingForInputNode = inputNode.title;
      }
    }
    if (waitingForInputNode) {
      this.#emitTraceEvent(`Node ${node.title} is waiting for input node ${waitingForInputNode}`);
      return;
    }
    this.#currentlyProcessing.add(node.id);
    if (node.type === "loopController") {
      this.#loopControllersSeen.add(node.id);
    }
    const attachedData = this.#getAttachedDataTo(node);
    if (attachedData.loopInfo && attachedData.loopInfo.loopControllerId !== node.id) {
      attachedData.loopInfo.nodes.add(node.id);
    }
    if ((_a = attachedData.races) == null ? void 0 : _a.completed) {
      this.#emitTraceEvent(`Node ${node.title} is part of a race that was completed`);
      return;
    }
    const processId = await this.#processNode(node);
    if (this.slowMode) {
      await new Promise((resolve) => setTimeout(resolve, 250));
    }
    this.#emitTraceEvent(`Finished processing node ${node.title} (${node.id})`);
    this.#visitedNodes.add(node.id);
    this.#currentlyProcessing.delete(node.id);
    this.#remainingNodes.delete(node.id);
    const outputNodes = this.#outputNodesFrom(node);
    if (node.type === "loopController") {
      const loopControllerResults = this.#nodeResults.get(node.id);
      const breakValue = loopControllerResults["break"];
      const didBreak = (
        // @ts-ignore
        !((breakValue == null ? void 0 : breakValue.type) === "control-flow-excluded" && (breakValue == null ? void 0 : breakValue.value) === "loop-not-broken")
      );
      if (!didBreak) {
        this.#emitTraceEvent(`Loop controller ${node.title} did not break, so we're looping again`);
        for (const loopNodeId of ((_b = attachedData.loopInfo) == null ? void 0 : _b.nodes) ?? []) {
          const cycleNode = this.#nodesById[loopNodeId];
          this.#emitTraceEvent(`Clearing cycle node ${cycleNode.title} (${cycleNode.id})`);
          this.#visitedNodes.delete(cycleNode.id);
          this.#currentlyProcessing.delete(cycleNode.id);
          this.#remainingNodes.add(cycleNode.id);
          this.#nodeResults.delete(cycleNode.id);
        }
      }
    }
    if (node.type === "raceInputs") {
      const allNodesForRace = [...this.#attachedNodeData.entries()].filter(
        ([, { races }]) => races == null ? void 0 : races.raceIds.includes(`race-${node.id}`)
      );
      for (const [nodeId] of allNodesForRace) {
        for (const [key, abortController] of this.#nodeAbortControllers.entries()) {
          if (key.startsWith(nodeId)) {
            this.#emitTraceEvent(`Aborting node ${nodeId} because other race branch won`);
            abortController.abort();
          }
        }
        for (const [, nodeAttachedData] of [...this.#attachedNodeData.entries()]) {
          if ((_c = nodeAttachedData.races) == null ? void 0 : _c.raceIds.includes(`race-${node.id}`)) {
            nodeAttachedData.races.completed = true;
          }
        }
      }
    }
    let childLoopInfo = attachedData.loopInfo;
    if (builtInNode.type === "loopController") {
      if (childLoopInfo != null && childLoopInfo.loopControllerId !== builtInNode.id) {
        this.#nodeErrored(node, new Error("Nested loops are not supported"), processId);
        return;
      }
      childLoopInfo = {
        propagate: (parent, connectionsFromParent) => {
          if (parent.type === "loopController" && connectionsFromParent.some((c) => c.outputId === "break")) {
            return false;
          }
          return true;
        },
        loopControllerId: node.id,
        // We want to be able to clear every node that _potentially_ could run in the loop
        nodes: (childLoopInfo == null ? void 0 : childLoopInfo.nodes) ?? /* @__PURE__ */ new Set(),
        iterationCount: ((childLoopInfo == null ? void 0 : childLoopInfo.iterationCount) ?? 0) + 1
      };
      attachedData.loopInfo = childLoopInfo;
    }
    for (const { node: outputNode, connections: connectionsToOutputNode } of outputNodes.connectionsToNodes) {
      const outputNodeAttachedData = this.#getAttachedDataTo(outputNode);
      const propagatedAttachedData = Object.entries(attachedData).filter(([, value]) => {
        if (!value) {
          return false;
        }
        if (typeof value.propagate === "boolean") {
          return value.propagate;
        }
        return value.propagate(node, connectionsToOutputNode);
      });
      for (const [key, value] of propagatedAttachedData) {
        outputNodeAttachedData[key] = value;
      }
    }
    this.#processingQueue.addAll(
      outputNodes.nodes.map((outputNode) => async () => {
        this.#emitTraceEvent(`Trying to run output node from ${node.title}: ${outputNode.title} (${outputNode.id})`);
        await this.#processNodeIfAllInputsAvailable(outputNode);
      })
    );
  }
  #getAttachedDataTo(node) {
    const nodeId = typeof node === "string" ? node : node.id;
    let nodeData = this.#attachedNodeData.get(nodeId);
    if (nodeData == null) {
      nodeData = {};
      this.#attachedNodeData.set(nodeId, nodeData);
    }
    return nodeData;
  }
  async #processNode(node) {
    const processId = (0, import_non_secure73.nanoid)();
    if (this.#abortController.signal.aborted) {
      this.#nodeErrored(node, new Error("Processing aborted"), processId);
      return processId;
    }
    const inputNodes = this.#inputNodesTo(node);
    const erroredInputNodes = inputNodes.filter((inputNode) => this.#erroredNodes.has(inputNode.id));
    if (erroredInputNodes.length > 0) {
      const error = new Error(
        `Cannot process node ${node.title} (${node.id}) because it depends on errored nodes: ${erroredInputNodes.map((n) => `${n.title} (${n.id})`).join(", ")}`
      );
      this.#nodeErrored(node, error, processId);
      return processId;
    }
    if (node.isSplitRun) {
      await this.#processSplitRunNode(node, processId);
    } else {
      await this.#processNormalNode(node, processId);
    }
    return processId;
  }
  async #processSplitRunNode(node, processId) {
    var _a;
    const inputValues = this.#getInputValuesForNode(node);
    if (this.#excludedDueToControlFlow(node, inputValues, processId)) {
      return;
    }
    const splittingAmount = Math.min(
      (0, import_lodash_es15.max)(values(inputValues).map((value) => Array.isArray(value == null ? void 0 : value.value) ? value == null ? void 0 : value.value.length : 1)) ?? 1,
      node.splitRunMax ?? 10
    );
    this.#emitter.emit("nodeStart", { node, inputs: inputValues, processId });
    try {
      let results = [];
      if (node.isSplitSequential) {
        for (let i = 0; i < splittingAmount; i++) {
          if (this.#aborted) {
            throw new Error("Processing aborted");
          }
          const inputs = fromEntries(
            entries(inputValues).map(([port, value]) => [
              port,
              isArrayDataValue(value) ? arrayizeDataValue(value)[i] ?? void 0 : value
            ])
          );
          try {
            const output = await this.#processNodeWithInputData(
              node,
              inputs,
              i,
              processId,
              (node2, partialOutputs, index) => {
                this.#emitter.emit("partialOutput", { node: node2, outputs: partialOutputs, index, processId });
              }
            );
            if (((_a = output["cost"]) == null ? void 0 : _a.type) === "number") {
              this.#totalCost += coerceTypeOptional(output["cost"], "number") ?? 0;
            }
            results.push({ type: "output", output });
          } catch (error) {
            results.push({ type: "error", error: getError(error) });
          }
        }
      } else {
        results = await Promise.all(
          (0, import_lodash_es15.range)(0, splittingAmount).map(async (i) => {
            var _a2;
            const inputs = fromEntries(
              entries(inputValues).map(([port, value]) => [
                port,
                isArrayDataValue(value) ? arrayizeDataValue(value)[i] ?? void 0 : value
              ])
            );
            try {
              const output = await this.#processNodeWithInputData(
                node,
                inputs,
                i,
                processId,
                (node2, partialOutputs, index) => {
                  this.#emitter.emit("partialOutput", { node: node2, outputs: partialOutputs, index, processId });
                }
              );
              if (((_a2 = output["cost"]) == null ? void 0 : _a2.type) === "number") {
                this.#totalCost += coerceTypeOptional(output["cost"], "number") ?? 0;
              }
              return { type: "output", output };
            } catch (error) {
              return { type: "error", error: getError(error) };
            }
          })
        );
      }
      const errors = results.filter((r) => r.type === "error").map((r) => r.error);
      if (errors.length === 1) {
        const e = errors[0];
        throw e;
      } else if (errors.length > 0) {
        throw new Error(errors.join("\n"));
      }
      const aggregateResults = results.reduce((acc, result) => {
        for (const [portId, value] of entries(result.output)) {
          acc[portId] ??= { type: (value == null ? void 0 : value.type) + "[]", value: [] };
          acc[portId].value.push(value == null ? void 0 : value.value);
        }
        return acc;
      }, {});
      this.#nodeResults.set(node.id, aggregateResults);
      this.#visitedNodes.add(node.id);
      this.#totalCost += (0, import_lodash_es15.sum)(results.map((r) => {
        var _a2;
        return coerceTypeOptional((_a2 = r.output) == null ? void 0 : _a2["cost"], "number") ?? 0;
      }));
      this.#emitter.emit("nodeFinish", { node, outputs: aggregateResults, processId });
    } catch (error) {
      this.#nodeErrored(node, error, processId);
    }
  }
  async #processNormalNode(node, processId) {
    var _a;
    const inputValues = this.#getInputValuesForNode(node);
    if (this.#excludedDueToControlFlow(node, inputValues, processId)) {
      return;
    }
    this.#emitter.emit("nodeStart", { node, inputs: inputValues, processId });
    try {
      const outputValues = await this.#processNodeWithInputData(
        node,
        inputValues,
        0,
        processId,
        (node2, partialOutputs, index) => {
          this.#emitter.emit("partialOutput", { node: node2, outputs: partialOutputs, index, processId });
        }
      );
      this.#nodeResults.set(node.id, outputValues);
      this.#visitedNodes.add(node.id);
      if (((_a = outputValues["cost"]) == null ? void 0 : _a.type) === "number") {
        this.#totalCost += coerceTypeOptional(outputValues["cost"], "number") ?? 0;
      }
      this.#emitter.emit("nodeFinish", { node, outputs: outputValues, processId });
    } catch (error) {
      this.#nodeErrored(node, error, processId);
    }
  }
  #nodeErrored(node, e, processId) {
    const error = getError(e);
    this.#emitter.emit("nodeError", { node, error, processId });
    this.#emitTraceEvent(`Node ${node.title} (${node.id}-${processId}) errored: ${error.stack}`);
    this.#erroredNodes.set(node.id, error.toString());
  }
  getRootProcessor() {
    let processor = this;
    while (processor.#parent) {
      processor = processor.#parent;
    }
    return processor;
  }
  /** Raise a user event on the processor, all subprocessors, and their children. */
  raiseEvent(event, data) {
    this.#emitter.emit(`userEvent:${event}`, data);
    for (const subprocessor of this.#subprocessors) {
      subprocessor.raiseEvent(event, data);
    }
  }
  #newAbortController() {
    const controller = new AbortController();
    this.#emitter.emit("newAbortController", controller);
    return controller;
  }
  async #processNodeWithInputData(node, inputValues, index, processId, partialOutput) {
    const instance = this.#nodeInstances[node.id];
    const nodeAbortController = this.#newAbortController();
    const abortListener = () => {
      nodeAbortController.abort();
    };
    this.#nodeAbortControllers.set(`${node.id}-${processId}`, nodeAbortController);
    this.#abortController.signal.addEventListener("abort", abortListener);
    const plugin = this.#registry.getPluginFor(node.type);
    let tokenizer = this.#context.tokenizer;
    if (!tokenizer) {
      tokenizer = new GptTokenizerTokenizer();
      tokenizer.on("error", (e) => {
        this.#emitter.emit("error", { error: e });
      });
    }
    const context = {
      ...this.#context,
      node,
      tokenizer,
      executor: this.executor ?? "nodejs",
      project: this.#project,
      executionCache: this.#executionCache,
      graphInputs: this.#graphInputs,
      graphOutputs: this.#graphOutputs,
      attachedData: this.#getAttachedDataTo(node),
      waitEvent: async (event) => {
        return new Promise((resolve, reject) => {
          this.#emitter.once(`userEvent:${event}`).then(resolve).catch(reject);
          nodeAbortController.signal.addEventListener("abort", () => {
            reject(new Error("Process aborted"));
          });
        });
      },
      raiseEvent: (event, data) => {
        this.getRootProcessor().raiseEvent(event, data);
      },
      contextValues: this.#contextValues,
      externalFunctions: { ...this.#externalFunctions },
      onPartialOutputs: (partialOutputs) => {
        partialOutput == null ? void 0 : partialOutput(node, partialOutputs, index);
        const { useAsGraphPartialOutput } = node.data ?? {};
        if (useAsGraphPartialOutput && this.#executor && this.#parent) {
          const executorNode = this.#parent.#nodesById[this.#executor.nodeId];
          if (executorNode) {
            this.#emitter.emit("partialOutput", {
              index: this.#executor.index,
              node: executorNode,
              outputs: partialOutputs,
              processId: this.#executor.processId
            });
          }
        }
      },
      signal: nodeAbortController.signal,
      processId,
      getGlobal: (id) => this.#globals.get(id),
      setGlobal: (id, value) => {
        this.#globals.set(id, value);
        this.#emitter.emit("globalSet", { id, value, processId });
      },
      waitForGlobal: async (id) => {
        if (this.#globals.has(id)) {
          return this.#globals.get(id);
        }
        await this.getRootProcessor().#emitter.once(`globalSet:${id}`);
        return this.#globals.get(id);
      },
      createSubProcessor: (subGraphId, { signal } = {}) => {
        const processor = new _GraphProcessor(this.#project, subGraphId, this.#registry);
        processor.executor = this.executor;
        processor.#isSubProcessor = true;
        processor.#executionCache = this.#executionCache;
        processor.#externalFunctions = this.#externalFunctions;
        processor.#contextValues = this.#contextValues;
        processor.#parent = this;
        processor.#globals = this.#globals;
        processor.#executor = {
          nodeId: node.id,
          index,
          processId
        };
        processor.on("nodeError", (e) => this.#emitter.emit("nodeError", e));
        processor.on("nodeFinish", (e) => this.#emitter.emit("nodeFinish", e));
        processor.on("partialOutput", (e) => this.#emitter.emit("partialOutput", e));
        processor.on("nodeExcluded", (e) => this.#emitter.emit("nodeExcluded", e));
        processor.on("nodeStart", (e) => this.#emitter.emit("nodeStart", e));
        processor.on("graphAbort", (e) => this.#emitter.emit("graphAbort", e));
        processor.on("userInput", (e) => this.#emitter.emit("userInput", e));
        processor.on("graphStart", (e) => this.#emitter.emit("graphStart", e));
        processor.on("graphFinish", (e) => this.#emitter.emit("graphFinish", e));
        processor.on("globalSet", (e) => this.#emitter.emit("globalSet", e));
        processor.on("newAbortController", (e) => this.#emitter.emit("newAbortController", e));
        processor.on("pause", () => {
          if (!this.#isPaused) {
            this.pause();
          }
        });
        processor.on("resume", () => {
          if (this.#isPaused) {
            this.resume();
          }
        });
        processor.onAny((event, data) => {
          if (event.startsWith("globalSet:")) {
            this.#emitter.emit(event, data);
          }
        });
        this.#subprocessors.add(processor);
        if (signal) {
          signal.addEventListener("abort", () => {
            processor.abort();
          });
        }
        this.#abortController.signal.addEventListener("abort", () => {
          processor.abort();
        });
        this.on("pause", () => processor.pause());
        this.on("resume", () => processor.resume());
        return processor;
      },
      trace: (message) => {
        this.#emitTraceEvent(message);
      },
      abortGraph: (error) => {
        this.abort(error === void 0, error);
      },
      getPluginConfig: (name) => getPluginConfig(plugin, this.#context.settings, name),
      requestUserInput: async (inputStrings, renderingType) => {
        const results2 = await new Promise((resolve, reject) => {
          this.#pendingUserInputs[node.id] = {
            resolve,
            reject
          };
          this.#abortController.signal.addEventListener("abort", () => {
            delete this.#pendingUserInputs[node.id];
            reject(new Error("Processing aborted"));
          });
          this.#emitter.emit("userInput", {
            node,
            inputStrings,
            inputs: inputValues,
            renderingType,
            callback: (results3) => {
              resolve(results3);
              delete this.#pendingUserInputs[node.id];
            },
            processId
          });
        });
        return results2;
      }
    };
    await this.#waitUntilUnpaused();
    const results = await instance.process(inputValues, context);
    this.#nodeAbortControllers.delete(`${node.id}-${processId}`);
    this.#abortController.signal.removeEventListener("abort", abortListener);
    if (nodeAbortController.signal.aborted) {
      throw new Error("Aborted");
    }
    return results;
  }
  #excludedDueToControlFlow(node, inputValues, processId, typeOfExclusion = void 0) {
    var _a;
    if (node.disabled) {
      this.#emitTraceEvent(`Excluding node ${node.title} because it's disabled`);
      this.#visitedNodes.add(node.id);
      this.#markAsExcluded(node, processId, inputValues, "disabled");
      return true;
    }
    if (node.isConditional && typeOfExclusion === void 0) {
      const ifValue = coerceTypeOptional(inputValues[IF_PORT.id], "boolean");
      if (ifValue === false) {
        this.#emitTraceEvent(`Excluding node ${node.title} because if port is false`);
        this.#visitedNodes.add(node.id);
        this.#markAsExcluded(node, processId, inputValues, "if port is false");
        return true;
      }
    }
    const inputsWithValues = entries(inputValues);
    const controlFlowExcludedValues = inputsWithValues.filter(
      ([, value]) => value && getScalarTypeOf(value.type) === "control-flow-excluded" && (!typeOfExclusion || value.value === typeOfExclusion)
    );
    const inputIsExcludedValue = inputsWithValues.length > 0 && controlFlowExcludedValues.length > 0;
    const isWaitingForLoop = controlFlowExcludedValues.some((value) => {
      var _a2;
      return ((_a2 = value == null ? void 0 : value[1]) == null ? void 0 : _a2.value) === "loop-not-broken";
    });
    const nodesAllowedToConsumeExcludedValue = [
      "if",
      "ifElse",
      "coalesce",
      "graphOutput",
      "raceInputs",
      "loopController"
    ];
    const allowedToConsumedExcludedValue = nodesAllowedToConsumeExcludedValue.includes(node.type) && !isWaitingForLoop;
    if (inputIsExcludedValue && !allowedToConsumedExcludedValue) {
      if (!isWaitingForLoop) {
        if (inputIsExcludedValue) {
          this.#emitTraceEvent(
            `Excluding node ${node.title} because of control flow. Input is has excluded value: ${(_a = controlFlowExcludedValues[0]) == null ? void 0 : _a[0]}`
          );
        }
        this.#visitedNodes.add(node.id);
        this.#markAsExcluded(node, processId, inputValues, "input is excluded value");
      }
      return true;
    }
    return false;
  }
  #markAsExcluded(node, processId, inputValues, reason) {
    const outputs = {};
    for (const output of this.#definitions[node.id].outputs) {
      outputs[output.id] = { type: "control-flow-excluded", value: void 0 };
    }
    if (node.type === "loopController") {
      outputs["break"] = { type: "control-flow-excluded", value: "loop-not-broken" };
    }
    this.#nodeResults.set(node.id, outputs);
    this.#emitter.emit("nodeExcluded", {
      node,
      processId,
      inputs: inputValues,
      outputs,
      reason
    });
  }
  #getInputValuesForNode(node) {
    const connections = this.#connections[node.id];
    return this.#definitions[node.id].inputs.reduce(
      (values3, input) => {
        if (!connections) {
          return values3;
        }
        const connection = connections.find((conn) => conn.inputId === input.id && conn.inputNodeId === node.id);
        if (connection) {
          const outputNode = this.#nodeInstances[connection.outputNodeId].chartNode;
          const outputNodeOutputs = this.#nodeResults.get(outputNode.id);
          const outputResult = outputNodeOutputs == null ? void 0 : outputNodeOutputs[connection.outputId];
          values3[input.id] = outputResult;
        }
        return values3;
      },
      {}
    );
  }
  /** Gets the nodes that are inputting to the given node. */
  #inputNodesTo(node) {
    var _a;
    const connections = this.#connections[node.id];
    if (!connections) {
      return [];
    }
    const connectionsToNode = connections.filter((conn) => conn.inputNodeId === node.id).filter(isNotNull);
    const inputDefinitions = ((_a = this.#definitions[node.id]) == null ? void 0 : _a.inputs) ?? [];
    return connectionsToNode.filter((connection) => {
      const connectionDefinition = inputDefinitions.find((def) => def.id === connection.inputId);
      return connectionDefinition != null;
    }).map((conn) => this.#nodesById[conn.outputNodeId]).filter(isNotNull);
  }
  /** Gets the nodes that the given node it outputting to. */
  #outputNodesFrom(node) {
    var _a;
    const connections = this.#connections[node.id];
    if (!connections) {
      return { nodes: [], connections: [], connectionsToNodes: [] };
    }
    const connectionsToNode = connections.filter((conn) => conn.outputNodeId === node.id);
    const outputDefinitions = ((_a = this.#definitions[node.id]) == null ? void 0 : _a.outputs) ?? [];
    const outputConnections = connectionsToNode.filter((connection) => {
      const connectionDefinition = outputDefinitions.find((def) => def.id === connection.outputId);
      return connectionDefinition != null;
    });
    const outputNodes = (0, import_lodash_es15.uniqBy)(
      outputConnections.map((conn) => this.#nodesById[conn.inputNodeId]).filter(isNotNull),
      (x) => x.id
    );
    const connectionsToNodes = [];
    outputNodes.forEach((node2) => {
      const connections2 = outputConnections.filter((conn) => conn.inputNodeId === node2.id);
      connectionsToNodes.push({ connections: connections2, node: node2 });
    });
    return { nodes: outputNodes, connections: outputConnections, connectionsToNodes };
  }
  #tarjanSCC() {
    let index = 0;
    const stack = [];
    const indices = /* @__PURE__ */ new Map();
    const lowLinks = /* @__PURE__ */ new Map();
    const onStack = /* @__PURE__ */ new Map();
    const sccs = [];
    const strongConnect = (node) => {
      var _a;
      indices.set(node.id, index);
      lowLinks.set(node.id, index);
      index++;
      stack.push(node);
      onStack.set(node.id, true);
      const outgoingConnections = (_a = this.#connections[node.id]) == null ? void 0 : _a.filter((conn) => conn.outputNodeId === node.id);
      for (const connection of outgoingConnections ?? []) {
        const successor = this.#nodesById[connection.inputNodeId];
        if (!indices.has(successor.id)) {
          strongConnect(successor);
          lowLinks.set(node.id, Math.min(lowLinks.get(node.id), lowLinks.get(successor.id)));
        } else if (onStack.get(successor.id)) {
          lowLinks.set(node.id, Math.min(lowLinks.get(node.id), indices.get(successor.id)));
        }
      }
      if (lowLinks.get(node.id) === indices.get(node.id)) {
        const scc = [];
        let connectedNode;
        do {
          connectedNode = stack.pop();
          onStack.set(connectedNode.id, false);
          scc.push(connectedNode);
        } while (connectedNode.id !== node.id);
        sccs.push(scc);
      }
    };
    for (const node of this.#graph.nodes) {
      if (!indices.has(node.id)) {
        strongConnect(node);
      }
    }
    return sccs;
  }
  #nodeIsInCycle(nodeId) {
    return this.#nodesNotInCycle.find((node) => node.id === nodeId) == null;
  }
  #nodesAreInSameCycle(a, b) {
    return this.#scc.find((cycle) => cycle.find((node) => node.id === a) && cycle.find((node) => node.id === b));
  }
};

// src/native/BaseDir.ts
var baseDirs = {
  app: "app",
  appCache: "appCache",
  appConfig: "appConfig",
  appData: "appData",
  appLocalData: "appLocalData",
  appLog: "appLog",
  audio: "audio",
  cache: "cache",
  config: "config",
  data: "data",
  desktop: "desktop",
  document: "document",
  download: "download",
  executable: "executable",
  font: "font",
  home: "home",
  localData: "localData",
  log: "log",
  picture: "picture",
  public: "public",
  resource: "resource",
  runtime: "runtime",
  temp: "temp",
  template: "template",
  video: "video"
};
function assertBaseDir(baseDir) {
  if (!(baseDir in baseDirs)) {
    throw new Error(`Invalid base directory: ${baseDir}`);
  }
}

// src/native/BrowserNativeApi.ts
var BrowserNativeApi = class {
  readdir(_path, _baseDir) {
    throw new Error("Method not implemented.");
  }
  readTextFile(_path, _baseDir) {
    throw new Error("Method not implemented.");
  }
  readBinaryFile(_path, _baseDir) {
    throw new Error("Method not implemented.");
  }
  writeTextFile(_path, _data, _baseDir) {
    throw new Error("Method not implemented.");
  }
  exec(command, args, options2) {
    throw new Error("Method not supported.");
  }
};

// src/integrations/openai/OpenAIEmbeddingGenerator.ts
var import_openai3 = require("openai");
var OpenAIEmbeddingGenerator = class {
  #settings;
  constructor(settings) {
    this.#settings = settings;
  }
  async generateEmbedding(text, options2) {
    const api = new import_openai3.OpenAI({
      apiKey: this.#settings.openAiKey,
      organization: this.#settings.openAiOrganization,
      dangerouslyAllowBrowser: true
      // It's fine in Rivet
    });
    const response = await api.embeddings.create({
      input: text,
      model: (options2 == null ? void 0 : options2.model) ?? "text-embedding-ada-002",
      dimensions: options2 == null ? void 0 : options2.dimensions
    });
    const embeddings = response.data;
    return embeddings[0].embedding;
  }
};

// src/integrations/enableIntegrations.ts
registerIntegration("embeddingGenerator", "openai", (context) => new OpenAIEmbeddingGenerator(context.settings));

// src/recording/ExecutionRecorder.ts
var import_non_secure74 = require("nanoid/non-secure");
var import_emittery3 = __toESM(require("emittery-0-13"), 1);
var toRecordedEventMap = {
  graphStart: ({ graph, inputs }) => ({ graphId: graph.metadata.id, inputs }),
  graphFinish: ({ graph, outputs }) => ({ graphId: graph.metadata.id, outputs }),
  graphError: ({ graph, error }) => ({
    graphId: graph.metadata.id,
    error: typeof error === "string" ? error : error.stack
  }),
  nodeStart: ({ node, inputs, processId }) => ({
    nodeId: node.id,
    inputs,
    processId
  }),
  nodeFinish: ({ node, outputs, processId }) => ({
    nodeId: node.id,
    outputs,
    processId
  }),
  nodeError: ({ node, error, processId }) => ({
    nodeId: node.id,
    error: typeof error === "string" ? error : error.stack,
    processId
  }),
  abort: ({ successful, error }) => ({ successful, error: typeof error === "string" ? error : error == null ? void 0 : error.stack }),
  graphAbort: ({ successful, error, graph }) => ({
    successful,
    error: typeof error === "string" ? error : error == null ? void 0 : error.stack,
    graphId: graph.metadata.id
  }),
  nodeExcluded: ({ node, processId, inputs, outputs, reason }) => ({
    nodeId: node.id,
    processId,
    inputs,
    outputs,
    reason
  }),
  userInput: ({ node, inputs, callback, processId, inputStrings, renderingType }) => ({
    nodeId: node.id,
    inputs,
    callback,
    processId,
    inputStrings,
    renderingType
  }),
  partialOutput: ({ node, outputs, index, processId }) => ({
    nodeId: node.id,
    outputs,
    index,
    processId
  }),
  nodeOutputsCleared: ({ node, processId }) => ({
    nodeId: node.id,
    processId
  }),
  error: ({ error }) => ({
    error: typeof error === "string" ? error : error.stack
  }),
  done: ({ results }) => ({ results }),
  globalSet: ({ id, processId, value }) => ({ id, processId, value }),
  pause: () => void 0,
  resume: () => void 0,
  start: ({ contextValues, inputs, project, startGraph }) => ({
    contextValues,
    inputs,
    projectId: project.metadata.id,
    startGraph: startGraph.metadata.id
  }),
  trace: (message) => message,
  newAbortController: () => {
  },
  finish: () => void 0
};
var isPrefix = (s, prefix) => s.startsWith(prefix);
function toRecordedEvent(event, data) {
  if (isPrefix(event, "globalSet:")) {
    return {
      type: event,
      data,
      ts: Date.now()
    };
  }
  if (isPrefix(event, "userEvent:")) {
    return {
      type: event,
      data,
      ts: Date.now()
    };
  }
  return {
    type: event,
    data: toRecordedEventMap[event](data),
    ts: Date.now()
  };
}
var ExecutionRecorder = class _ExecutionRecorder {
  #events = [];
  recordingId;
  #emitter;
  #includePartialOutputs;
  #includeTrace;
  constructor(options2 = {}) {
    this.#emitter = new import_emittery3.default();
    this.#emitter.bindMethods(this, ["on", "off", "once"]);
    this.#includePartialOutputs = options2.includePartialOutputs ?? false;
    this.#includeTrace = options2.includeTrace ?? false;
  }
  on = void 0;
  off = void 0;
  once = void 0;
  recordSocket(channel) {
    return new Promise((resolve, reject) => {
      this.recordingId = (0, import_non_secure74.nanoid)();
      const listener = (event) => {
        const { message, data } = JSON.parse(event.data);
        if (this.#includePartialOutputs === false && message === "partialOutput") {
          return;
        }
        if (this.#includeTrace === false && message === "trace") {
          return;
        }
        this.#events.push(toRecordedEvent(message, data));
        if (message === "done" || message === "abort" || message === "error") {
          this.#emitter.emit("finish", {
            recording: this.getRecording()
          });
          channel.removeEventListener("message", listener);
          resolve();
        }
      };
      channel.addEventListener("message", listener);
    });
  }
  record(processor) {
    this.recordingId = (0, import_non_secure74.nanoid)();
    processor.onAny((event, data) => {
      if (this.#includePartialOutputs === false && event === "partialOutput") {
        return;
      }
      if (this.#includeTrace === false && event === "trace") {
        return;
      }
      this.#events.push(toRecordedEvent(event, data));
      if (event === "done" || event === "abort" || event === "error") {
        this.#emitter.emit("finish", {
          recording: this.getRecording()
        });
      }
    });
  }
  getRecording() {
    var _a, _b;
    return {
      recordingId: this.recordingId,
      events: this.#events,
      startTs: ((_a = this.#events[0]) == null ? void 0 : _a.ts) ?? 0,
      finishTs: ((_b = this.#events[this.#events.length - 1]) == null ? void 0 : _b.ts) ?? 0
    };
  }
  get events() {
    return this.#events;
  }
  static deserializeFromString(serialized) {
    const recorder = new _ExecutionRecorder();
    const serializedRecording = JSON.parse(serialized);
    if (serializedRecording.version !== 1) {
      throw new Error("Unsupported serialized events version");
    }
    recorder.recordingId = serializedRecording.recording.recordingId;
    recorder.#events = serializedRecording.recording.events;
    return recorder;
  }
  serialize() {
    const serialized = {
      version: 1,
      recording: this.getRecording()
    };
    return JSON.stringify(serialized);
  }
};

// src/plugins/anthropic/fetchEventSource.ts
var EventSourceResponse2 = class extends Response {
  name;
  streams;
  constructor(body, init2) {
    if (body == null) {
      super(null, init2);
      this.name = "EventSourceResponse";
      this.streams = null;
      return;
    }
    const [bodyForString, bodyForEvents] = body.tee();
    const streams = createEventStream2(bodyForEvents);
    super(bodyForString, init2);
    this.name = "EventSourceResponse";
    this.streams = streams;
  }
  async *events() {
    if (this.streams == null) {
      return;
    }
    const reader = this.streams.eventStream.getReader();
    try {
      while (true) {
        const { done, value } = await this.raceWithTimeout(reader.read());
        if (done) {
          break;
        }
        yield value;
      }
    } finally {
      reader.releaseLock();
    }
  }
  async raceWithTimeout(promise, timeout = 5e3) {
    return new Promise(async (resolve, reject) => {
      const timer = setTimeout(() => {
        reject(new Error("Timeout: API response took too long."));
      }, timeout);
      try {
        const result = await promise;
        clearTimeout(timer);
        resolve(result);
      } catch (error) {
        clearTimeout(timer);
        reject(error);
      }
    });
  }
};
async function fetchEventSource2(url, init2) {
  const headers = {
    ...init2 == null ? void 0 : init2.headers,
    accept: "text/event-stream"
  };
  const response = await fetch(url, {
    ...init2,
    headers
  });
  return new EventSourceResponse2(response.body, response);
}
var LineSplitter2 = class {
  constructor(separator = /\n+/) {
    this.separator = separator;
  }
  buffer = "";
  transform(chunk, controller) {
    this.buffer += chunk;
    const lines = this.buffer.split(this.separator);
    this.buffer = lines.pop() ?? "";
    for (const line of lines) {
      controller.enqueue(line);
    }
  }
  flush(controller) {
    if (this.buffer.length > 0) {
      controller.enqueue(this.buffer);
      this.buffer = "";
    }
  }
};
function createEventStream2(body) {
  if (body == null) {
    return null;
  }
  const textStream = body.pipeThrough(new TextDecoderStream());
  const eventStream = textStream.pipeThrough(new TransformStream(new LineSplitter2())).pipeThrough(
    new TransformStream({
      transform(line, controller) {
        if (line.startsWith("data: ")) {
          const data = line.slice(6).trim();
          controller.enqueue(data);
        } else if (line.startsWith("event: ")) {
          const event = line.slice(7).trim();
          controller.enqueue(`[${event}]`);
        }
      }
    })
  );
  return { eventStream, textStream };
}

// src/plugins/anthropic/anthropic.ts
var anthropicModels = {
  "claude-instant-1": {
    maxTokens: 1e5,
    cost: {
      prompt: 163e-5,
      completion: 551e-5
    },
    displayName: "Claude Instant"
  },
  "claude-instant-1.2": {
    maxTokens: 1e5,
    cost: {
      prompt: 8e-7,
      completion: 24e-7
    },
    displayName: "Claude Instant 1.2"
  },
  "claude-2": {
    maxTokens: 1e5,
    cost: {
      prompt: 8e-6,
      completion: 24e-6
    },
    displayName: "Claude 2"
  },
  "claude-2.1": {
    maxTokens: 2e5,
    cost: {
      prompt: 8e-6,
      completion: 24e-6
    },
    displayName: "Claude 2.1"
  },
  "claude-3-haiku-20240307": {
    maxTokens: 2e5,
    cost: {
      prompt: 25e-8,
      completion: 125e-8
    },
    displayName: "Claude 3 Haiku"
  },
  "claude-3-sonnet-20240229": {
    maxTokens: 2e5,
    cost: {
      prompt: 3e-6,
      completion: 15e-6
    },
    displayName: "Claude 3 Sonnet"
  },
  "claude-3-opus-20240229": {
    maxTokens: 2e5,
    cost: {
      prompt: 15e-6,
      completion: 75e-6
    },
    displayName: "Claude 3 Opus"
  },
  "claude-3-5-sonnet-latest": {
    maxTokens: 2e5,
    cost: {
      prompt: 3e-6,
      completion: 15e-6
    },
    displayName: "Claude 3.5 Sonnet"
  },
  "claude-3-5-haiku-latest": {
    maxTokens: 2e5,
    cost: {
      prompt: 8e-7,
      completion: 4e-6
    },
    displayName: "Claude 3.5 Haiku"
  }
};
var anthropicModelOptions = Object.entries(anthropicModels).map(([id, { displayName }]) => ({
  value: id,
  label: displayName
}));
async function* streamChatCompletions2({
  apiEndpoint,
  apiKey,
  signal,
  ...rest
}) {
  const defaultSignal = new AbortController().signal;
  const response = await fetchEventSource2(`${apiEndpoint}/completions`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01"
    },
    body: JSON.stringify({
      ...rest,
      stream: true
    }),
    signal: signal ?? defaultSignal
  });
  let hadChunks = false;
  let nextDataType;
  for await (const chunk of response.events()) {
    hadChunks = true;
    if (chunk === "[DONE]") {
      return;
    } else if (/\[\w+\]/.test(chunk)) {
      nextDataType = chunk.slice(1, -1);
      continue;
    }
    let data;
    try {
      data = JSON.parse(chunk);
    } catch (err) {
      console.error("JSON parse failed on chunk: ", chunk);
      throw err;
    }
    yield data;
  }
  if (!hadChunks) {
    const responseJson = await response.json();
    throw new AnthropicError(`No chunks received. Response: ${JSON.stringify(responseJson)}`, response, responseJson);
  }
}
async function callMessageApi({
  apiEndpoint,
  apiKey,
  signal,
  tools,
  beta,
  ...rest
}) {
  var _a;
  const defaultSignal = new AbortController().signal;
  const response = await fetch(`${apiEndpoint}/messages`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
      ...beta ? { "anthropic-beta": beta } : {}
    },
    body: JSON.stringify({
      ...rest,
      tools,
      stream: false
    }),
    signal: signal ?? defaultSignal
  });
  const responseJson = await response.json();
  if (response.status !== 200) {
    throw new AnthropicError(((_a = responseJson == null ? void 0 : responseJson.error) == null ? void 0 : _a.message) ?? "Request failed", response, responseJson);
  }
  return responseJson;
}
async function* streamMessageApi({
  apiEndpoint,
  apiKey,
  signal,
  beta,
  ...rest
}) {
  const defaultSignal = new AbortController().signal;
  const response = await fetchEventSource2(`${apiEndpoint}/messages`, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "x-api-key": apiKey,
      "anthropic-version": "2023-06-01",
      ...beta ? { "anthropic-beta": beta } : {}
    },
    body: JSON.stringify({
      ...rest,
      stream: true
    }),
    signal: signal ?? defaultSignal
  });
  let hadChunks = false;
  let nextDataType;
  for await (const chunk of response.events()) {
    hadChunks = true;
    if (chunk === "[message_stop]") {
      return;
    } else if (/\[\w+\]/.test(chunk)) {
      nextDataType = chunk.slice(1, -1);
      continue;
    }
    let data;
    try {
      data = JSON.parse(chunk);
    } catch (err) {
      console.error("JSON parse failed on chunk: ", chunk);
      throw err;
    }
    yield data;
  }
  if (!hadChunks) {
    const responseJson = await response.json();
    throw new AnthropicError(`No chunks received. Response: ${JSON.stringify(responseJson)}`, response, responseJson);
  }
}
var AnthropicError = class extends Error {
  constructor(message, response, responseJson) {
    super(message);
    this.response = response;
    this.responseJson = responseJson;
  }
};

// src/plugins/anthropic/nodes/ChatAnthropicNode.ts
var import_non_secure75 = require("nanoid/non-secure");
var import_ts_dedent67 = require("ts-dedent");
var import_p_retry2 = __toESM(require("p-retry-4"), 1);
var import_ts_pattern11 = require("ts-pattern");

// src/utils/assertNever.ts
function assertNever(x) {
  throw new Error(`Unexpected object: ${x}`);
}

// src/plugins/anthropic/nodes/ChatAnthropicNode.ts
var cache2 = /* @__PURE__ */ new Map();
var ChatAnthropicNodeImpl = {
  create() {
    const chartNode = {
      type: "chatAnthropic",
      title: "Chat (Anthropic)",
      id: (0, import_non_secure75.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 275
      },
      data: {
        model: "claude-3-5-sonnet-latest",
        useModelInput: false,
        temperature: 0.5,
        useTemperatureInput: false,
        top_p: 1,
        useTopPInput: false,
        top_k: void 0,
        useTopKInput: false,
        useTopP: false,
        useUseTopPInput: false,
        maxTokens: 1024,
        useMaxTokensInput: false,
        useStop: false,
        stop: "",
        useStopInput: false,
        cache: false,
        useAsGraphPartialOutput: true,
        enableToolUse: false,
        endpoint: "",
        useEndpointInput: false,
        overrideModel: void 0,
        useOverrideModelInput: false,
        enableCitations: false
      }
    };
    return chartNode;
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.model.startsWith("claude-3")) {
      inputs.push({
        dataType: "string",
        id: "system",
        title: "System Prompt"
      });
    }
    if (data.useModelInput) {
      inputs.push({
        id: "model",
        title: "Model",
        dataType: "string",
        required: false
      });
    }
    if (data.useTemperatureInput) {
      inputs.push({
        dataType: "number",
        id: "temperature",
        title: "Temperature"
      });
    }
    if (data.useTopPInput) {
      inputs.push({
        dataType: "number",
        id: "top_p",
        title: "Top P"
      });
    }
    if (data.useUseTopPInput) {
      inputs.push({
        dataType: "boolean",
        id: "useTopP",
        title: "Use Top P"
      });
    }
    if (data.useMaxTokensInput) {
      inputs.push({
        dataType: "number",
        id: "maxTokens",
        title: "Max Tokens"
      });
    }
    if (data.useStopInput) {
      inputs.push({
        dataType: "string",
        id: "stop",
        title: "Stop"
      });
    }
    inputs.push({
      dataType: ["chat-message", "chat-message[]"],
      id: "prompt",
      title: "Prompt"
    });
    if (data.enableToolUse) {
      inputs.push({
        dataType: ["gpt-function", "gpt-function[]"],
        id: "tools",
        title: "Tools",
        description: "Tools to use in the model. To connect multiple tools, use an Array node.",
        coerced: false
      });
    }
    return inputs;
  },
  getOutputDefinitions(data) {
    const outputs = [];
    outputs.push({
      dataType: "string",
      id: "response",
      title: "Response"
    });
    if (data.enableCitations) {
      outputs.push({
        dataType: "object[]",
        id: "citations",
        title: "Citations",
        description: "Citations from the response, if any."
      });
    }
    if (data.enableToolUse) {
      outputs.push({
        dataType: "object[]",
        id: "function-calls",
        title: "Function Calls",
        description: "The function calls that were made, if any."
      });
    }
    outputs.push({
      dataType: "chat-message[]",
      id: "all-messages",
      title: "All Messages",
      description: "All messages, with the response appended."
    });
    return outputs;
  },
  getBody(data) {
    var _a;
    const modelName = data.overrideModel ? data.overrideModel : ((_a = anthropicModels[data.model]) == null ? void 0 : _a.displayName) ?? "Unknown Model";
    return import_ts_dedent67.dedent`
      ${modelName}
      ${data.useTopP ? `Top P: ${data.useTopPInput ? "(Using Input)" : data.top_p}` : `Temperature: ${data.useTemperatureInput ? "(Using Input)" : data.temperature}`}
      Max Tokens: ${data.maxTokens}
      ${data.useStop ? `Stop: ${data.useStopInput ? "(Using Input)" : data.stop}` : ""}
    `;
  },
  getEditors() {
    return [
      {
        type: "group",
        label: "Parameters",
        defaultOpen: true,
        editors: [
          {
            type: "dropdown",
            label: "Model",
            dataKey: "model",
            useInputToggleDataKey: "useModelInput",
            options: anthropicModelOptions,
            disableIf: (d) => {
              var _a;
              return !!((_a = d.overrideModel) == null ? void 0 : _a.trim());
            },
            helperMessage: (d) => !!d.overrideModel ? `Model is overridden to: ${d.overrideModel}` : ""
          },
          {
            type: "number",
            label: "Temperature",
            dataKey: "temperature",
            useInputToggleDataKey: "useTemperatureInput",
            min: 0,
            max: 2,
            step: 0.1
          },
          {
            type: "number",
            label: "Top P",
            dataKey: "top_p",
            useInputToggleDataKey: "useTopPInput",
            min: 0,
            max: 1,
            step: 0.1
          },
          {
            type: "toggle",
            label: "Use Top P",
            dataKey: "useTopP",
            useInputToggleDataKey: "useUseTopPInput"
          },
          {
            type: "number",
            label: "Max Tokens",
            dataKey: "maxTokens",
            useInputToggleDataKey: "useMaxTokensInput",
            min: 0,
            max: Number.MAX_SAFE_INTEGER,
            step: 1
          },
          {
            type: "string",
            label: "Stop",
            dataKey: "stop",
            useInputToggleDataKey: "useStopInput"
          }
        ]
      },
      {
        type: "group",
        label: "Tools",
        editors: [
          {
            type: "toggle",
            label: "Enable Tool Use (disables streaming)",
            dataKey: "enableToolUse"
          },
          {
            type: "toggle",
            label: "Enable Citations",
            dataKey: "enableCitations"
          }
        ]
      },
      {
        type: "group",
        label: "Advanced",
        editors: [
          {
            type: "toggle",
            label: "Cache (same inputs, same outputs)",
            dataKey: "cache"
          },
          {
            type: "toggle",
            label: "Use for subgraph partial output",
            dataKey: "useAsGraphPartialOutput"
          },
          {
            type: "string",
            label: "Endpoint",
            dataKey: "endpoint",
            useInputToggleDataKey: "useEndpointInput",
            helperMessage: "Overrides the Anthropic API endpoint. Leave blank to use the default configured endpoint in settings, or https://api.anthropic.com/v1 if none is configured."
          },
          {
            type: "string",
            label: "Override Model",
            dataKey: "overrideModel",
            useInputToggleDataKey: "useOverrideModelInput",
            helperMessage: "Overrides the AI model used for the chat node to this value."
          }
        ]
      }
    ];
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent67.dedent`
        Makes a call to an Anthropic chat model. The settings contains many options for tweaking the model's behavior.
      `,
      infoBoxTitle: "Chat (Anthropic) Node",
      contextMenuTitle: "Chat (Anthropic)",
      group: ["AI"]
    };
  },
  async process(data, inputs, context) {
    if (context.executor === "browser") {
      throw new Error("This node requires using the Node executor");
    }
    const output = {};
    const rawModel = getInputOrData(data, inputs, "model");
    const overrideModel = getInputOrData(data, inputs, "overrideModel");
    const model = overrideModel || rawModel;
    const temperature = data.useTemperatureInput ? coerceTypeOptional(inputs["temperature"], "number") ?? data.temperature : data.temperature;
    const topP = data.useTopPInput ? coerceTypeOptional(inputs["top_p"], "number") ?? data.top_p : data.top_p;
    const useTopP = data.useUseTopPInput ? coerceTypeOptional(inputs["useTopP"], "boolean") ?? data.useTopP : data.useTopP;
    const stop = data.useStopInput ? data.useStop ? coerceTypeOptional(inputs["stop"], "string") ?? data.stop : void 0 : data.stop;
    const tools = data.enableToolUse ? coerceTypeOptional(inputs["tools"], "gpt-function[]") ?? [] : void 0;
    const rivetChatMessages = getChatMessages(inputs);
    const messages = await chatMessagesToClaude3ChatMessages(rivetChatMessages);
    let prompt = messages.reduce((acc, message) => {
      const content = typeof message.content === "string" ? message.content : message.content.filter((c) => c.type === "text").map((c) => c.text ?? "").join("");
      if (message.role === "user") {
        return `${acc}

Human: ${content}`;
      } else if (message.role === "assistant") {
        return `${acc}

Assistant: ${content}`;
      }
      return acc;
    }, "");
    prompt += "\n\nAssistant:";
    const system = data.model.startsWith("claude-3") ? getSystemPrompt(inputs) : void 0;
    const systemInput = inputs["system"];
    const includesCacheBreakpoint = rivetChatMessages.some((m) => m.isCacheBreakpoint) || (systemInput == null ? void 0 : systemInput.type) === "chat-message" && systemInput.value.isCacheBreakpoint;
    let { maxTokens } = data;
    const tokenizerInfo = {
      node: context.node,
      model,
      endpoint: void 0
    };
    const tokenCountEstimate = await context.tokenizer.getTokenCountForString(prompt, tokenizerInfo);
    const modelInfo = anthropicModels[model] ?? {
      maxTokens: Number.MAX_SAFE_INTEGER,
      cost: {
        prompt: 0,
        completion: 0
      }
    };
    if (tokenCountEstimate >= modelInfo.maxTokens) {
      throw new Error(
        `The model ${model} can only handle ${modelInfo.maxTokens} tokens, but ${tokenCountEstimate} were provided in the prompts alone.`
      );
    }
    if (tokenCountEstimate + maxTokens > modelInfo.maxTokens) {
      const message = `The model can only handle a maximum of ${modelInfo.maxTokens} tokens, but the prompts and max tokens together exceed this limit. The max tokens has been reduced to ${modelInfo.maxTokens - tokenCountEstimate}.`;
      addWarning(output, message);
      maxTokens = Math.floor((modelInfo.maxTokens - tokenCountEstimate) * 0.95);
    }
    try {
      return await (0, import_p_retry2.default)(
        async () => {
          var _a, _b, _c, _d, _e, _f, _g, _h;
          const completionOptions = {
            model,
            temperature: useTopP ? void 0 : temperature,
            top_p: useTopP ? topP : void 0,
            max_tokens_to_sample: maxTokens ?? modelInfo.maxTokens,
            stop_sequences: stop ? [stop] : void 0,
            prompt
          };
          const messageOptions = {
            model,
            temperature: useTopP ? void 0 : temperature,
            top_p: useTopP ? topP : void 0,
            max_tokens: maxTokens ?? modelInfo.maxTokens,
            stop_sequences: stop ? [stop] : void 0,
            system,
            messages,
            tools: tools ? tools.map((tool) => ({ name: tool.name, description: tool.description, input_schema: tool.parameters })) : void 0
          };
          const useMessageApi = model.startsWith("claude-3");
          const cacheKey = JSON.stringify(useMessageApi ? messageOptions : completionOptions);
          if (data.cache) {
            const cached = cache2.get(cacheKey);
            if (cached) {
              return cached;
            }
          }
          const startTime = Date.now();
          const apiKey = context.getPluginConfig("anthropicApiKey");
          const defaultApiEndpoint = context.getPluginConfig("anthropicApiEndpoint") ?? "https://api.anthropic.com/v1";
          const configuredEndpoint = getInputOrData(data, inputs, "endpoint");
          const apiEndpoint = (configuredEndpoint == null ? void 0 : configuredEndpoint.trim()) ? configuredEndpoint : defaultApiEndpoint;
          if (useMessageApi && data.enableToolUse) {
            const response = await callMessageApi({
              apiEndpoint,
              apiKey: apiKey ?? "",
              beta: "prompt-caching-2024-07-31",
              ...messageOptions
            });
            const { input_tokens: requestTokens, output_tokens: responseTokens } = response.usage;
            const responseText = response.content.map((c) => c.text).filter(isNotNull).join("");
            output["response"] = {
              type: "string",
              value: responseText
            };
            const citations = response.content.filter((c) => c.type === "text").flatMap((c) => c.citations ?? []);
            output["citations"] = {
              type: "object[]",
              value: citations
            };
            output["raw_response"] = {
              type: "object[]",
              value: response.content
            };
            const functionCalls = response.content.filter((content) => content.name && content.id).map((functionCall) => ({
              name: functionCall.name,
              arguments: functionCall.input,
              // Matches OpenAI ChatNode
              id: functionCall.id
            }));
            if (functionCalls.length > 0) {
              output["function-calls"] = {
                type: "object[]",
                value: functionCalls
              };
            }
            output["all-messages"] = {
              type: "chat-message[]",
              value: [
                ...rivetChatMessages,
                {
                  type: "assistant",
                  message: responseText,
                  function_call: functionCalls.length > 0 ? functionCalls.map((toolCall) => ({
                    name: toolCall.name,
                    arguments: JSON.stringify(toolCall.arguments),
                    id: toolCall.id
                  }))[0] : void 0,
                  function_calls: functionCalls.map((toolCall) => ({
                    name: toolCall.name,
                    arguments: JSON.stringify(toolCall.arguments),
                    id: toolCall.id
                  }))
                }
              ]
            };
            output["requestTokens"] = { type: "number", value: requestTokens ?? tokenCountEstimate };
            const responseTokenCount = responseTokens ?? context.tokenizer.getTokenCountForString(responseText, tokenizerInfo);
            output["responseTokens"] = { type: "number", value: responseTokenCount };
          } else if (useMessageApi) {
            const chunks = streamMessageApi({
              apiEndpoint,
              apiKey: apiKey ?? "",
              signal: context.signal,
              beta: "prompt-caching-2024-07-31",
              ...messageOptions
            });
            const responseParts = [];
            let requestTokens = void 0;
            let responseTokens = void 0;
            const citations = [];
            for await (const chunk of chunks) {
              let completion = "";
              if (chunk.type === "content_block_start") {
                completion = chunk.content_block.text;
              } else if (chunk.type === "content_block_delta") {
                if (chunk.delta.type === "text_delta") {
                  completion = chunk.delta.text;
                } else {
                  citations.push(chunk.delta.citation);
                }
              } else if (chunk.type === "message_start" && ((_b = (_a = chunk.message) == null ? void 0 : _a.usage) == null ? void 0 : _b.input_tokens)) {
                requestTokens = chunk.message.usage.input_tokens;
              } else if (chunk.type === "message_delta" && ((_d = (_c = chunk.delta) == null ? void 0 : _c.usage) == null ? void 0 : _d.output_tokens)) {
                responseTokens = chunk.delta.usage.output_tokens;
              }
              if (!completion) {
                continue;
              }
              responseParts.push(completion);
              output["response"] = {
                type: "string",
                value: responseParts.join("").trim()
              };
              output["citations"] = {
                type: "object[]",
                value: citations
              };
              output["all-messages"] = {
                type: "chat-message[]",
                value: [
                  ...rivetChatMessages,
                  {
                    type: "assistant",
                    message: responseParts.join("").trim(),
                    function_call: void 0,
                    function_calls: void 0
                  }
                ]
              };
              (_e = context.onPartialOutputs) == null ? void 0 : _e.call(context, output);
            }
            if (responseParts.length === 0) {
              throw new Error("No response from Anthropic");
            }
            output["requestTokens"] = { type: "number", value: requestTokens ?? tokenCountEstimate };
            const responseTokenCount = responseTokens ?? await context.tokenizer.getTokenCountForString(responseParts.join(""), tokenizerInfo);
            output["responseTokens"] = { type: "number", value: responseTokenCount };
          } else {
            const chunks = streamChatCompletions2({
              apiEndpoint,
              apiKey: apiKey ?? "",
              signal: context.signal,
              ...completionOptions
            });
            const responseParts = [];
            for await (const chunk of chunks) {
              if (!chunk.completion) {
                continue;
              }
              responseParts.push(chunk.completion);
              output["response"] = {
                type: "string",
                value: responseParts.join("").trim()
              };
              (_f = context.onPartialOutputs) == null ? void 0 : _f.call(context, output);
            }
            if (responseParts.length === 0) {
              throw new Error("No response from Anthropic");
            }
            output["all-messages"] = {
              type: "chat-message[]",
              value: [
                ...rivetChatMessages,
                {
                  type: "assistant",
                  message: responseParts.join("").trim(),
                  function_call: void 0,
                  function_calls: void 0
                }
              ]
            };
            output["requestTokens"] = { type: "number", value: tokenCountEstimate };
            const responseTokenCount = await context.tokenizer.getTokenCountForString(
              responseParts.join(""),
              tokenizerInfo
            );
            output["responseTokens"] = { type: "number", value: responseTokenCount };
          }
          const cost = getCostForTokens2(
            {
              requestTokens: (_g = output["requestTokens"]) == null ? void 0 : _g.value,
              responseTokens: (_h = output["responseTokens"]) == null ? void 0 : _h.value
            },
            model
          );
          if (cost != null) {
            output["cost"] = { type: "number", value: cost };
          }
          const endTime = Date.now();
          const duration = endTime - startTime;
          output["duration"] = { type: "number", value: duration };
          Object.freeze(output);
          cache2.set(cacheKey, output);
          return output;
        },
        {
          forever: true,
          retries: 1e4,
          maxRetryTime: 1e3 * 60 * 5,
          factor: 2.5,
          minTimeout: 500,
          maxTimeout: 5e3,
          randomize: true,
          signal: context.signal,
          onFailedAttempt(err) {
            var _a;
            context.trace(`ChatAnthropicNode failed, retrying: ${err.toString()}`);
            if (context.signal.aborted) {
              throw new Error("Aborted");
            }
            if (err instanceof AnthropicError) {
              if (err.response.status >= 400 && err.response.status < 500) {
                if ((_a = err.responseJson.error) == null ? void 0 : _a.message) {
                  throw new Error(err.responseJson.error.message);
                }
              }
            }
          }
        }
      );
    } catch (error) {
      context.trace(getError(error).stack ?? "Missing stack");
      throw new Error(`Error processing ChatAnthropicNode: ${error.message}`);
    }
  }
};
var chatAnthropicNode = pluginNodeDefinition(ChatAnthropicNodeImpl, "Chat");
function getSystemPrompt(inputs) {
  const systemInput = inputs["system"];
  const system = coerceTypeOptional(systemInput, "string");
  if (system) {
    return [
      {
        type: "text",
        text: system,
        cache_control: (systemInput == null ? void 0 : systemInput.type) === "chat-message" ? systemInput.value.isCacheBreakpoint ? { type: "ephemeral" } : null : null
      }
    ];
  }
  const prompt = inputs["prompt"];
  if (prompt && prompt.type === "chat-message[]") {
    const systemMessages = prompt.value.filter((message) => message.type === "system");
    if (systemMessages.length) {
      const converted = systemMessages.map((message) => {
        return {
          type: "text",
          text: coerceType({ type: "chat-message", value: message }, "string"),
          cache_control: message.isCacheBreakpoint ? { type: "ephemeral" } : null
        };
      });
      return converted;
    }
  }
  return void 0;
}
function getChatMessages(inputs) {
  const prompt = inputs["prompt"];
  if (!prompt) {
    throw new Error("Prompt is required");
  }
  const chatMessages = (0, import_ts_pattern11.match)(prompt).with({ type: "chat-message" }, (p) => [p.value]).with({ type: "chat-message[]" }, (p) => p.value).with({ type: "string" }, (p) => [{ type: "user", message: p.value }]).with({ type: "string[]" }, (p) => p.value.map((v) => ({ type: "user", message: v }))).otherwise((p) => {
    if (isArrayDataValue(p)) {
      const stringValues = p.value.map(
        (v) => coerceType(
          {
            type: getScalarTypeOf(p.type),
            value: v
          },
          "string"
        )
      );
      return stringValues.filter((v) => v != null).map((v) => ({ type: "user", message: v }));
    }
    const coercedMessage = coerceType(p, "chat-message");
    if (coercedMessage != null) {
      return [coercedMessage];
    }
    const coercedString = coerceType(p, "string");
    return coercedString != null ? [{ type: "user", message: coerceType(p, "string") }] : [];
  });
  return chatMessages;
}
async function chatMessagesToClaude3ChatMessages(chatMessages) {
  const messages = (await Promise.all(chatMessages.map(chatMessageToClaude3ChatMessage))).filter(
    isNotNull
  );
  const combinedMessages = messages.reduce((acc, message) => {
    if (message.role === "user" && Array.isArray(message.content) && message.content.length === 1 && message.content[0].type === "tool_result") {
      const last = acc.at(-1);
      if ((last == null ? void 0 : last.role) === "user" && Array.isArray(last.content) && last.content.every((c) => c.type === "tool_result")) {
        const content = last.content.concat(message.content);
        return [...acc.slice(0, -1), { ...last, content }];
      }
    }
    return [...acc, message];
  }, []);
  return combinedMessages;
}
async function chatMessageToClaude3ChatMessage(message) {
  if (message.type === "system") {
    return void 0;
  }
  if (message.type === "function") {
    const content2 = (Array.isArray(message.message) ? message.message : [message.message]).map((m) => typeof m === "string" ? { type: "text", text: m } : void 0).filter(isNotNull);
    return {
      role: "user",
      content: [
        {
          type: "tool_result",
          tool_use_id: message.name,
          content: content2.length === 1 ? content2[0].text : content2,
          cache_control: message.isCacheBreakpoint ? { type: "ephemeral" } : null
        }
      ]
    };
  }
  const content = Array.isArray(message.message) ? await Promise.all(message.message.map((part) => chatMessageContentToClaude3ChatMessage(part))) : [await chatMessageContentToClaude3ChatMessage(message.message)];
  if (message.type === "assistant" && message.function_calls) {
    content.push(
      ...message.function_calls.map((fc) => ({
        type: "tool_use",
        id: fc.id,
        name: fc.name,
        input: JSON.parse(fc.arguments),
        cache_control: message.isCacheBreakpoint ? { type: "ephemeral" } : null
      }))
    );
  } else if (message.type === "assistant" && message.function_call) {
    content.push({
      type: "tool_use",
      id: message.function_call.id,
      name: message.function_call.name,
      input: JSON.parse(message.function_call.arguments),
      cache_control: message.isCacheBreakpoint ? { type: "ephemeral" } : null
    });
  }
  if (message.isCacheBreakpoint) {
    content.at(-1).cache_control = { type: "ephemeral" };
  }
  return {
    role: message.type,
    content
  };
}
async function chatMessageContentToClaude3ChatMessage(content) {
  var _a, _b;
  if (typeof content === "string") {
    return {
      type: "text",
      text: content,
      cache_control: null
      // set later
    };
  }
  switch (content.type) {
    case "image":
      return {
        type: "image",
        source: {
          type: "base64",
          media_type: content.mediaType,
          data: await uint8ArrayToBase64(content.data) ?? ""
        },
        cache_control: null
        // set later
      };
    case "url":
      throw new Error("unable to convert urls for Claude");
    case "document":
      return {
        type: "document",
        source: {
          type: "base64",
          data: await uint8ArrayToBase64(content.data) ?? "",
          media_type: content.mediaType
        },
        title: ((_a = content.title) == null ? void 0 : _a.trim()) ? content.title.trim() : void 0,
        context: ((_b = content.context) == null ? void 0 : _b.trim()) ? content.context.trim() : void 0,
        citations: content.enableCitations ? { enabled: true } : void 0,
        cache_control: null
        // set later
      };
    default:
      assertNever(content);
  }
}
function getCostForTokens2(tokenCounts, model) {
  const modelInfo = anthropicModels[model];
  if (modelInfo == null) {
    return void 0;
  }
  return modelInfo.cost.prompt * tokenCounts.requestTokens + modelInfo.cost.completion * tokenCounts.responseTokens;
}

// src/plugins/anthropic/plugin.ts
var anthropicPlugin = {
  id: "anthropic",
  name: "Anthropic",
  register: (register) => {
    register(chatAnthropicNode);
  },
  configSpec: {
    anthropicApiKey: {
      type: "secret",
      label: "Anthropic API Key",
      description: "The API key for the Anthropic service.",
      pullEnvironmentVariable: "ANTHROPIC_API_KEY",
      helperText: "You may also set the ANTHROPIC_API_KEY environment variable."
    },
    anthropicApiEndpoint: {
      type: "string",
      label: "Anthropic API Endpoint",
      description: "The API endpoint for the Anthropic service.",
      pullEnvironmentVariable: "ANTHROPIC_API_ENDPOINT",
      helperText: "Defaults to https://api.anthropic.com/v1. You may also set the ANTHROPIC_API_ENDPOINT environment variable.",
      default: "https://api.anthropic.com/v1"
    }
  }
};

// src/plugins/anthropic/index.ts
var anthropic_default = anthropicPlugin;

// src/plugins/autoevals/AutoEvalsNode.ts
var import_non_secure76 = require("nanoid/non-secure");
var import_ts_dedent68 = require("ts-dedent");
var import_autoevals = require("autoevals");
var import_ts_pattern12 = require("ts-pattern");
var options = [
  { label: "Factuality", value: "factuality" },
  { label: "Humor", value: "humor" },
  { label: "Security", value: "security" },
  { label: "Possible", value: "possible" },
  { label: "Summary", value: "summary" },
  { label: "Translation", value: "translation" },
  { label: "Battle", value: "battle" },
  { label: "Closed Q&A", value: "closed_q_a" },
  { label: "SQL", value: "sql" }
];
var AutoEvalsNodeImpl = {
  create() {
    const chartNode = {
      type: "autoevals",
      title: "Autoevals",
      id: (0, import_non_secure76.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        evaluatorName: "factuality"
      }
    };
    return chartNode;
  },
  getInputDefinitions(data) {
    const base = [
      {
        id: "output",
        dataType: "string",
        title: "Output"
      },
      {
        id: "expected",
        dataType: "string",
        title: "Expected"
      }
    ];
    const forEvaluator = (0, import_ts_pattern12.match)(data.evaluatorName).with("factuality", () => [
      {
        id: "input",
        dataType: "string",
        title: "Input"
      }
    ]).with("battle", () => [
      {
        id: "instructions",
        dataType: "string",
        title: "Instructions"
      }
    ]).with("closed_q_a", () => [
      {
        id: "input",
        dataType: "string",
        title: "Input"
      },
      {
        id: "criteria",
        dataType: "string",
        title: "Criteria"
      }
    ]).with("humor", () => []).with("possible", () => [
      {
        id: "input",
        dataType: "string",
        title: "Input"
      }
    ]).with("security", () => []).with("summary", () => [
      {
        id: "input",
        dataType: "string",
        title: "Input"
      }
    ]).with("translation", () => [
      {
        id: "input",
        dataType: "string",
        title: "Input"
      },
      {
        id: "language",
        dataType: "string",
        title: "Language"
      }
    ]).with("sql", () => [
      {
        id: "input",
        dataType: "string",
        title: "Input"
      }
    ]).with(void 0, () => []).exhaustive();
    return [...forEvaluator, ...base];
  },
  getOutputDefinitions() {
    return [
      {
        dataType: "number",
        id: "score",
        title: "Score"
      },
      {
        dataType: "string",
        id: "rationale",
        title: "Rationale"
      },
      {
        dataType: "object",
        id: "metadata",
        title: "Metadata"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "dropdown",
        dataKey: "evaluatorName",
        label: "Evaluator",
        options
      }
    ];
  },
  getBody(data) {
    var _a;
    return ((_a = options.find((option) => option.value === data.evaluatorName)) == null ? void 0 : _a.label) ?? "None";
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent68.dedent`
        Evaluates the validity of a response using the autoevals library.
      `,
      infoBoxTitle: "Autoevals Node",
      contextMenuTitle: "Autoevals",
      group: "Custom"
    };
  },
  async process(data, inputs, context) {
    var _a;
    const evaluatorName = data.evaluatorName;
    const output = coerceType(inputs["output"], "string");
    const expected = coerceType(inputs["expected"], "string");
    const baseArgs = {
      output,
      expected,
      openAiApiKey: context.settings.openAiKey,
      openAiOrganizationId: context.settings.openAiOrganization
    };
    const result = await (0, import_ts_pattern12.match)(evaluatorName).with("factuality", () => {
      const input = coerceType(inputs["input"], "string");
      return (0, import_autoevals.Factuality)({ ...baseArgs, input });
    }).with("battle", () => {
      const instructions = coerceType(inputs["instructions"], "string");
      return (0, import_autoevals.Battle)({ ...baseArgs, instructions });
    }).with("closed_q_a", () => {
      const input = coerceType(inputs["input"], "string");
      const criteria = coerceType(inputs["criteria"], "string");
      return (0, import_autoevals.ClosedQA)({ ...baseArgs, input, criteria });
    }).with("humor", () => {
      return (0, import_autoevals.Humor)({ ...baseArgs });
    }).with("possible", () => {
      const input = coerceType(inputs["input"], "string");
      return (0, import_autoevals.Possible)({ ...baseArgs, input });
    }).with("security", () => {
      return (0, import_autoevals.Security)({ ...baseArgs });
    }).with("summary", () => {
      const input = coerceType(inputs["input"], "string");
      return (0, import_autoevals.Summary)({ ...baseArgs, input });
    }).with("translation", () => {
      const input = coerceType(inputs["input"], "string");
      const language = coerceType(inputs["language"], "string");
      return (0, import_autoevals.Translation)({ ...baseArgs, input, language });
    }).with("sql", () => {
      const input = coerceType(inputs["input"], "string");
      return (0, import_autoevals.Sql)({ ...baseArgs, input });
    }).with(void 0, () => {
      throw new Error("Evaluator name is undefined");
    }).exhaustive();
    return {
      ["score"]: {
        type: "number",
        value: result.score
      },
      ["rationale"]: {
        type: "string",
        value: ((_a = result.metadata) == null ? void 0 : _a.rationale) ?? ""
      },
      ["metadata"]: {
        type: "object",
        value: result.metadata
      }
    };
  }
};
var autoEvalsNode = pluginNodeDefinition(AutoEvalsNodeImpl, "Autoevals");

// src/plugins/autoevals/plugin.ts
var autoevalsPlugin = {
  id: "autoevals",
  name: "Autoevals",
  register: (register) => {
    register(autoEvalsNode);
  }
};

// src/plugins/autoevals/index.ts
var autoevals_default = autoevalsPlugin;

// src/plugins/assemblyAi/LemurQaNode.ts
var import_non_secure77 = require("nanoid/non-secure");
var import_ts_dedent69 = require("ts-dedent");

// src/plugins/assemblyAi/lemurHelpers.ts
var import_assemblyai = require("assemblyai");
function getTranscriptIds(inputs) {
  const input = inputs["transcript_ids"];
  if (!input)
    return void 0;
  if (input.type === "string" || input.type === "any" && typeof input.value === "string") {
    return [coerceType(input, "string")];
  } else if (input.type === "string[]" || input.type === "any[]" || input.type === "any" && Array.isArray(input.value)) {
    return coerceType(input, "string[]");
  }
  throw new Error("Transcript IDs must be a string or string[] of transcript IDs.");
}
var userAgent = {
  integration: {
    name: "Rivet",
    version: "1.0.1"
  }
};
function getClient(context) {
  const apiKey = context.getPluginConfig("assemblyAiApiKey");
  if (!apiKey) {
    throw new Error("AssemblyAI API key not set.");
  }
  return new import_assemblyai.AssemblyAI({ apiKey, userAgent });
}
function getLemurParams(inputs, editorData) {
  const params = {
    transcript_ids: getTranscriptIds(inputs),
    input_text: coerceTypeOptional(inputs["input_text"], "string"),
    context: coerceTypeOptional(inputs["context"], "string") || editorData.context || void 0,
    final_model: editorData.final_model && editorData.final_model !== "default" ? editorData.final_model : void 0,
    max_output_size: editorData.max_output_size,
    temperature: editorData.temperature
  };
  return params;
}
var lemurInputDefinitions = [
  {
    id: "transcript_ids",
    dataType: ["string", "string[]", "any", "any[]"],
    title: "Transcript IDs"
  },
  {
    id: "input_text",
    dataType: ["string"],
    title: "Input Text"
  }
];
var lemurEditorDefinitions = [
  {
    type: "dropdown",
    label: "Final Model",
    dataKey: "final_model",
    options: [
      {
        value: "anthropic/claude-3-5-sonnet",
        label: "Claude 3.5 Sonnet (on Anthropic)"
      },
      {
        value: "anthropic/claude-3-opus",
        label: "Claude 3 Opus (on Anthropic)"
      },
      {
        value: "anthropic/claude-3-haiku",
        label: "Claude 3 Haiku (on Anthropic)"
      },
      {
        value: "anthropic/claude-3-sonnet",
        label: "Claude 3 Sonnet (on Anthropic)"
      },
      {
        value: "anthropic/claude-2-1",
        label: "Claude 2.1 (on Anthropic)"
      },
      {
        value: "anthropic/claude-2",
        label: "Claude 2.1 (on Anthropic)"
      },
      {
        value: "default",
        label: "Default"
      },
      {
        value: "anthropic/claude-instant-1-2",
        label: "Claude Instant 1.2 (on Anthropic)"
      },
      {
        value: "basic",
        label: "Basic"
      },
      {
        value: "assemblyai/mistral-7b",
        label: "Mistral 7B (hosted by AssemblyAI)"
      }
    ]
  },
  {
    type: "number",
    label: "Maximum Output Size",
    dataKey: "max_output_size"
  },
  {
    type: "number",
    label: "Temperature",
    dataKey: "temperature",
    min: 0,
    max: 1
  }
];

// src/plugins/assemblyAi/LemurQaNode.ts
var import_assemblyai2 = require("assemblyai");
var LemurQaNodeImpl = {
  create() {
    const chartNode = {
      type: "assemblyAiLemurQa",
      title: "LeMUR Question & Answers",
      id: (0, import_non_secure77.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        final_model: "default"
      }
    };
    return chartNode;
  },
  getInputDefinitions() {
    return [
      ...lemurInputDefinitions,
      {
        id: "questions",
        dataType: ["string", "string[]", "object", "object[]", "any", "any[]"],
        title: "Questions"
      },
      {
        id: "context",
        dataType: "string",
        title: "Context"
      }
    ];
  },
  getOutputDefinitions() {
    return [
      {
        dataType: "object[]",
        id: "response",
        title: "Response"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        label: "Context",
        dataKey: "context"
      },
      ...lemurEditorDefinitions,
      {
        type: "string",
        label: "Questions Answer Format",
        dataKey: "questions_answer_format"
      },
      {
        type: "string",
        label: "Questions Context",
        dataKey: "questions_context"
      },
      {
        type: "string",
        label: "Questions Answer Options",
        dataKey: "questions_answer_options"
      }
    ];
  },
  getBody() {
    return "";
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent69.dedent`Use AssemblyAI LeMUR to ask questions about transcripts`,
      infoBoxTitle: "Use AssemblyAI LeMUR Question & Answer",
      contextMenuTitle: "LeMUR Q&A",
      group: ["AI", "AssemblyAI"]
    };
  },
  async process(data, inputs, context) {
    const client = getClient(context);
    const questions = getQuestions(inputs).map((question) => applyQuestionEditors(data, question));
    const params = {
      questions,
      ...getLemurParams(inputs, data)
    };
    const { response } = await client.lemur.questionAnswer(params);
    return {
      ["response"]: {
        type: "object[]",
        value: response
      }
    };
  }
};
function getQuestions(inputs) {
  const input = inputs["questions"];
  if (!input)
    throw new Error("Questions are required.");
  if (input.type === "string") {
    return [
      {
        question: coerceType(input, "string")
      }
    ];
  } else if (input.type === "string[]") {
    return coerceType(input, "string[]").map((question) => ({ question }));
  } else if (input.type === "object") {
    return [coerceType(input, "object")];
  } else if (input.type === "object[]") {
    return coerceType(input, "object[]");
  } else if (input.type === "any" && typeof input.value === "string") {
    return [
      {
        question: coerceType(input, "string")
      }
    ];
  } else if (input.type === "any" && Array.isArray(input.value) || input.type === "any[]") {
    return input.value.map((question) => {
      if (typeof question === "string") {
        return { question };
      } else if (typeof question === "object") {
        return question;
      } else {
        throw new Error("Question must be a string or object.");
      }
    });
  }
  throw new Error("Questions must be a string, string[], a question object, or an array of question objects.");
}
function applyQuestionEditors(data, question) {
  if (!("answer_format" in question) && data.questions_answer_format) {
    question.answer_format = data.questions_answer_format;
  }
  if (!("answer_options" in question) && data.questions_answer_options) {
    question.answer_options = data.questions_answer_options.split(";");
  }
  if (!("context" in question) && data.questions_context) {
    question.context = data.questions_context;
  }
  return question;
}
var lemurQaNode = pluginNodeDefinition(LemurQaNodeImpl, "LeMUR Q&A");

// src/plugins/assemblyAi/TranscribeAudioNode.ts
var import_non_secure78 = require("nanoid/non-secure");
var import_ts_dedent70 = require("ts-dedent");
var TranscribeAudioNodeImpl = {
  create() {
    const chartNode = {
      type: "assemblyAiTranscribeAudio",
      title: "Transcribe Audio",
      id: (0, import_non_secure78.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {}
    };
    return chartNode;
  },
  getInputDefinitions() {
    return [
      {
        id: "audio",
        dataType: ["audio", "string"],
        title: "Audio"
      }
    ];
  },
  getOutputDefinitions() {
    return [
      {
        dataType: "string",
        id: "text",
        title: "Transcript text"
      },
      {
        dataType: "string",
        id: "id",
        title: "Transcript ID"
      },
      {
        dataType: "object",
        id: "transcript",
        title: "Transcript object"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "code",
        label: "Transcript Parameters (JSON)",
        language: "json",
        dataKey: "transcriptParameters",
        helperMessage: `Configure additional parameters using a JSON object. This will override any other fields you have set.
        For a detailed list of parameters, see [the AssemblyAI API documentation](https://www.assemblyai.com/docs/api-reference/transcripts/submit?utm_source=rivet).`
      }
    ];
  },
  getBody() {
    return "";
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent70.dedent`Use AssemblyAI to transcribe audio`,
      infoBoxTitle: "Transcribe Audio Node",
      contextMenuTitle: "Transcribe Audio",
      group: ["AI", "AssemblyAI"]
    };
  },
  async process(data, inputs, context) {
    const input = inputs["audio"];
    if (!input)
      throw new Error("Audio input is required.");
    const client = getClient(context);
    let audioUrl;
    if (input.type === "audio") {
      const audio = coerceType(inputs["audio"], "audio");
      audioUrl = await client.files.upload(audio.data);
    } else if (input.type === "string" || input.type === "any") {
      audioUrl = coerceType(inputs["audio"], "string");
    } else {
      throw new Error("Audio input must be audio or string containing the audio URL.");
    }
    let transcriptParams = { audio: audioUrl };
    transcriptParams = { ...transcriptParams, ...getAdditionalParameters(data) };
    const transcript = await client.transcripts.transcribe(transcriptParams);
    return {
      ["text"]: {
        type: "string",
        value: transcript.text
      },
      ["id"]: {
        type: "string",
        value: transcript.id
      },
      ["transcript"]: {
        type: "object",
        value: transcript
      }
    };
  }
};
var transcribeAudioNode = pluginNodeDefinition(TranscribeAudioNodeImpl, "Transcribe Audio");
function getAdditionalParameters(data) {
  var _a;
  const transcriptParams = (_a = data.transcriptParameters) == null ? void 0 : _a.trim();
  if (!transcriptParams) {
    return {};
  }
  let transcriptParamsObj;
  try {
    transcriptParamsObj = JSON.parse(transcriptParams);
  } catch (e) {
    throw new Error("The transcript parameters field has to be a valid JSON object, or empty.");
  }
  if (Array.isArray(transcriptParamsObj)) {
    throw new Error("The transcript parameters field should be a JSON object, but is a JSON array");
  }
  return transcriptParamsObj;
}

// src/plugins/assemblyAi/LemurSummaryNode.ts
var import_non_secure79 = require("nanoid/non-secure");
var import_ts_dedent71 = require("ts-dedent");
var import_assemblyai3 = require("assemblyai");
var LemurSummaryNodeImpl = {
  create() {
    const chartNode = {
      type: "assemblyAiLemurSummary",
      title: "LeMUR Summary",
      id: (0, import_non_secure79.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        final_model: "default"
      }
    };
    return chartNode;
  },
  getInputDefinitions() {
    return [
      ...lemurInputDefinitions,
      {
        id: "context",
        dataType: "string",
        title: "Context"
      }
    ];
  },
  getOutputDefinitions() {
    return [
      {
        dataType: "string",
        id: "response",
        title: "Response"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        label: "Context",
        dataKey: "context"
      },
      ...lemurEditorDefinitions
    ];
  },
  getBody() {
    return "";
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent71.dedent`Use AssemblyAI LeMUR Summary to summarize transcripts`,
      infoBoxTitle: "Use AssemblyAI LeMUR Summary",
      contextMenuTitle: "LeMUR Summary",
      group: ["AI", "AssemblyAI"]
    };
  },
  async process(data, inputs, context) {
    const client = getClient(context);
    const params = getLemurParams(inputs, data);
    if (data.answer_format) {
      params.answer_format = data.answer_format;
    }
    const { response } = await client.lemur.summary(params);
    return {
      ["response"]: {
        type: "string",
        value: response
      }
    };
  }
};
var lemurSummaryNode = pluginNodeDefinition(LemurSummaryNodeImpl, "LeMUR Summary");

// src/plugins/assemblyAi/LemurTaskNode.ts
var import_non_secure80 = require("nanoid/non-secure");
var import_ts_dedent72 = require("ts-dedent");
var import_assemblyai4 = require("assemblyai");
var LemurTaskNodeImpl = {
  create() {
    const chartNode = {
      type: "assemblyAiLemurTask",
      title: "LeMUR Task",
      id: (0, import_non_secure80.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        final_model: "default"
      }
    };
    return chartNode;
  },
  getInputDefinitions() {
    return [
      ...lemurInputDefinitions,
      {
        id: "prompt",
        dataType: "string",
        title: "Prompt"
      }
    ];
  },
  getOutputDefinitions() {
    return [
      {
        dataType: "string",
        id: "response",
        title: "Response"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        label: "Prompt",
        dataKey: "prompt"
      },
      ...lemurEditorDefinitions
    ];
  },
  getBody() {
    return "";
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent72.dedent`Use AssemblyAI LeMUR Custom Task to ask anything.`,
      infoBoxTitle: "Use AssemblyAI LeMUR Custom Task",
      contextMenuTitle: "LeMUR Custom Task",
      group: ["AI", "AssemblyAI"]
    };
  },
  async process(data, inputs, context) {
    const client = getClient(context);
    const params = {
      prompt: coerceTypeOptional(inputs["prompt"], "string") || data.prompt || "",
      ...getLemurParams(inputs, data)
    };
    if (!params.prompt)
      throw new Error("Prompt must be provided.");
    const { response } = await client.lemur.task(params);
    return {
      ["response"]: {
        type: "string",
        value: response
      }
    };
  }
};
var lemurTaskNode = pluginNodeDefinition(LemurTaskNodeImpl, "LeMUR Task");

// src/plugins/assemblyAi/LemurActionItemsNode.ts
var import_non_secure81 = require("nanoid/non-secure");
var import_ts_dedent73 = require("ts-dedent");
var LemurActionItemsNodeImpl = {
  create() {
    const chartNode = {
      type: "assemblyAiLemurActionItems",
      title: "LeMUR Action Items",
      id: (0, import_non_secure81.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 250
      },
      data: {
        final_model: "default"
      }
    };
    return chartNode;
  },
  getInputDefinitions() {
    return [
      ...lemurInputDefinitions,
      {
        id: "context",
        dataType: "string",
        title: "Context"
      }
    ];
  },
  getOutputDefinitions() {
    return [
      {
        dataType: "string",
        id: "response",
        title: "Response"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        label: "Context",
        dataKey: "context"
      },
      ...lemurEditorDefinitions
    ];
  },
  getBody() {
    return "";
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent73.dedent`Use AssemblyAI LeMUR Action Items to extract action items`,
      infoBoxTitle: "Use AssemblyAI LeMUR Action Items",
      contextMenuTitle: "LeMUR Action Items",
      group: ["AI", "AssemblyAI"]
    };
  },
  async process(data, inputs, context) {
    const client = getClient(context);
    const params = getLemurParams(inputs, data);
    const { response } = await client.lemur.actionItems(params);
    return {
      ["response"]: {
        type: "string",
        value: response
      }
    };
  }
};
var lemurActionItemsNode = pluginNodeDefinition(LemurActionItemsNodeImpl, "LeMUR Action Items");

// src/plugins/assemblyAi/plugin.ts
var assemblyAiPlugin = {
  id: "assemblyAi",
  name: "AssemblyAI",
  register: (register) => {
    register(transcribeAudioNode);
    register(lemurSummaryNode);
    register(lemurQaNode);
    register(lemurTaskNode);
    register(lemurActionItemsNode);
  },
  configSpec: {
    assemblyAiApiKey: {
      type: "secret",
      label: "AssemblyAI API Key",
      description: "The API key for the AssemblyAI service.",
      pullEnvironmentVariable: "ASSEMBLYAI_API_KEY",
      helperText: "You may also set the ASSEMBLYAI_API_KEY environment variable."
    }
  },
  contextMenuGroups: [
    {
      id: "add-node-group:assemblyai",
      label: "AssemblyAI"
    }
  ]
};

// src/plugins/assemblyAi/index.ts
var assemblyAi_default = assemblyAiPlugin;

// src/plugins/huggingface/nodes/ChatHuggingFace.ts
var import_non_secure82 = require("nanoid/non-secure");
var import_inference = require("@huggingface/inference");
var ChatHuggingFaceNodeImpl = {
  create() {
    return {
      id: (0, import_non_secure82.nanoid)(),
      type: "chatHuggingFace",
      data: {
        model: "",
        temperature: 0.5,
        maxNewTokens: 1024,
        doSample: false
      },
      title: "Chat (Hugging Face)",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: ["AI", "Hugging Face"],
      contextMenuTitle: "Chat (Hugging Face)",
      infoBoxTitle: "Chat (Hugging Face) Node",
      infoBoxBody: "Chat, using the hugging face inference API"
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    inputs.push({
      id: "prompt",
      dataType: "string",
      title: "Prompt",
      required: true
    });
    if (data.useModelInput) {
      inputs.push({
        id: "model",
        dataType: "string",
        title: "Model"
      });
    }
    if (data.useEndpointInput) {
      inputs.push({
        id: "endpoint",
        dataType: "string",
        title: "Endpoint"
      });
    }
    if (data.useTemperatureInput) {
      inputs.push({
        id: "temperature",
        dataType: "number",
        title: "Temperature"
      });
    }
    if (data.useMaxNewTokensInput) {
      inputs.push({
        id: "maxNewTokens",
        dataType: "number",
        title: "Max New Tokens"
      });
    }
    if (data.useDoSampleInput) {
      inputs.push({
        id: "doSample",
        dataType: "boolean",
        title: "Do Sample"
      });
    }
    if (data.useMaxTimeInput) {
      inputs.push({
        id: "maxTime",
        dataType: "number",
        title: "Max Time (s)"
      });
    }
    if (data.useRepetitionPenaltyInput) {
      inputs.push({
        id: "repetitionPenalty",
        dataType: "number",
        title: "Repetition Penalty"
      });
    }
    if (data.useTopPInput) {
      inputs.push({
        id: "topP",
        dataType: "number",
        title: "Top P"
      });
    }
    if (data.useTopKInput) {
      inputs.push({
        id: "topK",
        dataType: "number",
        title: "Top K"
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "output",
        dataType: "string",
        title: "Output"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        label: "Model",
        dataKey: "model",
        useInputToggleDataKey: "useModelInput"
      },
      {
        type: "string",
        label: "Endpoint",
        dataKey: "endpoint",
        useInputToggleDataKey: "useEndpointInput"
      },
      {
        type: "number",
        label: "Temperature (0-100)",
        dataKey: "temperature",
        useInputToggleDataKey: "useTemperatureInput",
        min: 0,
        step: 50,
        allowEmpty: true
      },
      {
        type: "number",
        label: "Max New Tokens",
        dataKey: "maxNewTokens",
        useInputToggleDataKey: "useMaxNewTokensInput",
        min: 0,
        step: 1
      },
      {
        type: "toggle",
        label: "Do Sample",
        dataKey: "doSample",
        useInputToggleDataKey: "useDoSampleInput"
      },
      {
        type: "number",
        label: "Max Time (s)",
        dataKey: "maxTime",
        useInputToggleDataKey: "useMaxTimeInput",
        allowEmpty: true
      },
      {
        type: "number",
        label: "Repetition Penalty (0-100)",
        dataKey: "repetitionPenalty",
        useInputToggleDataKey: "useRepetitionPenaltyInput",
        allowEmpty: true
      },
      {
        type: "number",
        label: "Top P (0-100)",
        dataKey: "topP",
        useInputToggleDataKey: "useTopPInput",
        allowEmpty: true
      },
      {
        type: "number",
        label: "Top K (0-100)",
        dataKey: "topK",
        useInputToggleDataKey: "useTopKInput",
        allowEmpty: true
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      ${data.endpoint || data.useEndpointInput ? `Endpoint: ${data.useEndpointInput ? "(Using Input)" : "Yes"}` : `Model: ${data.useModelInput ? "(Using Input)" : data.model}`}
      ${data.useTemperatureInput ? "Temperature: (Using Input)" : data.temperature != null ? `Temperature: ${data.temperature}` : ""}
      Max New Tokens: ${data.useMaxNewTokensInput ? "(Using Input)" : data.maxNewTokens}
    `;
  },
  async process(data, inputData, context) {
    var _a;
    const accessToken = context.getPluginConfig("huggingFaceAccessToken");
    const prompt = coerceType(inputData["prompt"], "string");
    const endpoint = getInputOrData(data, inputData, "endpoint");
    const model = getInputOrData(data, inputData, "model");
    const temperature = getInputOrData(data, inputData, "temperature", "number");
    const maxNewTokens = getInputOrData(data, inputData, "maxNewTokens", "number");
    const doSample = getInputOrData(data, inputData, "doSample", "boolean");
    const maxTime = getInputOrData(data, inputData, "maxTime", "number");
    const repetitionPenalty = getInputOrData(data, inputData, "repetitionPenalty", "number");
    const topP = getInputOrData(data, inputData, "topP", "number");
    const topK = getInputOrData(data, inputData, "topK", "number");
    const hf = endpoint ? new import_inference.HfInferenceEndpoint(endpoint, accessToken) : new import_inference.HfInference(accessToken);
    const generationStream = hf.textGenerationStream({
      inputs: prompt,
      model,
      parameters: {
        temperature,
        max_new_tokens: maxNewTokens,
        do_sample: doSample,
        max_time: maxTime,
        repetition_penalty: repetitionPenalty,
        top_p: topP,
        top_k: topK
      }
    });
    const parts = [];
    for await (const { token } of generationStream) {
      if (!token.special) {
        parts.push(token.text);
      }
      (_a = context.onPartialOutputs) == null ? void 0 : _a.call(context, {
        ["output"]: {
          type: "string",
          value: parts.join("")
        }
      });
    }
    return {
      ["output"]: {
        type: "string",
        value: parts.join("")
      }
    };
  }
};
var chatHuggingFaceNode = pluginNodeDefinition(ChatHuggingFaceNodeImpl, "Chat (Hugging Face)");

// src/plugins/huggingface/nodes/TextToImageHuggingFace.ts
var import_non_secure83 = require("nanoid/non-secure");
var import_inference2 = require("@huggingface/inference");
var import_ts_dedent74 = require("ts-dedent");
var TextToImageHuggingFaceNodeImpl = {
  create() {
    return {
      id: (0, import_non_secure83.nanoid)(),
      type: "textToImageHuggingFace",
      data: {
        model: "",
        width: 256,
        height: 256,
        negativePrompt: "",
        guidanceScale: 7,
        numInferenceSteps: 3
      },
      title: "Text-to-Image (Hugging Face)",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: ["AI", "Hugging Face"],
      contextMenuTitle: "Text-to-Image (Hugging Face)",
      infoBoxTitle: "Text-to-Image (Hugging Face) Node",
      infoBoxBody: "Use the Hugging Face API to generate an image from text."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    inputs.push({
      id: "prompt",
      dataType: "string",
      title: "Prompt",
      required: true
    });
    if (data.useModelInput) {
      inputs.push({
        id: "model",
        dataType: "string",
        title: "Model"
      });
    }
    if (data.useEndpointInput) {
      inputs.push({
        id: "endpoint",
        dataType: "string",
        title: "Endpoint"
      });
    }
    if (data.useWidthInput) {
      inputs.push({
        id: "width",
        dataType: "number",
        title: "Width"
      });
    }
    if (data.useHeightInput) {
      inputs.push({
        id: "height",
        dataType: "number",
        title: "Height"
      });
    }
    if (data.useNegativePromptInput) {
      inputs.push({
        id: "negativePrompt",
        dataType: "string",
        title: "Negative Prompt"
      });
    }
    if (data.useGuidanceScaleInput) {
      inputs.push({
        id: "guidanceScale",
        dataType: "number",
        title: "Guidance Scale"
      });
    }
    if (data.useNumInferenceStepsInput) {
      inputs.push({
        id: "numInferenceSteps",
        dataType: "number",
        title: "Num Inference Steps"
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "output",
        dataType: "string",
        title: "Output"
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        label: "Model",
        dataKey: "model",
        useInputToggleDataKey: "useModelInput"
      },
      {
        type: "number",
        label: "Width",
        dataKey: "width",
        useInputToggleDataKey: "useWidthInput"
      },
      {
        type: "number",
        label: "Height",
        dataKey: "height",
        useInputToggleDataKey: "useHeightInput"
      },
      {
        type: "string",
        label: "Negative Prompt",
        dataKey: "negativePrompt",
        useInputToggleDataKey: "useNegativePromptInput"
      },
      {
        type: "number",
        label: "Guidance Scale",
        dataKey: "guidanceScale",
        useInputToggleDataKey: "useGuidanceScaleInput",
        min: 0,
        max: 20,
        step: 1
      },
      {
        type: "number",
        label: "Num Inference Steps",
        dataKey: "numInferenceSteps",
        useInputToggleDataKey: "useNumInferenceStepsInput",
        min: 0,
        max: 20,
        step: 1
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent74.dedent`
      Model: ${data.useModelInput ? "(Using Input)" : data.model}
    `;
  },
  async process(data, inputData, context) {
    const accessToken = context.getPluginConfig("huggingFaceAccessToken");
    const prompt = coerceType(inputData["prompt"], "string");
    const endpoint = getInputOrData(data, inputData, "endpoint");
    const model = getInputOrData(data, inputData, "model");
    const width = getInputOrData(data, inputData, "width", "number");
    const height = getInputOrData(data, inputData, "height", "number");
    const negativePrompt = getInputOrData(data, inputData, "negativePrompt") || void 0;
    const guidanceScale = getInputOrData(data, inputData, "guidanceScale", "number");
    const numInferenceSteps = getInputOrData(data, inputData, "numInferenceSteps", "number");
    const hf = endpoint ? new import_inference2.HfInferenceEndpoint(endpoint, accessToken) : new import_inference2.HfInference(accessToken);
    const image = await hf.textToImage({
      inputs: prompt,
      model,
      parameters: {
        width,
        height,
        negative_prompt: negativePrompt,
        guidance_scale: guidanceScale,
        num_inference_steps: numInferenceSteps
      }
    });
    return {
      ["output"]: {
        type: "image",
        value: {
          mediaType: "image/png",
          data: new Uint8Array(await image.arrayBuffer())
        }
      }
    };
  }
};
var textToImageHuggingFaceNode = pluginNodeDefinition(
  TextToImageHuggingFaceNodeImpl,
  "Text-to-Image (Hugging Face)"
);

// src/plugins/huggingface/plugin.ts
var huggingFacePlugin = {
  id: "huggingface",
  name: "Hugging Face",
  configSpec: {
    huggingFaceAccessToken: {
      type: "secret",
      label: "Hugging Face Access Token",
      description: "Your access token for the Hugging Face API.",
      pullEnvironmentVariable: "HUGGING_FACE_ACCESS_TOKEN",
      helperText: "Create at https://huggingface.co/settings/tokens"
    }
  },
  contextMenuGroups: [
    {
      id: "huggingFace",
      label: "Hugging Face"
    }
  ],
  register(register) {
    register(chatHuggingFaceNode);
    register(textToImageHuggingFaceNode);
  }
};

// src/plugins/pinecone/PineconeVectorDatabase.ts
var CryptoJS = __toESM(require("crypto-js"), 1);
var PineconeVectorDatabase = class {
  #apiKey;
  constructor(settings) {
    var _a, _b;
    this.#apiKey = (_b = (_a = settings.pluginSettings) == null ? void 0 : _a.pinecone) == null ? void 0 : _b.pineconeApiKey;
  }
  async store(collection, vector, data, { id }) {
    const collectionDetails = getCollection(coerceType(collection, "string"));
    if (!id) {
      id = CryptoJS.SHA256(vector.value.join(",")).toString(CryptoJS.enc.Hex);
    }
    let metadata = {};
    if (data.type === "object") {
      metadata = data.value;
    } else {
      metadata = { data: data.value };
    }
    const response = await fetch(`${collectionDetails.host}/vectors/upsert`, {
      method: "POST",
      body: JSON.stringify({
        vectors: [
          {
            id,
            values: vector.value,
            metadata
          }
        ],
        ...collectionDetails.options
      }),
      headers: {
        "Content-Type": "application/json",
        Accept: "application/json",
        "api-key": this.#apiKey
      }
    });
    if (response.status !== 200) {
      throw new Error(`Pinecone error: ${await response.text()}`);
    }
  }
  async nearestNeighbors(collection, vector, k) {
    const collectionDetails = getCollection(coerceType(collection, "string"));
    const response = await fetch(`${collectionDetails.host}/query`, {
      method: "POST",
      body: JSON.stringify({
        vector: vector.value,
        topK: k,
        includeMetadata: true,
        ...collectionDetails.options
      }),
      headers: {
        "Content-Type": "application/json",
        Accept: "application/json",
        "api-key": this.#apiKey
      }
    });
    if (response.status !== 200) {
      throw new Error(`Pinecone error: ${await response.text()}`);
    }
    const responseData = await response.json();
    const { matches } = responseData;
    return {
      type: "object[]",
      value: matches.map(({ id, metadata }) => ({ id, data: metadata.data, metadata }))
    };
  }
};
function getCollection(collectionString) {
  let collectionURL;
  if (!collectionString.startsWith("http://") && !collectionString.startsWith("https://")) {
    collectionString = `https://${collectionString}`;
  }
  try {
    collectionURL = new URL(collectionString);
  } catch (error) {
    throw new Error(`Incorrectly formatted Pinecone collection: ${error}`);
  }
  const host = `${collectionURL.protocol}//${collectionURL.host}`;
  const options2 = {};
  if (collectionURL.pathname !== "/") {
    options2.namespace = collectionURL.pathname.slice(1);
  }
  return { host, options: options2 };
}

// src/plugins/pinecone/plugin.ts
var pineconePlugin = {
  id: "pinecone",
  name: "Pinecone",
  register: () => {
    registerIntegration("vectorDatabase", "pinecone", (context) => new PineconeVectorDatabase(context.settings));
  },
  configSpec: {
    pineconeApiKey: {
      type: "secret",
      label: "Pinecone API Key",
      description: "The API key for the Pinecone service.",
      pullEnvironmentVariable: "PINECONE_API_KEY",
      helperText: "You may also set the PINECONE_API_KEY environment variable."
    }
  }
};

// src/plugins/pinecone/index.ts
var pinecone_default = pineconePlugin;

// src/plugins/gentrace/plugin.ts
var import_core = require("@gentrace/core");
var import_lodash_es16 = require("lodash");
var apiKeyConfigSpec = {
  type: "secret",
  label: "Gentrace API Key",
  description: "The API key for the Gentrace service.",
  pullEnvironmentVariable: "GENTRACE_API_KEY",
  helperText: "Create at https://gentrace.ai/settings/api-keys"
};
var gentracePlugin = {
  id: "gentrace",
  name: "Gentrace",
  configSpec: {
    gentraceApiKey: apiKeyConfigSpec
  }
};

// src/plugins/gentrace/index.ts
var gentrace_default = gentracePlugin;

// src/plugins/openai/nodes/CreateThreadNode.ts
var CreateThreadNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiCreateThread",
      data: {
        metadata: [],
        useMetadataInput: false
      },
      title: "Create Thread",
      visualData: {
        x: 0,
        y: 0,
        width: 225
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Create Thread",
      infoBoxTitle: "Create Thread Node",
      infoBoxBody: "Create a new thread for OpenAI assistants."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useThreadIdInput) {
      inputs.push({
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the thread to modify. If not provided, a new thread will be created.",
        required: true
      });
    }
    inputs.push({
      id: "messages",
      dataType: "object[]",
      title: "Messages",
      coerced: true,
      defaultValue: [],
      description: "A list of user messages to start the thread with.",
      required: false
    });
    if (data.useMetadataInput) {
      inputs.push({
        id: "metadata",
        dataType: "object",
        title: "Metadata",
        coerced: true,
        defaultValue: {},
        description: "Metadata to attach to the thread.",
        required: false
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        description: "The ID of the created thread."
      },
      {
        id: "thread",
        dataType: "object",
        title: "Thread",
        description: "The full created thread object."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "keyValuePair",
        dataKey: "metadata",
        useInputToggleDataKey: "useMetadataInput",
        label: "Metadata",
        keyPlaceholder: "Key",
        valuePlaceholder: "Value"
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      ${data.threadId ? `Thread ID: ${data.threadId}` : "Create New Thread"}
      ${data.useMetadataInput ? "(Metadata From Input)" : data.metadata.map(({ key, value }) => `${key}=${value}`).join(", ")}
    `;
  },
  async process(data, inputData, context) {
    const threadId = getInputOrData(data, inputData, "threadId") ?? "";
    const messages = coerceTypeOptional(inputData["messages"], "object[]") ?? [];
    let metadata = data.metadata.reduce(
      (acc, { key, value }) => {
        acc[key] = value;
        return acc;
      },
      {}
    );
    if (data.useMetadataInput && inputData["metadata"]) {
      metadata = coerceTypeOptional(inputData["metadata"], "object");
    }
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const messagesFormatted = messages.map((message) => {
      if (!("role" in message)) {
        throw new Error("Invalid message format.");
      }
      if (message.role !== "user") {
        throw new Error("Only user messages are supported.");
      }
      return message;
    });
    const url = threadId.trim() ? `https://api.openai.com/v1/threads/${threadId}` : "https://api.openai.com/v1/threads";
    if (threadId && messages.length > 0) {
      throw new Error("Cannot provide messages when modifying an existing thread.");
    }
    const response = await fetch(url, {
      method: "POST",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      },
      body: JSON.stringify(
        threadId.trim() ? { metadata } : {
          messages: messagesFormatted,
          metadata
        }
      )
    });
    if (!response.ok) {
      throw new Error("Failed to create thread.");
    }
    const body = await response.json();
    return {
      ["threadId"]: {
        type: "string",
        value: body.id
      },
      ["thread"]: {
        type: "object",
        value: body
      }
    };
  }
};
var createThreadNode = pluginNodeDefinition(CreateThreadNodeImpl, "Create Thread");

// src/plugins/openai/nodes/GetThreadNode.ts
var GetThreadNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiGetThread",
      data: {
        threadId: "",
        useThreadIdInput: true
      },
      title: "Get Thread",
      visualData: {
        x: 0,
        y: 0,
        width: 225
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Get Thread",
      infoBoxTitle: "Get Thread Node",
      infoBoxBody: "Retrieve an existing thread from OpenAI assistants."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useThreadIdInput) {
      inputs.push({
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        description: "The ID of the thread to retrieve.",
        required: true
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "thread",
        dataType: "object",
        title: "Thread",
        description: "The retrieved thread object. If the thread does not exist, this port will not be ran. You can use an If node to test whether the thread exists."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "threadId",
        useInputToggleDataKey: "useThreadIdInput",
        label: "Thread ID",
        autoFocus: true
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      ${data.useThreadIdInput ? "(Thread ID from input)" : `Thread ID: ${data.threadId}`}
    `;
  },
  async process(data, inputData, context) {
    var _a;
    let threadId = data.threadId;
    if (data.useThreadIdInput) {
      threadId = (_a = inputData["threadId"]) == null ? void 0 : _a.value;
      if (!threadId) {
        throw new Error("Thread ID is required.");
      }
    }
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const response = await fetch(`https://api.openai.com/v1/threads/${threadId}`, {
      method: "GET",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    if (response.status === 404) {
      return {
        ["thread"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    if (!response.ok) {
      throw new Error("Failed to get thread.");
    }
    const body = await response.json();
    return {
      ["thread"]: {
        type: "object",
        value: body
      }
    };
  }
};
var getThreadNode = pluginNodeDefinition(GetThreadNodeImpl, "Get Thread");

// src/plugins/openai/nodes/DeleteThreadNode.ts
var DeleteThreadNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiDeleteThread",
      data: {
        threadId: "",
        useThreadIdInput: true
      },
      title: "Delete Thread",
      visualData: {
        x: 0,
        y: 0,
        width: 225
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Delete Thread",
      infoBoxTitle: "Delete Thread Node",
      infoBoxBody: "Delete an existing thread from OpenAI assistants."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useThreadIdInput) {
      inputs.push({
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        description: "The ID of the thread to delete.",
        required: true
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        description: "The ID of the deleted thread."
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      ${data.useThreadIdInput ? "" : `Thread ID: ${data.threadId}`}
    `;
  },
  getEditors() {
    return [];
  },
  async process(data, inputData, context) {
    const threadId = getInputOrData(data, inputData, "threadId");
    if (!threadId) {
      throw new Error("Thread ID is required.");
    }
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const response = await fetch(`https://api.openai.com/v1/threads/${threadId}`, {
      method: "DELETE",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    if (response.status === 404) {
      return {
        ["threadId"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    if (!response.ok) {
      throw new Error("Failed to delete thread.");
    }
    return {
      ["threadId"]: {
        type: "string",
        value: threadId
      }
    };
  }
};
var deleteThreadNode = pluginNodeDefinition(DeleteThreadNodeImpl, "Delete Thread");

// src/plugins/openai/handleOpenaiError.ts
async function handleOpenAIError(response) {
  var _a;
  if (!response.ok) {
    let errorBody;
    try {
      errorBody = await response.json();
    } catch (err) {
      throw new Error(`OpenAI request failed, no JSON body. Status code: ${response.status}`);
    }
    if ((_a = errorBody == null ? void 0 : errorBody.error) == null ? void 0 : _a.message) {
      throw new Error(errorBody.error.message);
    } else {
      throw new Error(`OpenAI request failed with body. Status code: ${response.status}: ${JSON.stringify(errorBody)}`);
    }
  }
}

// src/plugins/openai/nodes/CreateAssistantNode.ts
var CreateAssistantNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiCreateAssistant",
      data: {
        assistantId: "",
        useAssistantIdInput: false,
        model: "",
        useModelInput: false,
        name: "",
        useNameInput: false,
        description: "",
        useDescriptionInput: false,
        instructions: "",
        useInstructionsInput: false,
        tools: [],
        file_ids: [],
        useFileIdsInput: false,
        metadata: [],
        useMetadataInput: false
      },
      title: "Create Assistant",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Create Assistant",
      infoBoxTitle: "Create Assistant Node",
      infoBoxBody: "Create a new assistant for OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useAssistantIdInput) {
      inputs.push({
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the assistant to modify. Leave empty to create a new assistant."
      });
    }
    if (data.useModelInput) {
      inputs.push({
        id: "model",
        dataType: "string",
        title: "Model",
        coerced: true,
        defaultValue: "",
        description: "ID of the model to use.",
        required: false
      });
    }
    if (data.useNameInput) {
      inputs.push({
        id: "name",
        dataType: "string",
        title: "Name",
        coerced: true,
        defaultValue: "",
        description: "The name of the assistant.",
        required: false
      });
    }
    if (data.useDescriptionInput) {
      inputs.push({
        id: "description",
        dataType: "string",
        title: "Description",
        coerced: true,
        defaultValue: "",
        description: "The description of the assistant.",
        required: false
      });
    }
    if (data.useInstructionsInput) {
      inputs.push({
        id: "instructions",
        dataType: "string",
        title: "Instructions",
        coerced: true,
        defaultValue: "",
        description: "The system instructions that the assistant uses.",
        required: false
      });
    }
    inputs.push({
      id: "functions",
      dataType: "object[]",
      title: "Functions",
      coerced: true,
      defaultValue: [],
      description: "A list of GPT functions enabled on the assistant.",
      required: false
    });
    if (data.useFileIdsInput) {
      inputs.push({
        id: "file_ids",
        dataType: "string[]",
        title: "File IDs",
        coerced: true,
        defaultValue: [],
        description: "A list of file IDs attached to this assistant.",
        required: false
      });
    }
    if (data.useMetadataInput) {
      inputs.push({
        id: "metadata",
        dataType: "object",
        title: "Metadata",
        coerced: true,
        defaultValue: {},
        description: "Metadata to attach to the assistant.",
        required: false
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        description: "The ID of the created assistant."
      },
      {
        id: "assistant",
        dataType: "object",
        title: "Assistant",
        description: "The full created assistant object."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "assistantId",
        useInputToggleDataKey: "useAssistantIdInput",
        label: "Existing Assistant ID",
        placeholder: "Existing assistant ID",
        helperMessage: "Leave empty to create a new assistant."
      },
      {
        type: "dropdown",
        dataKey: "model",
        useInputToggleDataKey: "useModelInput",
        label: "Model",
        options: openAiModelOptions,
        defaultValue: "gpt-4-turbo"
      },
      {
        type: "string",
        dataKey: "name",
        useInputToggleDataKey: "useNameInput",
        label: "Name",
        placeholder: "Enter assistant name",
        maxLength: 256,
        autoFocus: true
      },
      {
        type: "string",
        dataKey: "description",
        useInputToggleDataKey: "useDescriptionInput",
        label: "Description",
        placeholder: "Enter assistant description",
        maxLength: 512
      },
      {
        type: "code",
        dataKey: "instructions",
        useInputToggleDataKey: "useInstructionsInput",
        label: "Instructions",
        language: "markdown"
      },
      {
        type: "toggle",
        dataKey: "useCodeInterpreterTool",
        label: "Code Interpreter Tool Enabled"
      },
      {
        type: "toggle",
        dataKey: "useRetrievalTool",
        label: "Retrieval Tool Enabled"
      },
      {
        type: "stringList",
        dataKey: "file_ids",
        useInputToggleDataKey: "useFileIdsInput",
        label: "File IDs"
      },
      {
        type: "keyValuePair",
        dataKey: "metadata",
        useInputToggleDataKey: "useMetadataInput",
        label: "Metadata",
        keyPlaceholder: "Key",
        valuePlaceholder: "Value"
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      Model: ${data.useModelInput ? "(Model From Input)" : data.model}
      Name: ${data.useNameInput ? "(Name From Input)" : data.name}
      Description: ${data.useDescriptionInput ? "(Description From Input)" : data.description}
      File IDs: ${data.useFileIdsInput ? "(File IDs From Input)" : JSON.stringify(data.file_ids)}
      Metadata: ${data.useMetadataInput ? "(Metadata From Input)" : data.metadata.map(({ key, value }) => `${key}=${value}`).join(", ")}

      ${data.useInstructionsInput ? "(Instructions From Input)" : data.instructions}
    `;
  },
  async process(data, inputData, context) {
    var _a, _b;
    const assistantId = getInputOrData(data, inputData, "assistantId");
    let metadata = data.metadata.reduce(
      (acc, { key, value }) => {
        acc[key] = value;
        return acc;
      },
      {}
    );
    if (data.useMetadataInput && inputData["metadata"]) {
      metadata = coerceTypeOptional(inputData["metadata"], "object");
    }
    const functionTools = coerceTypeOptional(inputData["functions"], "gpt-function[]");
    const tools = [...(functionTools == null ? void 0 : functionTools.map((f) => ({ type: "function", function: f }))) ?? []];
    if (data.useCodeInterpreterTool) {
      tools.push({ type: "code_interpreter" });
    }
    if (data.useRetrievalTool) {
      tools.push({ type: "retrieval" });
    }
    const requestBody = {
      model: getInputOrData(data, inputData, "model"),
      name: getInputOrData(data, inputData, "name"),
      description: getInputOrData(data, inputData, "description"),
      instructions: getInputOrData(data, inputData, "instructions"),
      tools,
      file_ids: getInputOrData(data, inputData, "file_ids", "string[]"),
      metadata
    };
    if (!((_a = requestBody.model) == null ? void 0 : _a.trim()) || !((_b = requestBody.name) == null ? void 0 : _b.trim())) {
      throw new Error("Model and name are required.");
    }
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const url = assistantId.trim() ? `https://api.openai.com/v1/assistants/${assistantId}` : "https://api.openai.com/v1/assistants";
    const response = await fetch(url, {
      method: "POST",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      },
      body: JSON.stringify(requestBody)
    });
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["assistantId"]: {
        type: "string",
        value: body.id
      },
      ["assistant"]: {
        type: "object",
        value: body
      }
    };
  }
};
var createAssistantNode = pluginNodeDefinition(CreateAssistantNodeImpl, "Create Assistant");

// src/plugins/openai/nodes/GetAssistantNode.ts
var GetAssistantNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiGetAssistant",
      data: {
        assistantId: "",
        useAssistantIdInput: true
      },
      title: "Get Assistant",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Get Assistant",
      infoBoxTitle: "Get Assistant Node",
      infoBoxBody: "Retrieve an assistant by its ID from OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useAssistantIdInput) {
      inputs.push({
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the assistant to retrieve.",
        required: true
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        description: "The ID of the retrieved assistant."
      },
      {
        id: "assistant",
        dataType: "object",
        title: "Assistant",
        description: "The full retrieved assistant object."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "assistantId",
        useInputToggleDataKey: "useAssistantIdInput",
        label: "Assistant ID",
        placeholder: "Enter assistant ID"
      }
    ];
  },
  getBody(data) {
    return `Assistant ID: ${data.useAssistantIdInput ? "(Assistant ID From Input)" : data.assistantId}`;
  },
  async process(data, inputData, context) {
    const assistantId = getInputOrData(data, inputData, "assistantId");
    if (!(assistantId == null ? void 0 : assistantId.trim())) {
      throw new Error("Assistant ID is required.");
    }
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const response = await fetch(`https://api.openai.com/v1/assistants/${assistantId}`, {
      method: "GET",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    if (response.status === 404) {
      return {
        ["assistantId"]: {
          type: "control-flow-excluded",
          value: void 0
        },
        ["assistant"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["assistantId"]: {
        type: "string",
        value: body.id
      },
      ["assistant"]: {
        type: "object",
        value: body
      }
    };
  }
};
var getAssistantNode = pluginNodeDefinition(GetAssistantNodeImpl, "Get Assistant");

// src/plugins/openai/nodes/ListAssistantsNode.ts
var ListAssistantsNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiListAssistants",
      data: {
        limit: 20,
        useLimitInput: false,
        order: "asc",
        useOrderInput: false,
        after: "",
        useAfterInput: false,
        before: "",
        useBeforeInput: false
      },
      title: "List Assistants",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "List Assistants",
      infoBoxTitle: "List Assistants Node",
      infoBoxBody: "List assistants from OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useLimitInput) {
      inputs.push({
        id: "limit",
        dataType: "number",
        title: "Limit",
        coerced: true,
        defaultValue: 20,
        description: "A limit on the number of objects to be returned.",
        required: false
      });
    }
    if (data.useOrderInput) {
      inputs.push({
        id: "order",
        dataType: "string",
        title: "Order",
        coerced: true,
        defaultValue: "asc",
        description: "Sort order by the created_at timestamp of the objects.",
        required: false
      });
    }
    if (data.useAfterInput) {
      inputs.push({
        id: "after",
        dataType: "string",
        title: "After",
        coerced: true,
        defaultValue: "",
        description: "A cursor for use in pagination.",
        required: false
      });
    }
    if (data.useBeforeInput) {
      inputs.push({
        id: "before",
        dataType: "string",
        title: "Before",
        coerced: true,
        defaultValue: "",
        description: "A cursor for use in pagination.",
        required: false
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "assistants",
        dataType: "object[]",
        title: "Assistants",
        description: "The list of assistants."
      },
      {
        id: "first_id",
        dataType: "string",
        title: "First ID",
        description: "The ID of the first assistant in the list."
      },
      {
        id: "last_id",
        dataType: "string",
        title: "Last ID",
        description: "The ID of the last assistant in the list."
      },
      {
        id: "has_more",
        dataType: "boolean",
        title: "Has More",
        description: "Whether there are more assistants to be retrieved."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "number",
        dataKey: "limit",
        useInputToggleDataKey: "useLimitInput",
        label: "Limit",
        defaultValue: 20,
        min: 1,
        max: 100
      },
      {
        type: "dropdown",
        dataKey: "order",
        useInputToggleDataKey: "useOrderInput",
        label: "Order",
        options: [
          { value: "asc", label: "Ascending" },
          { value: "desc", label: "Descending" }
        ],
        defaultValue: "asc"
      },
      {
        type: "string",
        dataKey: "after",
        useInputToggleDataKey: "useAfterInput",
        label: "After",
        placeholder: "Enter after cursor"
      },
      {
        type: "string",
        dataKey: "before",
        useInputToggleDataKey: "useBeforeInput",
        label: "Before",
        placeholder: "Enter before cursor"
      }
    ];
  },
  getBody(data) {
    var _a, _b;
    return import_ts_dedent.dedent`
      Limit: ${data.useLimitInput ? "(Limit From Input)" : data.limit}, ${data.useOrderInput ? "(Order From Input)" : data.order === "asc" ? "Ascending" : "Descending"}
${data.useAfterInput || ((_a = data.after) == null ? void 0 : _a.trim()) ? `After: ${data.useAfterInput ? "(After From Input)" : data.after}
` : ""}${data.useBeforeInput || ((_b = data.before) == null ? void 0 : _b.trim()) ? `Before: ${data.useBeforeInput ? "(Before From Input)" : data.before}
` : ""}
    `;
  },
  async process(data, inputData, context) {
    const requestQuery = {
      limit: getInputOrData(data, inputData, "limit", "number").toString(),
      order: getInputOrData(data, inputData, "order"),
      after: getInputOrData(data, inputData, "after") || void 0,
      // Mutually exclusive with before, so set to undefined if empty string
      before: getInputOrData(data, inputData, "before") || void 0
    };
    const queryParams = Object.entries(requestQuery).filter(([, value]) => value !== void 0);
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const query = new URLSearchParams(queryParams);
    const url = `https://api.openai.com/v1/assistants?${query.toString()}`;
    const response = await fetch(url, {
      method: "GET",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["assistants"]: {
        type: "object[]",
        value: body.data
      },
      ["first_id"]: {
        type: "string",
        value: body.first_id
      },
      ["last_id"]: {
        type: "string",
        value: body.last_id
      },
      ["has_more"]: {
        type: "boolean",
        value: body.has_more
      }
    };
  }
};
var listAssistantsNode = pluginNodeDefinition(ListAssistantsNodeImpl, "List Assistants");

// src/plugins/openai/nodes/DeleteAssistantNode.ts
var DeleteAssistantNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiDeleteAssistant",
      data: {
        assistantId: "",
        useAssistantIdInput: true
      },
      title: "Delete Assistant",
      visualData: {
        x: 0,
        y: 0,
        width: 275
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Delete Assistant",
      infoBoxTitle: "Delete Assistant Node",
      infoBoxBody: "Delete an existing assistant from OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useAssistantIdInput) {
      inputs.push({
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        description: "The ID of the assistant to delete.",
        required: true
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        description: "The ID of the deleted assistant."
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      ${data.useAssistantIdInput ? "" : `Assistant ID: ${data.assistantId}`}
    `;
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "assistantId",
        useInputToggleDataKey: "useAssistantIdInput",
        label: "Assistant ID",
        placeholder: "Enter assistant ID"
      }
    ];
  },
  async process(data, inputData, context) {
    const assistantId = getInputOrData(data, inputData, "assistantId");
    if (!assistantId) {
      throw new Error("Assistant ID is required.");
    }
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const response = await fetch(`https://api.openai.com/v1/assistants/${assistantId}`, {
      method: "DELETE",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    if (response.status === 404) {
      return {
        ["assistantId"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    await handleOpenAIError(response);
    return {
      ["assistantId"]: {
        type: "string",
        value: assistantId
      }
    };
  }
};
var deleteAssistantNode = pluginNodeDefinition(DeleteAssistantNodeImpl, "Delete Assistant");

// src/plugins/openai/nodes/UploadFileNode.ts
var UploadFileNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiUploadFile",
      data: {
        purpose: "assistants"
      },
      title: "Upload File to OpenAI",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Upload File to OpenAI",
      infoBoxTitle: "Upload File to OpenAI Node",
      infoBoxBody: "Upload a file to OpenAI."
    };
  },
  getInputDefinitions() {
    const inputs = [];
    inputs.push({
      id: "data",
      dataType: "binary",
      title: "Data",
      coerced: true,
      defaultValue: "",
      description: "The binary data of the file to upload.",
      required: true
    });
    inputs.push({
      id: "file-name",
      dataType: "string",
      title: "File Name",
      coerced: true,
      description: "An optional file name to use for the uploaded file.",
      required: false
    });
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "fileId",
        dataType: "string",
        title: "File ID",
        description: "The ID of the uploaded file."
      },
      {
        id: "file",
        dataType: "object",
        title: "File",
        description: "The full uploaded file object."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "dropdown",
        dataKey: "purpose",
        label: "Purpose",
        options: openAIFileUploadPurposeOptions,
        defaultValue: "assistants"
      }
    ];
  },
  getBody(data) {
    var _a;
    return import_ts_dedent.dedent`
      Purpose: ${((_a = openAIFileUploadPurposeOptions.find(({ value }) => value === data.purpose)) == null ? void 0 : _a.label) ?? "Unknown"}
    `;
  },
  async process(data, inputData, context) {
    const purpose = getInputOrData(data, inputData, "purpose");
    const fileData = coerceType(inputData["data"], "binary");
    const fileName = coerceTypeOptional(inputData["file-name"], "string");
    if (!fileData) {
      throw new Error("File data is required.");
    }
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const file = fileName ? new File([fileData], fileName, { type: "application/octet-stream" }) : new Blob([fileData], { type: "application/octet-stream" });
    const formData = new FormData();
    formData.append("purpose", purpose);
    formData.append("file", file);
    const response = await fetch("https://api.openai.com/v1/files", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      },
      body: formData
    });
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["fileId"]: {
        type: "string",
        value: body.id
      },
      ["file"]: {
        type: "object",
        value: body
      }
    };
  }
};
var uploadFileNode = pluginNodeDefinition(UploadFileNodeImpl, "Upload File to OpenAI");

// src/plugins/openai/nodes/ListOpenAIFilesNode.ts
var ListOpenAIFilesNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiListFiles",
      data: {
        purpose: "assistants"
      },
      title: "List OpenAI Files",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "List OpenAI Files",
      infoBoxTitle: "List OpenAI Files Node",
      infoBoxBody: "List files from OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.usePurposeInput) {
      inputs.push({
        id: "purpose",
        dataType: "string",
        title: "Purpose",
        coerced: true,
        defaultValue: "",
        description: "Retrieve only files with the specified purpose."
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "files",
        dataType: "object[]",
        title: "Files",
        description: "The list of files."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "dropdown",
        dataKey: "purpose",
        useInputToggleDataKey: "usePurposeInput",
        label: "Purpose",
        options: openAIFilePurposeOptions,
        defaultValue: "assistants"
      }
    ];
  },
  getBody(data) {
    var _a;
    return import_ts_dedent.dedent`
      Purpose: ${((_a = openAIFilePurposeOptions.find(({ value }) => value === data.purpose)) == null ? void 0 : _a.label) ?? "Unknown"}
    `;
  },
  async process(data, inputData, context) {
    const purpose = getInputOrData(data, inputData, "purpose");
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const url = `https://api.openai.com/v1/files?purpose=${purpose}`;
    const response = await fetch(url, {
      method: "GET",
      headers: {
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["files"]: {
        type: "object[]",
        value: body.data
      }
    };
  }
};
var listOpenAIFilesNode = pluginNodeDefinition(ListOpenAIFilesNodeImpl, "List OpenAI Files");

// src/plugins/openai/nodes/GetOpenAIFileNode.ts
var GetOpenAIFileNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiGetFile",
      data: {
        useFileIdInput: true
      },
      title: "Get OpenAI File",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Get OpenAI File",
      infoBoxTitle: "Get OpenAI File Node",
      infoBoxBody: "Get a specific file from OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useFileIdInput) {
      inputs.push({
        id: "fileId",
        dataType: "string",
        title: "File ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the file to retrieve.",
        required: true
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "file",
        dataType: "object",
        title: "File",
        description: "The retrieved file object."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "fileId",
        useInputToggleDataKey: "useFileIdInput",
        label: "File ID"
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      File ID: ${data.fileId ?? "Unknown"}
    `;
  },
  async process(data, inputData, context) {
    const fileId = getInputOrData(data, inputData, "fileId");
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const url = `https://api.openai.com/v1/files/${fileId}`;
    const response = await fetch(url, {
      method: "GET",
      headers: {
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    if (response.status === 404) {
      return {
        ["file"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["file"]: {
        type: "object",
        value: body
      }
    };
  }
};
var getOpenAIFileNode = pluginNodeDefinition(GetOpenAIFileNodeImpl, "Get OpenAI File");

// src/plugins/openai/nodes/AttachAssistantFileNode.ts
var AttachAssistantFileNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiAttachAssistantFile",
      data: {
        useAssistantIdInput: true,
        useFileIdInput: true
      },
      title: "Attach Assistant File",
      visualData: {
        x: 0,
        y: 0,
        width: 225
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Attach Assistant File",
      infoBoxTitle: "Attach Assistant File Node",
      infoBoxBody: "Attach a file to an OpenAI assistant."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useAssistantIdInput) {
      inputs.push({
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the assistant to attach the file to.",
        required: true
      });
    }
    if (data.useFileIdInput) {
      inputs.push({
        id: "fileId",
        dataType: "string",
        title: "File ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the file to attach.",
        required: true
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "fileId",
        dataType: "string",
        title: "File ID",
        description: "The ID of the attached file."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "assistantId",
        useInputToggleDataKey: "useAssistantIdInput",
        label: "Assistant ID"
      },
      {
        type: "string",
        dataKey: "fileId",
        useInputToggleDataKey: "useFileIdInput",
        label: "File ID"
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      Assistant ID: ${data.useAssistantIdInput ? "(From Input)" : data.assistantId}
      File ID: ${data.useFileIdInput ? "(From Input)" : data.fileId}
    `;
  },
  async process(data, inputData, context) {
    const assistantId = getInputOrData(data, inputData, "assistantId");
    const fileId = getInputOrData(data, inputData, "fileId");
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const url = `https://api.openai.com/v1/assistants/${assistantId}/files`;
    const response = await fetch(url, {
      method: "POST",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      },
      body: JSON.stringify({ file_id: fileId })
    });
    if (response.status === 404) {
      return {
        ["fileId"]: {
          type: "control-flow-excluded",
          value: void 0
        }
      };
    }
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["fileId"]: {
        type: "string",
        value: body.id
      }
    };
  }
};
var attachAssistantFileNode = pluginNodeDefinition(AttachAssistantFileNodeImpl, "Attach Assistant File");

// src/plugins/openai/nodes/CreateThreadMessageNode.ts
var CreateThreadMessageNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiCreateThreadMessage",
      data: {
        threadId: "",
        useThreadIdInput: true,
        file_ids: [],
        useFileIdsInput: false,
        metadata: [],
        useMetadataInput: false
      },
      title: "Create Thread Message",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Create Thread Message",
      infoBoxTitle: "Create Thread Message Node",
      infoBoxBody: "Create a new message for an OpenAI thread."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    inputs.push({
      id: "content",
      dataType: "string",
      title: "Content",
      coerced: true,
      defaultValue: "",
      description: "The content of the message."
    });
    if (data.useThreadIdInput) {
      inputs.push({
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the thread to post the message to.",
        required: true
      });
    }
    if (data.useFileIdsInput) {
      inputs.push({
        id: "file_ids",
        dataType: "string[]",
        title: "File IDs",
        coerced: true,
        defaultValue: [],
        description: "A list of file IDs attached to this message.",
        required: false
      });
    }
    if (data.useMetadataInput) {
      inputs.push({
        id: "metadata",
        dataType: "object",
        title: "Metadata",
        coerced: true,
        defaultValue: {},
        description: "Metadata to attach to the message.",
        required: false
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "messageId",
        dataType: "string",
        title: "Message ID",
        description: "The ID of the created message."
      },
      {
        id: "message",
        dataType: "object",
        title: "Message",
        description: "The full created message object."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "threadId",
        useInputToggleDataKey: "useThreadIdInput",
        label: "Thread ID",
        placeholder: "Enter thread ID",
        helperMessage: "The ID of the thread to post the message to."
      },
      {
        type: "stringList",
        dataKey: "file_ids",
        useInputToggleDataKey: "useFileIdsInput",
        label: "File IDs"
      },
      {
        type: "keyValuePair",
        dataKey: "metadata",
        useInputToggleDataKey: "useMetadataInput",
        label: "Metadata",
        keyPlaceholder: "Key",
        valuePlaceholder: "Value"
      }
    ];
  },
  getBody(data) {
    return import_ts_dedent.dedent`
      Thread ID: ${data.useThreadIdInput ? "(Thread ID From Input)" : data.threadId}${data.useFileIdsInput || data.file_ids.length > 0 ? `File IDs: ${data.useFileIdsInput ? "(File IDs From Input)" : JSON.stringify(data.file_ids)}
` : ""}${data.useMetadataInput || data.metadata.length > 0 ? `Metadata: ${data.useMetadataInput ? "(Metadata From Input)" : data.metadata.map(({ key, value }) => `${key}=${value}`).join(", ")}
` : ""}
    `;
  },
  async process(data, inputData, context) {
    const threadId = getInputOrData(data, inputData, "threadId");
    const content = coerceTypeOptional(inputData["content"], "string") ?? "";
    let metadata = data.metadata.reduce(
      (acc, { key, value }) => {
        acc[key] = value;
        return acc;
      },
      {}
    );
    if (data.useMetadataInput && inputData["metadata"]) {
      metadata = coerceTypeOptional(inputData["metadata"], "object");
    }
    const requestBody = {
      role: "user",
      content,
      file_ids: getInputOrData(data, inputData, "file_ids", "string[]"),
      metadata
    };
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const url = `https://api.openai.com/v1/threads/${threadId}/messages`;
    const response = await fetch(url, {
      method: "POST",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      },
      body: JSON.stringify(requestBody)
    });
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["messageId"]: {
        type: "string",
        value: body.id
      },
      ["message"]: {
        type: "object",
        value: body
      }
    };
  }
};
var createThreadMessageNode = pluginNodeDefinition(CreateThreadMessageNodeImpl, "Create Thread Message");

// src/plugins/openai/nodes/ListThreadMessagesNode.ts
var ListThreadMessagesNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiListThreadMessages",
      data: {
        threadId: "",
        useThreadIdInput: true,
        limit: 20,
        useLimitInput: false,
        order: "asc",
        useOrderInput: false,
        after: "",
        useAfterInput: false,
        before: "",
        useBeforeInput: false
      },
      title: "List Thread Messages",
      visualData: {
        x: 0,
        y: 0,
        width: 300
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "List Thread Messages",
      infoBoxTitle: "List Thread Messages Node",
      infoBoxBody: "List messages from a thread in OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (data.useThreadIdInput) {
      inputs.push({
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the thread to retrieve messages from.",
        required: true
      });
    }
    if (data.useLimitInput) {
      inputs.push({
        id: "limit",
        dataType: "number",
        title: "Limit",
        coerced: true,
        defaultValue: 20,
        description: "A limit on the number of objects to be returned.",
        required: false
      });
    }
    if (data.useOrderInput) {
      inputs.push({
        id: "order",
        dataType: "string",
        title: "Order",
        coerced: true,
        defaultValue: "asc",
        description: "Sort order by the created_at timestamp of the objects.",
        required: false
      });
    }
    if (data.useAfterInput) {
      inputs.push({
        id: "after",
        dataType: "string",
        title: "After",
        coerced: true,
        defaultValue: "",
        description: "A cursor for use in pagination.",
        required: false
      });
    }
    if (data.useBeforeInput) {
      inputs.push({
        id: "before",
        dataType: "string",
        title: "Before",
        coerced: true,
        defaultValue: "",
        description: "A cursor for use in pagination.",
        required: false
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "messages",
        dataType: "object[]",
        title: "Messages",
        description: "The list of messages."
      },
      {
        id: "first_id",
        dataType: "string",
        title: "First ID",
        description: "The ID of the first message in the list."
      },
      {
        id: "last_id",
        dataType: "string",
        title: "Last ID",
        description: "The ID of the last message in the list."
      },
      {
        id: "has_more",
        dataType: "boolean",
        title: "Has More",
        description: "Whether there are more messages to be retrieved."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "string",
        dataKey: "threadId",
        useInputToggleDataKey: "useThreadIdInput",
        label: "Thread ID",
        placeholder: "Enter thread ID"
      },
      {
        type: "number",
        dataKey: "limit",
        useInputToggleDataKey: "useLimitInput",
        label: "Limit",
        defaultValue: 20,
        min: 1,
        max: 100
      },
      {
        type: "dropdown",
        dataKey: "order",
        useInputToggleDataKey: "useOrderInput",
        label: "Order",
        options: [
          { value: "asc", label: "Ascending" },
          { value: "desc", label: "Descending" }
        ],
        defaultValue: "asc"
      },
      {
        type: "string",
        dataKey: "after",
        useInputToggleDataKey: "useAfterInput",
        label: "After",
        placeholder: "Enter after cursor"
      },
      {
        type: "string",
        dataKey: "before",
        useInputToggleDataKey: "useBeforeInput",
        label: "Before",
        placeholder: "Enter before cursor"
      }
    ];
  },
  getBody(data) {
    var _a, _b;
    return import_ts_dedent.dedent`
      Thread ID: ${data.useThreadIdInput ? "(Thread ID From Input)" : data.threadId}
      Limit: ${data.useLimitInput ? "(Limit From Input)" : data.limit}, ${data.useOrderInput ? "(Order From Input)" : data.order === "asc" ? "Ascending" : "Descending"}
${data.useAfterInput || ((_a = data.after) == null ? void 0 : _a.trim()) ? `After: ${data.useAfterInput ? "(After From Input)" : data.after}
` : ""}${data.useBeforeInput || ((_b = data.before) == null ? void 0 : _b.trim()) ? `Before: ${data.useBeforeInput ? "(Before From Input)" : data.before}
` : ""}
    `;
  },
  async process(data, inputData, context) {
    const threadId = getInputOrData(data, inputData, "threadId");
    const requestQuery = {
      limit: getInputOrData(data, inputData, "limit", "number"),
      order: getInputOrData(data, inputData, "order"),
      after: getInputOrData(data, inputData, "after") || void 0,
      // Mutually exclusive with before, so set to undefined if empty string
      before: getInputOrData(data, inputData, "before") || void 0
    };
    const queryParams = Object.entries(requestQuery).filter(([, value]) => value !== void 0);
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    const query = new URLSearchParams(queryParams);
    const url = `https://api.openai.com/v1/threads/${threadId}/messages?${query.toString()}`;
    const response = await fetch(url, {
      method: "GET",
      headers: {
        "OpenAI-Beta": "assistants=v1",
        "Content-Type": "application/json",
        Authorization: `Bearer ${context.settings.openAiKey}`,
        "OpenAI-Organization": context.settings.openAiOrganization ?? ""
      }
    });
    await handleOpenAIError(response);
    const body = await response.json();
    return {
      ["messages"]: {
        type: "object[]",
        value: body.data
      },
      ["first_id"]: {
        type: "string",
        value: body.first_id
      },
      ["last_id"]: {
        type: "string",
        value: body.last_id
      },
      ["has_more"]: {
        type: "boolean",
        value: body.has_more
      }
    };
  }
};
var listThreadMessagesNode = pluginNodeDefinition(ListThreadMessagesNodeImpl, "List Thread Messages");

// src/plugins/openai/nodes/RunThreadNode.ts
var POLL_FREQUENCY = 500;
var RunThreadNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "openaiRunThread",
      data: {
        createThread: true,
        threadId: "",
        useThreadIdInput: false,
        assistantId: "",
        useAssistantIdInput: false,
        model: "",
        useModelInput: false,
        instructions: "",
        useInstructionsInput: false,
        tools: [],
        metadata: [],
        useMetadataInput: false,
        toolCallHandlers: []
      },
      title: "Run Thread",
      visualData: {
        x: 0,
        y: 0,
        width: 400
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Run Thread",
      infoBoxTitle: "Run Thread Node",
      infoBoxBody: "Run a thread for OpenAI."
    };
  },
  getInputDefinitions(data) {
    const inputs = [];
    if (!data.createThread && data.useThreadIdInput) {
      inputs.push({
        id: "threadId",
        dataType: "string",
        title: "Thread ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the thread to run.",
        required: true
      });
    }
    if (data.createThread) {
      inputs.push({
        id: "messages",
        dataType: "object[]",
        title: "Messages",
        coerced: true,
        defaultValue: [],
        description: "A list of user messages to start the thread with.",
        required: false
      });
    }
    if (data.useAssistantIdInput) {
      inputs.push({
        id: "assistantId",
        dataType: "string",
        title: "Assistant ID",
        coerced: true,
        defaultValue: "",
        description: "The ID of the assistant to use.",
        required: true
      });
    }
    if (data.useModelInput) {
      inputs.push({
        id: "model",
        dataType: "string",
        title: "Model",
        coerced: true,
        defaultValue: "",
        description: "ID of the model to use.",
        required: false
      });
    }
    if (data.useInstructionsInput) {
      inputs.push({
        id: "instructions",
        dataType: "string",
        title: "Instructions",
        coerced: true,
        defaultValue: "",
        description: "The system instructions that the assistant uses.",
        required: false
      });
    }
    inputs.push({
      id: "functions",
      dataType: ["gpt-function[]", "gpt-function"],
      title: "Functions",
      coerced: true,
      defaultValue: [],
      description: "A list of GPT functions enabled on the assistant.",
      required: false
    });
    if (data.useMetadataInput) {
      inputs.push({
        id: "metadata",
        dataType: "object",
        title: "Metadata",
        coerced: true,
        defaultValue: {},
        description: "Metadata to attach to the run.",
        required: false
      });
    }
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "runId",
        dataType: "string",
        title: "Run ID",
        description: "The ID of the run."
      },
      {
        id: "run",
        dataType: "object",
        title: "Run",
        description: "The full run object."
      },
      {
        id: "steps",
        dataType: "object[]",
        title: "Steps",
        description: "The list of steps for the run."
      },
      {
        id: "last_step",
        dataType: "object",
        title: "Last Step",
        description: "The last step for the run."
      },
      {
        id: "messages",
        dataType: "object[]",
        title: "Messages",
        description: "The list of messages for the thread."
      },
      {
        id: "last_message",
        dataType: "object",
        title: "Last Message",
        description: "The last message on the thread."
      },
      {
        id: "last_assistant_messages",
        dataType: "object[]",
        title: "Last Assistant Messages",
        description: "The last messages of type `assistant` for the thread."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "toggle",
        dataKey: "createThread",
        label: "Create New Thread"
      },
      {
        type: "string",
        dataKey: "threadId",
        useInputToggleDataKey: "useThreadIdInput",
        label: "Thread ID",
        placeholder: "Enter thread ID",
        helperMessage: "The ID of the thread to run.",
        hideIf: (data) => data.createThread
      },
      {
        type: "string",
        dataKey: "assistantId",
        useInputToggleDataKey: "useAssistantIdInput",
        label: "Assistant ID",
        placeholder: "Enter assistant ID",
        helperMessage: "The ID of the assistant to use. Required."
      },
      {
        type: "dropdown",
        dataKey: "model",
        useInputToggleDataKey: "useModelInput",
        label: "Model",
        options: [
          {
            label: "Default",
            value: ""
          },
          ...openAiModelOptions
        ],
        defaultValue: "",
        helperMessage: "The GPT model to use for the run. If default, the model of the assistant will be used."
      },
      {
        type: "code",
        dataKey: "instructions",
        useInputToggleDataKey: "useInstructionsInput",
        label: "Instructions",
        language: "markdown",
        helperMessage: "The instructions for the assistant to use for the run. If empty, the instructions of the assistant will be used."
      },
      {
        type: "toggle",
        dataKey: "useCodeInterpreterTool",
        label: "Code Interpreter Tool Enabled",
        helperMessage: "Note: Only enabled if functions are provided. Otherwise, the assistant's settings will be used."
      },
      {
        type: "toggle",
        dataKey: "useRetrievalTool",
        label: "Retrieval Tool Enabled",
        helperMessage: "Note: Only enabled if functions are provided. Otherwise, the assistant's settings will be used."
      },
      {
        type: "custom",
        customEditorId: "ToolCallHandlers",
        label: "Tool Call Handlers",
        dataKey: "toolCallHandlers",
        helperMessage: "Handles for each function tool call that the assistant has access to. Make sure you provide a subgraph handler for every possible tool call that can be performed. A special `unknown` handler can be used as a fallback for unconfigured tool calls."
      },
      {
        type: "keyValuePair",
        dataKey: "metadata",
        useInputToggleDataKey: "useMetadataInput",
        label: "Metadata",
        keyPlaceholder: "Key",
        valuePlaceholder: "Value"
      },
      {
        type: "graphSelector",
        dataKey: "onMessageCreationSubgraphId",
        label: "On Message Creation Subgraph",
        helperMessage: "A subgraph to run when a message is created. The message will be available as `input` or `message` in the subgraph."
      }
    ];
  },
  getBody(data, context) {
    var _a, _b;
    let body = import_ts_dedent.dedent`
      Assistant ID: ${data.useAssistantIdInput ? "(Assistant ID From Input)" : data.assistantId}
    `;
    const additional = [];
    if (data.createThread) {
      additional.push("Create New Thread");
    } else {
      additional.push(`Thread ID: ${data.useThreadIdInput ? "(Thread ID From Input)" : data.threadId}`);
    }
    if (data.useModelInput || data.model) {
      additional.push(`Model: ${data.useModelInput ? "(Model From Input)" : data.model}`);
    }
    if (data.useInstructionsInput || ((_a = data.instructions) == null ? void 0 : _a.trim())) {
      additional.push(`Instructions: ${data.useInstructionsInput ? "(Instructions From Input)" : data.instructions}`);
    }
    if (data.useMetadataInput || data.metadata.length > 0) {
      additional.push(
        `Metadata: ${data.useMetadataInput ? "(Metadata From Input)" : data.metadata.map(({ key, value }) => `${key}=${value}`).join(", ")}`
      );
    }
    if (data.useCodeInterpreterTool) {
      additional.push("Code Interpreter Tool Enabled");
    }
    if (data.useRetrievalTool) {
      additional.push("Retrieval Tool Enabled");
    }
    if (data.toolCallHandlers.length > 0) {
      additional.push("Tool Call Handlers:");
      data.toolCallHandlers.forEach(({ key, value }) => {
        var _a2;
        const subgraphName = ((_a2 = context.project.graphs[value]) == null ? void 0 : _a2.metadata.name) ?? "Unknown Subgraph";
        additional.push(`    ${key || "(MISSING!)"} -> ${subgraphName}`);
      });
    }
    if (data.onMessageCreationSubgraphId) {
      const subgraphName = ((_b = context.project.graphs[data.onMessageCreationSubgraphId]) == null ? void 0 : _b.metadata.name) ?? "Unknown Subgraph";
      additional.push(`On Message Creation Subgraph: ${subgraphName}`);
    }
    body = `${body}
${additional.join("\n")}`;
    return body;
  },
  async process(data, inputData, context) {
    const threadId = getInputOrData(data, inputData, "threadId");
    const assistantId = getInputOrData(data, inputData, "assistantId");
    let metadata = data.metadata.reduce(
      (acc, { key, value }) => {
        acc[key] = value;
        return acc;
      },
      {}
    );
    if (data.useMetadataInput && inputData["metadata"]) {
      metadata = coerceTypeOptional(inputData["metadata"], "object");
    }
    const functionTools = coerceTypeOptional(inputData["functions"], "gpt-function[]");
    const tools = [...(functionTools == null ? void 0 : functionTools.map((f) => ({ type: "function", function: f }))) ?? []];
    if (tools.length) {
      if (data.useCodeInterpreterTool) {
        tools.push({ type: "code_interpreter" });
      }
      if (data.useRetrievalTool) {
        tools.push({ type: "retrieval" });
      }
    }
    const requestBody = {
      assistant_id: assistantId,
      model: getInputOrData(data, inputData, "model"),
      instructions: getInputOrData(data, inputData, "instructions"),
      tools: tools.length > 0 ? tools : void 0,
      metadata
    };
    if (!context.settings.openAiKey) {
      throw new Error("OpenAI key is not set.");
    }
    let response;
    const coerceToThreadMessage = (value) => {
      if (!(value == null ? void 0 : value.value)) {
        return void 0;
      }
      if (value.type === "string" || typeof value.value === "string") {
        return { role: "user", content: value.value };
      }
      if (typeof value.value === "object") {
        if (!("role" in value.value)) {
          throw new Error("Invalid message format - missing role.");
        }
        if (value.value.role !== "user") {
          throw new Error("Only user messages are supported.");
        }
        return value.value;
      }
      return { role: "user", content: coerceTypeOptional(value, "string") ?? "" };
    };
    if (data.createThread) {
      const messagesInput = inputData["messages"];
      const messages = messagesInput ? arrayizeDataValue(unwrapDataValue(messagesInput)).map((message) => coerceToThreadMessage(message)) : [];
      response = await fetch("https://api.openai.com/v1/threads/runs", {
        method: "POST",
        headers: {
          "OpenAI-Beta": "assistants=v1",
          "Content-Type": "application/json",
          Authorization: `Bearer ${context.settings.openAiKey}`,
          "OpenAI-Organization": context.settings.openAiOrganization ?? ""
        },
        body: JSON.stringify({
          ...requestBody,
          thread: {
            messages
            // Thread metadata?
          }
        })
      });
    } else {
      response = await fetch(`https://api.openai.com/v1/threads/${threadId}/runs`, {
        method: "POST",
        headers: {
          "OpenAI-Beta": "assistants=v1",
          "Content-Type": "application/json",
          Authorization: `Bearer ${context.settings.openAiKey}`,
          "OpenAI-Organization": context.settings.openAiOrganization ?? ""
        },
        body: JSON.stringify(requestBody)
      });
    }
    await handleOpenAIError(response);
    const body = await response.json();
    const pollController = new AbortController();
    const pollRunSteps = async (onNewStepCompleted) => {
      let lastCompletedAt = 0;
      const pollControllerAborted = new Promise(
        (resolve) => pollController.signal.addEventListener("abort", () => resolve(void 0))
      );
      const mainGraphAborted = new Promise(
        (_, reject) => context.signal.addEventListener("abort", () => reject(new Error("aborted")))
      );
      while (!pollController.signal.aborted) {
        await Promise.race([
          // Poll frequency
          new Promise((resolve) => setTimeout(resolve, POLL_FREQUENCY)),
          pollControllerAborted,
          mainGraphAborted
        ]);
        const query = new URLSearchParams({
          limit: "3",
          order: "desc"
        });
        const url = `https://api.openai.com/v1/threads/${body.thread_id}/runs/${body.id}/steps?${query.toString()}`;
        const response2 = await fetch(url, {
          method: "GET",
          headers: {
            "OpenAI-Beta": "assistants=v1",
            "Content-Type": "application/json",
            Authorization: `Bearer ${context.settings.openAiKey}`,
            "OpenAI-Organization": context.settings.openAiOrganization ?? ""
          }
        });
        await handleOpenAIError(response2);
        const stepListBody = await response2.json();
        const newSteps = stepListBody.data.filter(
          (step) => step.completed_at != null && step.completed_at > lastCompletedAt
        );
        if (newSteps.length > 0) {
          lastCompletedAt = newSteps[0].completed_at;
        }
        for (const newStep of newSteps) {
          await onNewStepCompleted(newStep);
        }
      }
    };
    const pollRunStepsPromise = data.onMessageCreationSubgraphId ? pollRunSteps(async (step) => {
      if (step.step_details.type !== "message_creation") {
        return;
      }
      const messageId = step.step_details.message_creation.message_id;
      const messageResponse = await fetch(
        `https://api.openai.com/v1/threads/${body.thread_id}/messages/${messageId}`,
        {
          method: "GET",
          headers: {
            "OpenAI-Beta": "assistants=v1",
            "Content-Type": "application/json",
            Authorization: `Bearer ${context.settings.openAiKey}`,
            "OpenAI-Organization": context.settings.openAiOrganization ?? ""
          }
        }
      );
      await handleOpenAIError(messageResponse);
      const messageBody = await messageResponse.json();
      const inputs = {
        input: {
          type: "object[]",
          value: messageBody.content
        },
        message: {
          type: "object",
          value: messageBody
        },
        message_id: {
          type: "string",
          value: messageBody.id
        },
        thread_id: {
          type: "string",
          value: messageBody.thread_id
        }
      };
      const subprocessor = context.createSubProcessor(data.onMessageCreationSubgraphId, {
        signal: context.signal
      });
      await subprocessor.processGraph(context, inputs, context.contextValues);
    }) : Promise.resolve();
    let latestBody = body;
    try {
      while (latestBody.status === "in_progress" || latestBody.status === "queued" || latestBody.status === "requires_action") {
        const runResponse = await fetch(`https://api.openai.com/v1/threads/${body.thread_id}/runs/${body.id}`, {
          method: "GET",
          headers: {
            "OpenAI-Beta": "assistants=v1",
            "Content-Type": "application/json",
            Authorization: `Bearer ${context.settings.openAiKey}`,
            "OpenAI-Organization": context.settings.openAiOrganization ?? ""
          }
        });
        await handleOpenAIError(runResponse);
        latestBody = await runResponse.json();
        if (latestBody.status === "requires_action") {
          const toolCalls = latestBody.required_action.submit_tool_outputs.tool_calls;
          const toolCallOutputs = await Promise.all(
            toolCalls.map(async (toolCall) => {
              var _a, _b;
              let inputArguments = {};
              try {
                inputArguments = JSON.parse(toolCall.function.arguments);
              } catch (err) {
              }
              const inputs = {
                run_id: {
                  type: "string",
                  value: latestBody.id
                },
                run: {
                  type: "object",
                  value: latestBody
                },
                tool_call_id: {
                  type: "string",
                  value: toolCall.id
                },
                name: {
                  type: "string",
                  value: toolCall.function.name
                },
                arguments: {
                  type: "object",
                  value: inputArguments
                },
                input: {
                  type: "object",
                  value: inputArguments
                }
              };
              let handlerSubgraphId = (_a = data.toolCallHandlers.find(({ key }) => key === toolCall.function.name)) == null ? void 0 : _a.value;
              if (!handlerSubgraphId) {
                handlerSubgraphId = (_b = data.toolCallHandlers.find(({ key }) => key === "unknown")) == null ? void 0 : _b.value;
              }
              if (!handlerSubgraphId) {
                throw new Error(`No handler found for tool call: ${toolCall.function.name}`);
              }
              const subprocessor = context.createSubProcessor(handlerSubgraphId, { signal: context.signal });
              const outputs = await subprocessor.processGraph(context, inputs, context.contextValues);
              const outputString = coerceTypeOptional(outputs.output, "string");
              return outputString ?? "";
            })
          );
          const mappedToolCallOuptuts = toolCalls.map((toolCall, i) => ({
            tool_call_id: toolCall.id,
            output: toolCallOutputs[i]
          }));
          const submitResponse = await fetch(
            `https://api.openai.com/v1/threads/${body.thread_id}/runs/${body.id}/submit_tool_outputs`,
            {
              method: "POST",
              headers: {
                "OpenAI-Beta": "assistants=v1",
                "Content-Type": "application/json",
                Authorization: `Bearer ${context.settings.openAiKey}`,
                "OpenAI-Organization": context.settings.openAiOrganization ?? ""
              },
              body: JSON.stringify({
                tool_outputs: mappedToolCallOuptuts
              })
            }
          );
          await handleOpenAIError(submitResponse);
        }
        await Promise.race([
          new Promise((resolve) => setTimeout(resolve, POLL_FREQUENCY)),
          new Promise((_, reject) => context.signal.addEventListener("abort", () => reject(new Error("aborted"))))
        ]);
      }
      if (latestBody.status === "cancelled" || latestBody.status === "cancelling" || latestBody.status === "expired" || latestBody.status === "failed") {
        throw new Error(`Run failed with status: ${latestBody.status}`);
      }
      const listStepsQuery = new URLSearchParams({
        limit: "20",
        order: "desc"
      });
      const listStepsResponsePromise = await fetch(
        `https://api.openai.com/v1/threads/${body.thread_id}/runs/${body.id}/steps?${listStepsQuery.toString()}`,
        {
          method: "GET",
          headers: {
            "OpenAI-Beta": "assistants=v1",
            "Content-Type": "application/json",
            Authorization: `Bearer ${context.settings.openAiKey}`,
            "OpenAI-Organization": context.settings.openAiOrganization ?? ""
          }
        }
      );
      const getMessagesQuery = new URLSearchParams({
        limit: "20",
        order: "desc"
      });
      const messagesResponsePromise = await fetch(
        `https://api.openai.com/v1/threads/${body.thread_id}/messages?${getMessagesQuery.toString()}`,
        {
          method: "GET",
          headers: {
            "OpenAI-Beta": "assistants=v1",
            "Content-Type": "application/json",
            Authorization: `Bearer ${context.settings.openAiKey}`,
            "OpenAI-Organization": context.settings.openAiOrganization ?? ""
          }
        }
      );
      const [listStepsResponse, messagesResponse] = await Promise.all([
        listStepsResponsePromise,
        messagesResponsePromise
      ]);
      await handleOpenAIError(listStepsResponse);
      await handleOpenAIError(messagesResponse);
      const listStepsBody = await listStepsResponse.json();
      const messagesForThread = await messagesResponse.json();
      const lastUserMessageIndex = messagesForThread.data.findIndex((message) => message.role === "user");
      const lastAssistantMessages = messagesForThread.data.slice(0, lastUserMessageIndex);
      return {
        ["runId"]: {
          type: "string",
          value: latestBody.id
        },
        ["run"]: {
          type: "object",
          value: latestBody
        },
        ["steps"]: {
          type: "object[]",
          value: listStepsBody.data
        },
        ["last_step"]: {
          type: "object",
          value: listStepsBody.data[0]
        },
        ["messages"]: {
          type: "object[]",
          value: messagesForThread.data
        },
        ["last_message"]: {
          type: "object",
          value: messagesForThread.data[0]
        },
        ["last_assistant_messages"]: {
          type: "object[]",
          value: lastAssistantMessages
        }
      };
    } finally {
      pollController.abort();
      await pollRunStepsPromise;
    }
  }
};
var runThreadNode = pluginNodeDefinition(RunThreadNodeImpl, "Run Thread");

// src/plugins/openai/nodes/ThreadMessageNode.ts
var import_lodash_es17 = require("lodash");
var ThreadMessageNodeImpl = {
  create() {
    return {
      id: newId(),
      type: "threadMessage",
      data: {
        text: "{{input}}",
        fileIds: [],
        useFileIdsInput: false,
        metadata: [],
        useMetadataInput: false
      },
      title: "Thread Message",
      visualData: {
        x: 0,
        y: 0,
        width: 225
      }
    };
  },
  getUIData() {
    return {
      group: "OpenAI",
      contextMenuTitle: "Thread Message",
      infoBoxTitle: "Thread Message Node",
      infoBoxBody: "Create a new message for a thread."
    };
  },
  getInputDefinitions(data) {
    let inputs = [];
    if (data.useFileIdsInput) {
      inputs.push({
        id: "fileIds",
        dataType: "string[]",
        title: "File IDs",
        coerced: true,
        defaultValue: [],
        description: "The IDs of the files to attach to the message.",
        required: false
      });
    }
    if (data.useMetadataInput) {
      inputs.push({
        id: "metadata",
        dataType: "object",
        title: "Metadata",
        coerced: true,
        defaultValue: {},
        description: "Metadata to attach to the message.",
        required: false
      });
    }
    const inputNames = [...new Set(data.text.match(/\{\{([^}]+)\}\}/g))];
    inputs = [
      ...inputs,
      ...(inputNames == null ? void 0 : inputNames.map((inputName) => {
        return {
          // id and title should not have the {{ and }}
          id: inputName.slice(2, -2),
          title: inputName.slice(2, -2),
          dataType: "string",
          required: false
        };
      })) ?? []
    ];
    return inputs;
  },
  getOutputDefinitions() {
    return [
      {
        id: "message",
        dataType: "object",
        title: "Message",
        description: "The created message."
      }
    ];
  },
  getEditors() {
    return [
      {
        type: "code",
        label: "Text",
        dataKey: "text",
        language: "prompt-interpolation-markdown",
        theme: "prompt-interpolation"
      },
      {
        type: "keyValuePair",
        dataKey: "metadata",
        useInputToggleDataKey: "useMetadataInput",
        label: "Metadata",
        keyPlaceholder: "Key",
        valuePlaceholder: "Value"
      },
      {
        type: "stringList",
        dataKey: "fileIds",
        useInputToggleDataKey: "useFileIdsInput",
        label: "File IDs",
        placeholder: "File ID"
      }
    ];
  },
  getBody(data) {
    return {
      type: "colorized",
      text: data.text.split("\n").slice(0, 15).join("\n").trim(),
      language: "prompt-interpolation-markdown",
      theme: "prompt-interpolation"
    };
  },
  async process(data, inputData) {
    const text = getInputOrData(data, inputData, "text", "string");
    const fileIds = getInputOrData(data, inputData, "fileIds", "string[]") ?? [];
    let metadata = data.metadata.reduce(
      (acc, { key, value }) => {
        acc[key] = value;
        return acc;
      },
      {}
    );
    if (data.useMetadataInput && inputData["metadata"]) {
      metadata = coerceTypeOptional(inputData["metadata"], "object");
    }
    const inputMap = (0, import_lodash_es17.mapValues)(inputData, (input) => coerceType(input, "string"));
    const interpolated = interpolate(text, inputMap);
    return {
      ["message"]: {
        type: "object",
        value: {
          role: "user",
          content: interpolated,
          file_ids: fileIds,
          metadata
        }
      }
    };
  }
};
var threadMessageNode = pluginNodeDefinition(ThreadMessageNodeImpl, "Thread Message");

// src/plugins/openai/plugin.ts
var openAIPlugin = {
  id: "openai",
  name: "OpenAI",
  configSpec: {},
  contextMenuGroups: [
    {
      id: "openai",
      label: "OpenAI"
    }
  ],
  register(register) {
    register(createThreadNode);
    register(getThreadNode);
    register(deleteThreadNode);
    register(createAssistantNode);
    register(getAssistantNode);
    register(listAssistantsNode);
    register(deleteAssistantNode);
    register(uploadFileNode);
    register(listOpenAIFilesNode);
    register(getOpenAIFileNode);
    register(attachAssistantFileNode);
    register(createThreadMessageNode);
    register(listThreadMessagesNode);
    register(runThreadNode);
    register(threadMessageNode);
  }
};

// src/plugins/google/google.ts
var import_ts_pattern13 = require("ts-pattern");
var googleModelsDeprecated = {
  "gemini-pro": {
    maxTokens: 32760,
    cost: {
      prompt: NaN,
      completion: NaN
    },
    displayName: "Gemini Pro"
  },
  "gemini-pro-vision": {
    maxTokens: 16384,
    cost: {
      prompt: NaN,
      completion: NaN
    },
    displayName: "Gemini Pro Vision"
  }
};
var generativeAiGoogleModels = {
  "gemini-2.0-flash-001": {
    maxTokens: 1048576,
    cost: {
      prompt: 0.15 / 1e3,
      completion: 0.6 / 1e3
    },
    displayName: "Gemini 2.0 Flash"
  },
  "gemini-2.0-pro-exp-02-05": {
    maxTokens: 2097152,
    cost: {
      prompt: 0,
      // Unknown
      completion: 0
      // Unknown
    },
    displayName: "Gemini 2.0 Pro"
  },
  "gemini-2.0-flash-lite-preview-02-05": {
    maxTokens: 1048576,
    cost: {
      prompt: 0.075 / 1e3,
      completion: 0.3 / 1e3
    },
    displayName: "Gemini 2.0 Flash Lite"
  },
  "gemini-2.0-flash-thinking-exp-01-21": {
    maxTokens: 1048576,
    cost: {
      prompt: 0,
      // Unknown
      completion: 0
      // Unknown
    },
    displayName: "Gemini 2.0 Flash Thinking"
  },
  "gemini-1.5-flash": {
    maxTokens: 1048576,
    cost: {
      prompt: 0,
      // It's per-character wtf
      completion: 0
      // It's per-character
    },
    displayName: "Gemini 1.5 Flash"
  },
  "gemini-1.5-pro": {
    maxTokens: 2097152,
    cost: {
      prompt: 0,
      // It's per-character wtf
      completion: 0
      // It's per-character
    },
    displayName: "Gemini 1.5 Pro"
  },
  "gemini-1.0-pro": {
    maxTokens: 32760,
    cost: {
      prompt: 0,
      // It's per-character wtf
      completion: 0
      // 1It's per-character
    },
    displayName: "Gemini 1.0 Pro"
  },
  "gemini-1.0-pro-vision": {
    maxTokens: 16384,
    cost: {
      prompt: 0,
      // It's per-character wtf
      completion: 0
      // It's per-character
    },
    displayName: "Gemini 1.0 Pro Vision"
  }
};
var googleModelOptionsDeprecated = Object.entries(googleModelsDeprecated).map(([id, { displayName }]) => ({
  value: id,
  label: displayName
}));
var generativeAiOptions = Object.entries(generativeAiGoogleModels).map(([id, { displayName }]) => ({
  value: id,
  label: displayName
}));
async function* streamGenerativeAi({
  apiKey,
  model,
  systemPrompt,
  prompt,
  maxOutputTokens,
  temperature,
  topP,
  topK,
  signal
}) {
  var _a, _b, _c;
  const { GoogleGenerativeAI } = await import("@google/generative-ai");
  const genAi = new GoogleGenerativeAI(apiKey);
  const genaiModel = genAi.getGenerativeModel({
    model,
    systemInstruction: systemPrompt,
    generationConfig: {
      maxOutputTokens,
      temperature,
      topP,
      topK
    }
  });
  const contentParts = prompt.map(({ role, parts }) => {
    return {
      role,
      parts: parts.map((part) => {
        return (0, import_ts_pattern13.match)(part).with({ text: import_ts_pattern13.P.string }, ({ text }) => {
          return { text };
        }).with({ inline_data: import_ts_pattern13.P.any }, ({ inline_data: inlineData }) => {
          return {
            inlineData: {
              data: inlineData.data,
              mimeType: inlineData.mime_type
            }
          };
        }).exhaustive();
      })
    };
  });
  const result = await genaiModel.generateContentStream(
    {
      contents: contentParts
    },
    { signal }
  );
  for await (const chunk of result.stream) {
    if (chunk.candidates) {
      yield {
        completion: ((_b = (_a = chunk.candidates[0]) == null ? void 0 : _a.content.parts[0]) == null ? void 0 : _b.text) ?? "",
        finish_reason: (_c = chunk.candidates[0]) == null ? void 0 : _c.finishReason,
        model
      };
    }
  }
}
async function* streamChatCompletions3({
  project,
  location,
  applicationCredentials,
  model,
  signal,
  max_output_tokens,
  temperature,
  top_p,
  top_k,
  prompt
}) {
  var _a, _b, _c, _d, _e;
  const defaultSignal = new AbortController().signal;
  const { VertexAI } = await import("@google-cloud/vertexai");
  process.env.GOOGLE_APPLICATION_CREDENTIALS = applicationCredentials;
  const vertexAi = new VertexAI({ project, location });
  const generativeModel = vertexAi.preview.getGenerativeModel({
    model,
    generation_config: {
      max_output_tokens,
      temperature,
      top_p,
      top_k
    }
  });
  const response = await generativeModel.generateContentStream({
    contents: prompt
  });
  let hadChunks = false;
  for await (const chunk of response.stream) {
    hadChunks = true;
    if (!(signal == null ? void 0 : signal.aborted) && ((_b = (_a = chunk.candidates[0]) == null ? void 0 : _a.content.parts[0]) == null ? void 0 : _b.text)) {
      yield {
        completion: (_d = (_c = chunk.candidates[0]) == null ? void 0 : _c.content.parts[0]) == null ? void 0 : _d.text,
        finish_reason: (_e = chunk.candidates[0]) == null ? void 0 : _e.finishReason,
        model
      };
    } else {
      return;
    }
  }
  if (!hadChunks) {
    throw new Error(`No chunks received.`);
  }
}

// src/plugins/google/nodes/ChatGoogleNode.ts
var import_non_secure84 = require("nanoid/non-secure");
var import_ts_dedent75 = require("ts-dedent");
var import_p_retry3 = __toESM(require("p-retry-4"), 1);
var import_ts_pattern14 = require("ts-pattern");
var cache3 = /* @__PURE__ */ new Map();
var ChatGoogleNodeImpl = {
  create() {
    const chartNode = {
      type: "chatGoogle",
      title: "Chat (Google)",
      id: (0, import_non_secure84.nanoid)(),
      visualData: {
        x: 0,
        y: 0,
        width: 275
      },
      data: {
        model: "gemini-2.0-flash-001",
        useModelInput: false,
        temperature: 0.5,
        useTemperatureInput: false,
        top_p: 1,
        useTopPInput: false,
        top_k: void 0,
        useTopKInput: false,
        useTopP: false,
        useUseTopPInput: false,
        maxTokens: 1024,
        useMaxTokensInput: false,
        cache: false,
        useAsGraphPartialOutput: true
      }
    };
    return chartNode;
  },
  getInputDefinitions(data) {
    const inputs = [];
    inputs.push({
      id: "systemPrompt",
      title: "System Prompt",
      dataType: "string",
      required: false,
      description: "An optional system prompt for the model to use."
    });
    if (data.useModelInput) {
      inputs.push({
        id: "model",
        title: "Model",
        dataType: "string",
        required: false
      });
    }
    if (data.useTemperatureInput) {
      inputs.push({
        dataType: "number",
        id: "temperature",
        title: "Temperature"
      });
    }
    if (data.useTopPInput) {
      inputs.push({
        dataType: "number",
        id: "top_p",
        title: "Top P"
      });
    }
    if (data.useUseTopPInput) {
      inputs.push({
        dataType: "boolean",
        id: "useTopP",
        title: "Use Top P"
      });
    }
    if (data.useMaxTokensInput) {
      inputs.push({
        dataType: "number",
        id: "maxTokens",
        title: "Max Tokens"
      });
    }
    inputs.push({
      dataType: ["chat-message", "chat-message[]"],
      id: "prompt",
      title: "Prompt"
    });
    return inputs;
  },
  getOutputDefinitions(data) {
    const outputs = [];
    outputs.push({
      dataType: "string",
      id: "response",
      title: "Response"
    });
    outputs.push({
      dataType: "chat-message[]",
      id: "in-messages",
      title: "Messages Sent",
      description: "All messages sent to the model."
    });
    outputs.push({
      dataType: "chat-message[]",
      id: "all-messages",
      title: "All Messages",
      description: "All messages, with the response appended."
    });
    return outputs;
  },
  getBody(data) {
    var _a;
    return import_ts_dedent75.dedent`
      ${((_a = generativeAiGoogleModels[data.model]) == null ? void 0 : _a.displayName) ?? `Google (${data.model})`}
      ${data.useTopP ? `Top P: ${data.useTopPInput ? "(Using Input)" : data.top_p}` : `Temperature: ${data.useTemperatureInput ? "(Using Input)" : data.temperature}`}
      Max Tokens: ${data.maxTokens}
    `;
  },
  getEditors() {
    return [
      {
        type: "dropdown",
        label: "Model",
        dataKey: "model",
        useInputToggleDataKey: "useModelInput",
        options: generativeAiOptions
      },
      {
        type: "number",
        label: "Temperature",
        dataKey: "temperature",
        useInputToggleDataKey: "useTemperatureInput",
        min: 0,
        max: 2,
        step: 0.1
      },
      {
        type: "number",
        label: "Top P",
        dataKey: "top_p",
        useInputToggleDataKey: "useTopPInput",
        min: 0,
        max: 1,
        step: 0.1
      },
      {
        type: "toggle",
        label: "Use Top P",
        dataKey: "useTopP",
        useInputToggleDataKey: "useUseTopPInput"
      },
      {
        type: "number",
        label: "Max Tokens",
        dataKey: "maxTokens",
        useInputToggleDataKey: "useMaxTokensInput",
        min: 0,
        max: Number.MAX_SAFE_INTEGER,
        step: 1
      },
      {
        type: "toggle",
        label: "Cache (same inputs, same outputs)",
        dataKey: "cache"
      },
      {
        type: "toggle",
        label: "Use for subgraph partial output",
        dataKey: "useAsGraphPartialOutput"
      }
    ];
  },
  getUIData() {
    return {
      infoBoxBody: import_ts_dedent75.dedent`
        Makes a call to an Google chat model. The settings contains many options for tweaking the model's behavior.
      `,
      infoBoxTitle: "Chat (Google) Node",
      contextMenuTitle: "Chat (Google)",
      group: ["AI"]
    };
  },
  async process(data, inputs, context) {
    const output = {};
    const systemPrompt = coerceTypeOptional(inputs["systemPrompt"], "string");
    const rawModel = getInputOrData(data, inputs, "model");
    const model = rawModel;
    const temperature = getInputOrData(data, inputs, "temperature", "number");
    const topP = getInputOrData(data, inputs, "top_p", "number");
    const useTopP = getInputOrData(data, inputs, "useTopP", "boolean");
    const { messages } = getChatGoogleNodeMessages(inputs);
    const prompt = await Promise.all(
      messages.map(async (message) => {
        return {
          role: message.type === "user" ? "user" : "assistant",
          parts: await Promise.all(
            [message.message].flat().map(async (part) => {
              if (typeof part === "string") {
                return { text: part };
              } else if (part.type === "image") {
                return {
                  inline_data: {
                    mime_type: part.mediaType,
                    data: await uint8ArrayToBase64(part.data)
                  }
                };
              } else {
                throw new Error(`Google Vertex AI does not support message parts of type ${part.type}`);
              }
            })
          )
        };
      })
    );
    let { maxTokens } = data;
    const tokenizerInfo = {
      node: context.node,
      model,
      endpoint: void 0
    };
    const tokenCount = await context.tokenizer.getTokenCountForMessages(messages, void 0, tokenizerInfo);
    if (generativeAiGoogleModels[model] && tokenCount >= generativeAiGoogleModels[model].maxTokens) {
      throw new Error(
        `The model ${model} can only handle ${generativeAiGoogleModels[model].maxTokens} tokens, but ${tokenCount} were provided in the prompts alone.`
      );
    }
    if (generativeAiGoogleModels[model] && tokenCount + maxTokens > generativeAiGoogleModels[model].maxTokens) {
      const message = `The model can only handle a maximum of ${generativeAiGoogleModels[model].maxTokens} tokens, but the prompts and max tokens together exceed this limit. The max tokens has been reduced to ${generativeAiGoogleModels[model].maxTokens - tokenCount}.`;
      addWarning(output, message);
      maxTokens = Math.floor((generativeAiGoogleModels[model].maxTokens - tokenCount) * 0.95);
    }
    const project = context.getPluginConfig("googleProjectId");
    const location = context.getPluginConfig("googleRegion");
    const applicationCredentials = context.getPluginConfig("googleApplicationCredentials");
    const apiKey = context.getPluginConfig("googleApiKey");
    if (!apiKey) {
      if (project == null) {
        throw new Error("Google Project ID or Google API Key is not defined.");
      }
      if (location == null) {
        throw new Error("Google Region or Google API Key is not defined.");
      }
      if (applicationCredentials == null) {
        throw new Error("Google Application Credentials or Google API Key is not defined.");
      }
    }
    try {
      return await (0, import_p_retry3.default)(
        async () => {
          var _a;
          const options2 = {
            prompt,
            model,
            temperature: useTopP ? void 0 : temperature,
            topP: useTopP ? topP : void 0,
            maxOutputTokens: maxTokens,
            systemPrompt,
            topK: void 0
          };
          const cacheKey = JSON.stringify(options2);
          if (data.cache) {
            const cached = cache3.get(cacheKey);
            if (cached) {
              return cached;
            }
          }
          const startTime = Date.now();
          let chunks;
          if (apiKey) {
            chunks = streamGenerativeAi({
              signal: context.signal,
              model,
              prompt,
              maxOutputTokens: maxTokens,
              temperature: useTopP ? void 0 : temperature,
              topP: useTopP ? topP : void 0,
              topK: void 0,
              apiKey,
              systemPrompt
            });
          } else {
            chunks = streamChatCompletions3({
              signal: context.signal,
              model,
              prompt,
              max_output_tokens: maxTokens,
              temperature: useTopP ? void 0 : temperature,
              top_p: useTopP ? topP : void 0,
              top_k: void 0,
              project,
              location,
              applicationCredentials
            });
          }
          const responseParts = [];
          for await (const chunk of chunks) {
            if (!chunk.completion) {
              continue;
            }
            responseParts.push(chunk.completion);
            output["response"] = {
              type: "string",
              value: responseParts.join("").trim()
            };
            (_a = context.onPartialOutputs) == null ? void 0 : _a.call(context, output);
          }
          const endTime = Date.now();
          output["all-messages"] = {
            type: "chat-message[]",
            value: [
              ...messages,
              {
                type: "assistant",
                message: responseParts.join("").trim() ?? "",
                function_call: void 0,
                function_calls: void 0
              }
            ]
          };
          output["in-messages"] = {
            type: "chat-message[]",
            value: messages
          };
          if (responseParts.length === 0) {
            throw new Error("No response from Google");
          }
          output["requestTokens"] = { type: "number", value: tokenCount };
          const responseTokenCount = await context.tokenizer.getTokenCountForString(
            responseParts.join(""),
            tokenizerInfo
          );
          output["responseTokens"] = { type: "number", value: responseTokenCount };
          const duration = endTime - startTime;
          output["duration"] = { type: "number", value: duration };
          Object.freeze(output);
          cache3.set(cacheKey, output);
          return output;
        },
        {
          retries: 10,
          maxRetryTime: 1e3 * 60 * 5,
          factor: 2.5,
          minTimeout: 500,
          maxTimeout: 5e3,
          randomize: true,
          signal: context.signal,
          onFailedAttempt(err) {
            context.trace(`ChatGoogleNode failed, retrying: ${err.toString()}`);
            if (context.signal.aborted) {
              throw new Error("Aborted");
            }
          }
        }
      );
    } catch (error) {
      context.trace(getError(error).stack ?? "Missing stack");
      throw new Error(`Error processing ChatGoogleNode: ${error.message}`);
    }
  }
};
var chatGoogleNode = pluginNodeDefinition(ChatGoogleNodeImpl, "Chat");
function getChatGoogleNodeMessages(inputs) {
  const prompt = inputs["prompt"];
  if (!prompt) {
    throw new Error("Prompt is required");
  }
  const messages = (0, import_ts_pattern14.match)(prompt).with({ type: "chat-message" }, (p) => [p.value]).with({ type: "chat-message[]" }, (p) => p.value).with({ type: "string" }, (p) => [{ type: "user", message: p.value }]).with({ type: "string[]" }, (p) => p.value.map((v) => ({ type: "user", message: v }))).otherwise((p) => {
    if (isArrayDataValue(p)) {
      const stringValues = p.value.map(
        (v) => coerceType(
          {
            type: getScalarTypeOf(p.type),
            value: v
          },
          "string"
        )
      );
      return stringValues.filter((v) => v != null).map((v) => ({ type: "user", message: v }));
    }
    const coercedMessage = coerceType(p, "chat-message");
    if (coercedMessage != null) {
      return [coercedMessage];
    }
    const coercedString = coerceType(p, "string");
    return coercedString != null ? [{ type: "user", message: coerceType(p, "string") }] : [];
  });
  return { messages };
}

// src/plugins/google/plugin.ts
var googlePlugin = {
  id: "google",
  name: "Google",
  register: (register) => {
    register(chatGoogleNode);
  },
  configSpec: {
    googleApiKey: {
      type: "secret",
      label: "Google API Key",
      description: "The API key for accessing Google generative AI.",
      pullEnvironmentVariable: "GOOGLE_GENERATIVE_AI_API_KEY",
      helperText: "You may also set the GOOGLE_GENERATIVE_AI_API_KEY environment variable."
    },
    googleProjectId: {
      type: "string",
      label: "Google Project ID (Deprecated)",
      description: "The Google project ID.",
      pullEnvironmentVariable: "GCP_PROJECT",
      helperText: "Deprecated, use Google API Key instead. You may also set the GCP_PROJECT environment variable."
    },
    googleRegion: {
      type: "string",
      label: "Google Region (Deprecated)",
      description: "The Google region.",
      pullEnvironmentVariable: "GCP_REGION",
      helperText: "Deprecated, use Google API Key instead. You may also set the GCP_REGION environment variable."
    },
    googleApplicationCredentials: {
      type: "string",
      label: "Google Application Credentials (Deprecated)",
      description: "The path with the JSON file that contains your credentials.",
      pullEnvironmentVariable: "GOOGLE_APPLICATION_CREDENTIALS",
      helperText: "Deprecated, use Google API Key instead. You may also set the GOOGLE_APPLICATION_CREDENTIALS environment variable. See https://cloud.google.com/vertex-ai/docs/start/client-libraries for more info."
    }
  }
};

// src/plugins.ts
var plugins = {
  anthropic: anthropic_default,
  autoevals: autoevals_default,
  assemblyAi: assemblyAi_default,
  pinecone: pinecone_default,
  huggingFace: huggingFacePlugin,
  gentrace: gentrace_default,
  openai: openAIPlugin,
  google: googlePlugin
};

// src/integrations/DatasetProvider.ts
var import_lodash_es18 = require("lodash");
var InMemoryDatasetProvider = class {
  #datasets;
  constructor(datasets) {
    this.#datasets = datasets;
  }
  async getDatasetMetadata(id) {
    const dataset = this.#datasets.find((d) => d.meta.id === id);
    return dataset == null ? void 0 : dataset.meta;
  }
  async getDatasetsForProject(projectId) {
    return this.#datasets.map((d) => d.meta);
  }
  async getDatasetData(id) {
    const dataset = this.#datasets.find((d) => d.meta.id === id);
    if (!dataset) {
      return { id, rows: [] };
    }
    return dataset.data;
  }
  async putDatasetRow(id, row) {
    const dataset = this.#datasets.find((d) => d.meta.id === id);
    if (!dataset) {
      throw new Error(`Dataset ${id} not found`);
    }
    const existingRow = dataset.data.rows.find((r) => r.id === row.id);
    if (existingRow) {
      existingRow.data = row.data;
      existingRow.embedding = row.embedding;
      return;
    }
    dataset.data.rows.push(row);
  }
  async putDatasetData(id, data) {
    const dataset = this.#datasets.find((d) => d.meta.id === id);
    if (!dataset) {
      throw new Error(`Dataset ${id} not found`);
    }
    dataset.data = data;
  }
  async putDatasetMetadata(metadata) {
    const matchingDataset = this.#datasets.find((d) => d.meta.id === metadata.id);
    if (matchingDataset) {
      matchingDataset.meta = metadata;
      return;
    }
    this.#datasets.push({
      meta: metadata,
      data: {
        id: metadata.id,
        rows: []
      }
    });
  }
  async clearDatasetData(id) {
    const dataset = this.#datasets.find((d) => d.meta.id === id);
    if (!dataset) {
      return;
    }
    dataset.data = {
      id,
      rows: []
    };
  }
  async deleteDataset(id) {
    const index = this.#datasets.findIndex((d) => d.meta.id === id);
    if (index === -1) {
      return;
    }
    this.#datasets.splice(index, 1);
  }
  async knnDatasetRows(datasetId, k, vector) {
    const allRows = await this.getDatasetData(datasetId);
    const sorted = allRows.rows.filter((row) => row.embedding != null).map((row) => ({
      row,
      similarity: dotProductSimilarity(vector, row.embedding)
    })).sort((a, b) => b.similarity - a.similarity);
    return sorted.slice(0, k).map((r) => ({ ...r.row, distance: r.similarity }));
  }
  async exportDatasetsForProject(_projectId) {
    return (0, import_lodash_es18.cloneDeep)(this.#datasets);
  }
};
var dotProductSimilarity = (a, b) => {
  return a.reduce((acc, val, i) => acc + val * b[i], 0);
};

// src/api/streaming.ts
async function* getProcessorEvents(processor, spec) {
  var _a, _b, _c, _d, _e, _f;
  const previousIndexes = /* @__PURE__ */ new Map();
  for await (const event of processor.events()) {
    if (event.type === "partialOutput") {
      if (spec.partialOutputs === true || ((_a = spec.partialOutputs) == null ? void 0 : _a.includes(event.node.id)) || ((_b = spec.partialOutputs) == null ? void 0 : _b.includes(event.node.title))) {
        const currentOutput = coerceType(event.outputs["response"], "string");
        const delta = currentOutput.slice(previousIndexes.get(event.node.id) ?? 0);
        yield {
          type: "partialOutput",
          nodeId: event.node.id,
          nodeTitle: event.node.title,
          delta
        };
        previousIndexes.set(event.node.id, currentOutput.length);
      }
    } else if (event.type === "done") {
      if (spec.done) {
        yield {
          type: "done",
          graphOutput: event.results
        };
      }
    } else if (event.type === "error") {
      if (spec.error) {
        yield {
          type: "error",
          error: typeof event.error === "string" ? event.error : event.error.toString()
        };
      }
    } else if (event.type === "nodeStart") {
      if (spec.nodeStart === true || ((_c = spec.nodeStart) == null ? void 0 : _c.includes(event.node.id)) || ((_d = spec.nodeStart) == null ? void 0 : _d.includes(event.node.title))) {
        yield {
          type: "nodeStart",
          inputs: event.inputs,
          nodeId: event.node.id,
          nodeTitle: event.node.title
        };
      }
    } else if (event.type === "nodeFinish") {
      if (spec.nodeFinish === true || ((_e = spec.nodeFinish) == null ? void 0 : _e.includes(event.node.id)) || ((_f = spec.nodeFinish) == null ? void 0 : _f.includes(event.node.title))) {
        yield {
          type: "nodeFinish",
          outputs: event.outputs,
          nodeId: event.node.id,
          nodeTitle: event.node.title
        };
      }
    }
  }
}
function getProcessorSSEStream(processor, spec) {
  const encoder = new TextEncoder();
  function sendEvent(controller, type, data) {
    const event = `event: ${type}
data: ${JSON.stringify(data)}

`;
    controller.enqueue(encoder.encode(event));
  }
  return new ReadableStream({
    async start(controller) {
      try {
        for await (const event of getProcessorEvents(processor, spec)) {
          sendEvent(controller, event.type, event);
        }
        controller.close();
      } catch (err) {
        controller.error(err);
      }
    }
  });
}
function getSingleNodeStream(processor, nodeIdOrTitle) {
  return new ReadableStream({
    async start(controller) {
      try {
        for await (const event of getProcessorEvents(processor, {
          partialOutputs: [nodeIdOrTitle],
          nodeFinish: [nodeIdOrTitle]
        })) {
          if (event.type === "partialOutput" && (event.nodeId === nodeIdOrTitle || event.nodeTitle === nodeIdOrTitle)) {
            controller.enqueue(`data: ${JSON.stringify(event.delta)}

`);
          } else if (event.type === "nodeFinish" && (event.nodeId === nodeIdOrTitle || event.nodeTitle === nodeIdOrTitle)) {
            controller.close();
          }
        }
        controller.close();
      } catch (err) {
        controller.error(err);
      }
    }
  });
}

// src/api/createProcessor.ts
function coreCreateProcessor(project, options2) {
  var _a, _b, _c;
  const { graph, inputs = {}, context = {} } = options2;
  const graphId = graph ? graph in project.graphs ? graph : (_b = (_a = Object.values(project.graphs).find((g) => {
    var _a2;
    return ((_a2 = g.metadata) == null ? void 0 : _a2.name) === graph;
  })) == null ? void 0 : _a.metadata) == null ? void 0 : _b.id : project.metadata.mainGraphId;
  if (!graphId) {
    throw new Error(`Graph not found, and no main graph specified.`);
  }
  const processor = new GraphProcessor(project, graphId, options2.registry, options2.includeTrace);
  if (options2.onStart) {
    processor.on("start", options2.onStart);
  }
  if (options2.onNodeStart) {
    processor.on("nodeStart", options2.onNodeStart);
  }
  if (options2.onNodeFinish) {
    processor.on("nodeFinish", options2.onNodeFinish);
  }
  if (options2.onNodeError) {
    processor.on("nodeError", options2.onNodeError);
  }
  if (options2.onNodeExcluded) {
    processor.on("nodeExcluded", options2.onNodeExcluded);
  }
  if (options2.onGraphStart) {
    processor.on("graphStart", options2.onGraphStart);
  }
  if (options2.onGraphError) {
    processor.on("graphError", options2.onGraphError);
  }
  if (options2.onGraphFinish) {
    processor.on("graphFinish", options2.onGraphFinish);
  }
  if (options2.onPartialOutput) {
    processor.on("partialOutput", options2.onPartialOutput);
  }
  if (options2.onUserInput) {
    processor.on("userInput", options2.onUserInput);
  }
  if (options2.onDone) {
    processor.on("done", options2.onDone);
  }
  if (options2.onAbort) {
    processor.on("abort", options2.onAbort);
  }
  if (options2.onGraphAbort) {
    processor.on("graphAbort", options2.onGraphAbort);
  }
  if (options2.onTrace) {
    processor.on("trace", options2.onTrace);
  }
  if (options2.onNodeOutputsCleared) {
    processor.on("nodeOutputsCleared", options2.onNodeOutputsCleared);
  }
  if (options2.externalFunctions) {
    for (const [name, fn] of Object.entries(options2.externalFunctions)) {
      processor.setExternalFunction(name, fn);
    }
  }
  if (options2.onUserEvent) {
    for (const [name, fn] of Object.entries(options2.onUserEvent)) {
      processor.onUserEvent(name, fn);
    }
  }
  (_c = options2.abortSignal) == null ? void 0 : _c.addEventListener("abort", () => {
    processor.abort();
  });
  const resolvedInputs = looseDataValuesToDataValues(inputs);
  const resolvedContextValues = looseDataValuesToDataValues(context);
  return {
    processor,
    inputs: resolvedInputs,
    contextValues: resolvedContextValues,
    getEvents: (spec) => getProcessorEvents(processor, spec),
    getSSEStream: (spec) => getProcessorSSEStream(processor, spec),
    streamNode: (nodeIdOrTitle) => getSingleNodeStream(processor, nodeIdOrTitle),
    async run() {
      const outputs = await processor.processGraph(
        {
          nativeApi: options2.nativeApi,
          datasetProvider: options2.datasetProvider,
          audioProvider: options2.audioProvider,
          settings: {
            openAiKey: options2.openAiKey ?? "",
            openAiOrganization: options2.openAiOrganization ?? "",
            openAiEndpoint: options2.openAiEndpoint ?? "",
            pluginEnv: options2.pluginEnv ?? {},
            pluginSettings: options2.pluginSettings ?? {},
            recordingPlaybackLatency: 1e3,
            chatNodeHeaders: options2.chatNodeHeaders ?? {},
            chatNodeTimeout: options2.chatNodeTimeout ?? DEFAULT_CHAT_NODE_TIMEOUT,
            throttleChatNode: options2.throttleChatNode ?? 100
          },
          getChatNodeEndpoint: options2.getChatNodeEndpoint
        },
        resolvedInputs,
        resolvedContextValues
      );
      return outputs;
    }
  };
}
async function coreRunGraph(project, options2) {
  const processorInfo = coreCreateProcessor(project, options2);
  return processorInfo.run();
}
function loadProjectFromString(content) {
  const [project] = deserializeProject(content);
  return project;
}
function loadProjectAndAttachedDataFromString(content) {
  return deserializeProject(content);
}

// src/index.ts
var Rivet = void 0;
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  AbortGraphNodeImpl,
  AppendToDatasetNodeImpl,
  ArrayNodeImpl,
  AssembleMessageNodeImpl,
  AssemblePromptNodeImpl,
  AudioNodeImpl,
  BooleanNodeImpl,
  BrowserNativeApi,
  CallGraphNodeImpl,
  ChatLoopNodeImpl,
  ChatNodeBase,
  ChatNodeImpl,
  ChunkNodeImpl,
  CoalesceNodeImpl,
  CodeNodeImpl,
  CommentNodeImpl,
  CompareNodeImpl,
  ContextNodeImpl,
  CreateDatasetNodeImpl,
  CronNodeImpl,
  DEFAULT_CHAT_ENDPOINT,
  DEFAULT_CHAT_NODE_TIMEOUT,
  DatasetNearestNeighborsNodeImpl,
  DelayNodeImpl,
  DelegateFunctionCallNodeImpl,
  DestructureNodeImpl,
  DocumentNodeImpl,
  EvaluateNodeImpl,
  ExecutionRecorder,
  ExternalCallNodeImpl,
  ExtractJsonNodeImpl,
  ExtractMarkdownCodeBlocksNodeImpl,
  ExtractObjectPathNodeImpl,
  ExtractRegexNodeImpl,
  ExtractYamlNodeImpl,
  FilterNodeImpl,
  GetAllDatasetsNodeImpl,
  GetDatasetRowNodeImpl,
  GetEmbeddingNodeImpl,
  GetGlobalNodeImpl,
  GptFunctionNodeImpl,
  GraphInputNodeImpl,
  GraphOutputNodeImpl,
  GraphProcessor,
  GraphReferenceNodeImpl,
  HashNodeImpl,
  HttpCallNodeImpl,
  IF_PORT,
  IfElseNodeImpl,
  IfNodeImpl,
  ImageNodeImpl,
  InMemoryDatasetProvider,
  JoinNodeImpl,
  ListGraphsNodeImpl,
  LoadDatasetNodeImpl,
  LoopControllerNodeImpl,
  LoopUntilNodeImpl,
  MatchNodeImpl,
  NodeImpl,
  NodeRegistration,
  NumberNodeImpl,
  ObjectNodeImpl,
  PassthroughNodeImpl,
  PlayAudioNodeImpl,
  PluginNodeImplClass,
  PopNodeImpl,
  PromptNodeImpl,
  RaceInputsNodeImpl,
  RaiseEventNodeImpl,
  RandomNumberNodeImpl,
  ReadAllFilesNodeImpl,
  ReadDirectoryNodeImpl,
  ReadFileNodeImpl,
  ReplaceDatasetNodeImpl,
  Rivet,
  SetGlobalNodeImpl,
  ShuffleNodeImpl,
  SliceNodeImpl,
  SplitNodeImpl,
  SubGraphNodeImpl,
  TextNodeImpl,
  ToJsonNodeImpl,
  ToMarkdownTableNodeImpl,
  ToTreeNodeImpl,
  ToYamlNodeImpl,
  TrimChatMessagesNodeImpl,
  UrlReferenceNodeImpl,
  UserInputNodeImpl,
  VectorNearestNeighborsNodeImpl,
  VectorStoreNodeImpl,
  WaitForEventNodeImpl,
  abortGraphNode,
  addWarning,
  anthropicPlugin,
  appendToDatasetNode,
  arrayNode,
  arrayTypeToScalarType,
  arrayizeDataValue,
  assembleMessageNode,
  assemblePromptNode,
  assemblyAiPlugin,
  assertBaseDir,
  audioNode,
  autoevalsPlugin,
  base64ToUint8Array,
  baseDirs,
  booleanNode,
  callGraphNode,
  canBeCoerced,
  canBeCoercedAny,
  chatLoopNode,
  chatNode,
  chunkNode,
  chunkStringByTokenCount,
  cleanHeaders,
  coalesceNode,
  codeNode,
  coerceType,
  coerceTypeOptional,
  commentNode,
  compareNode,
  contextNode,
  coreCreateProcessor,
  coreRunGraph,
  createDatasetNode,
  cronNode,
  dataTypeDisplayNames,
  dataTypes,
  datasetNearestNeighborsNode,
  dedent,
  delayNode,
  delegateFunctionCallNode,
  deserializeDatasets,
  deserializeGraph,
  deserializeProject,
  destructureNode,
  documentNode,
  doubleCheckProject,
  emptyNodeGraph,
  evaluateNode,
  expectType,
  expectTypeOptional,
  externalCallNode,
  extractJsonNode,
  extractMarkdownCodeBlocksNode,
  extractObjectPathNode,
  extractRegexNode,
  extractYamlNode,
  filterNode,
  functionTypeToScalarType,
  gentracePlugin,
  getAllDatasetsNode,
  getChatNodeMessages,
  getCostForTokens,
  getDatasetRowNode,
  getDefaultValue,
  getEmbeddingNode,
  getError,
  getGlobalNode,
  getInputOrData,
  getIntegration,
  getPluginConfig,
  getProcessorEvents,
  getProcessorSSEStream,
  getScalarTypeOf,
  getSingleNodeStream,
  getWarnings,
  globalRivetNodeRegistry,
  googlePlugin,
  gptFunctionNode,
  graphInputNode,
  graphOutputNode,
  graphReferenceNode,
  handleEscapeCharacters,
  hashNode,
  httpCallNode,
  huggingFacePlugin,
  ifElseNode,
  ifNode,
  imageNode,
  inferType,
  isArrayDataType,
  isArrayDataValue,
  isBuiltInInputDefinition,
  isDataTypeAccepted,
  isDataTypeCompatible,
  isFunctionDataType,
  isFunctionDataValue,
  isNotFunctionDataValue,
  isScalarDataType,
  isScalarDataValue,
  joinNode,
  listGraphsNode,
  loadDatasetNode,
  loadProjectAndAttachedDataFromString,
  loadProjectFromString,
  loopControllerNode,
  loopUntilNode,
  looseDataValueToDataValue,
  looseDataValuesToDataValues,
  matchNode,
  newId,
  nodeDefinition,
  numberNode,
  objectNode,
  openai,
  passthroughNode,
  pineconePlugin,
  playAudioNode,
  pluginNodeDefinition,
  plugins,
  popNode,
  promptNode,
  raceInputsNode,
  raiseEventNode,
  randomNumberNode,
  readAllFilesNode,
  readDirectoryNode,
  readFileNode,
  registerBuiltInNodes,
  registerIntegration,
  replaceDatasetNode,
  resetGlobalRivetNodeRegistry,
  scalarDefaults,
  scalarTypes,
  serializeDatasets,
  serializeGraph,
  serializeProject,
  setGlobalNode,
  shuffleNode,
  sliceNode,
  splitNode,
  subGraphNode,
  textNode,
  toJsonNode,
  toMarkdownTableNode,
  toTreeNode,
  toYamlNode,
  trimChatMessagesNode,
  uint8ArrayToBase64,
  unwrapDataValue,
  urlReferenceNode,
  userInputNode,
  vectorNearestNeighborsNode,
  vectorStoreNode,
  waitForEventNode,
  yamlProblem
});
//# sourceMappingURL=bundle.cjs.map
