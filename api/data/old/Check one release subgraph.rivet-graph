version: 4
data:
  metadata:
    description: ""
    id: hcy2UDhZVh6QP8e0AjKC7
    name: Check one release subgraph
  nodes:
    '[6JaC_oSAGFBhKIVMkEWYH]:graphOutput "Graph Output"':
      data:
        dataType: boolean
        id: Analysis
      visualData: 1653.3084158213596/265.662211643463/330/362/var(--node-color-3)/var(--node-color-3)
    '[Gh78wjKAaPvBid3c-skfR]:boolean "Bool"':
      data:
        useValueInput: true
        value: true
      outgoingConnections:
        - value->"Graph Output" 6JaC_oSAGFBhKIVMkEWYH/value
      visualData: 1402.0330584589349/287.8153056679769/160/356//
    '[KFdr9J6ICJGZx5GUCVA2z]:destructure "Destructure"':
      data:
        paths:
          - $.data.history[0].rewrite
          - $.data.history[0].fails
          - $.data.history[0].updates
      outgoingConnections:
        - match_0->"Chat" oprEYTNZ_pRARqzGBLP-T/prompt
      visualData: 577.6329094434866/564.9764745587175/280/819//
    '[MzLNx8qSegilkaBQOcD40]:graphInput "Graph Input"':
      data:
        dataType: object
        id: input
        useDefaultValueInput: false
      outgoingConnections:
        - data->"Destructure" KFdr9J6ICJGZx5GUCVA2z/object
      visualData: 167.68004842955062/430.2924658037318/330/818/var(--node-color-3)/var(--node-color-3)
    '[nQq13VvC8AaOBOhf-mLp3]:text "Text"':
      data:
        text: >-
          You are an agent who checks the content of a press releases.


          Your prompt will contain a piece of text content and you need to ensure that content adheres to the PR best practices as defined by the following:


          {{Bestpractice}}


          If the press release content meets the majority of the criteria then set the output value to boolean "false" otherwise set the output value to boolean "true".
      outgoingConnections:
        - output->"Chat" oprEYTNZ_pRARqzGBLP-T/systemPrompt
      visualData: 653.3694504216322/24.97846355171863/330/349//
    '[oprEYTNZ_pRARqzGBLP-T]:chat "Chat"':
      data:
        additionalParameters: []
        cache: false
        enableFunctionUse: false
        headers: []
        maxTokens: 2048
        modalitiesIncludeAudio: false
        modalitiesIncludeText: false
        model: gpt-4o-mini
        outputUsage: false
        parallelFunctionCalling: true
        reasoningEffort: medium
        stop: ""
        temperature: 0.5
        text: ""
        top_p: 1
        useAdditionalParametersInput: false
        useAsGraphPartialOutput: true
        useFrequencyPenaltyInput: false
        useMaxTokensInput: false
        useModelInput: false
        usePredictedOutput: false
        usePresencePenaltyInput: false
        useReasoningEffortInput: false
        useServerTokenCalculation: true
        useStop: false
        useStopInput: false
        useTemperatureInput: false
        useTopP: false
        useTopPInput: false
        useUseTopPInput: false
        useUserInput: false
      outgoingConnections:
        - response->"Bool" Gh78wjKAaPvBid3c-skfR/input
      visualData: 1073.1870401927615/411.2937970096649/230/354//
    '[pq10Mh3gpDQwkS9T4_Taf]:loadDataset "Load Dataset"':
      data:
        datasetId: xLJpaKaUKaZBupQgz34vW
      description: Best practices data set
      outgoingConnections:
        - dataset->"Text" nQq13VvC8AaOBOhf-mLp3/Bestpractice
      visualData: 211.83706178712825/20.293594189116902/280/347//
